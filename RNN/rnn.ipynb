{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readability Assessment through Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Readability assessment is a well known problem in natural language processing field. Giving someone the suitable text for his level of comprehension (not so easy and not so hard) could maximize his understanding and enjoyment. In this notebook we are trying to assess the readability of a given text regardless of the text subject using recurrent neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Corpus\n",
    "> OneStopEnglish corpus: A new corpus for automatic readability assessment and text simplification  \n",
    "> Sowmya Vajjala and Ivana Lučić  \n",
    "> 2018  \n",
    "> Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications, pages 297–304. Association for Computational Linguistics.  \n",
    "> [url](http://aclweb.org/anthology/W18-0535). [bib file](https://aclanthology.coli.uni-saarland.de/papers/W18-0535/w18-0535.bib)\n",
    "\n",
    "Please cite the above paper if you use this corpus in your research.\n",
    "\n",
    "[![DOI](https://zenodo.org/badge/128919409.svg)](https://zenodo.org/badge/latestdoi/128919409)\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let's dive into our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/ms10596/PycharmProjects/match\")\n",
    "from ipywidgets import interact\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from utils.loading import load_glove_embeddings\n",
    "from utils.one_stop_english import load_corpus, corpus_to_words, corpus_to_pos\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, LSTM, Bidirectional\n",
    "import numpy as np\n",
    "\n",
    "glove = load_glove_embeddings()\n",
    "corpus = load_corpus()\n",
    "articles, tags = corpus_to_words(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading level|Avg. Num. Words|Std. Dev|Number of Articles\n",
    "---|---|---|---\n",
    "Elementary|533.17|103.79|189\n",
    "Intermediate|676.59|117.15|189\n",
    "Advanced|820.49|162.52|189\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb5fb4d113e4c1bbddc6c6bd23419c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=94, description='i', max=188), IntSlider(value=500, description='words',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def show_articles(i=(0,188,1), words=(0,1000,1)):\n",
    "    data = [\n",
    "        [\"Advanced\",articles[i][:words]], \n",
    "        [\"Intermediate\",articles[i+2][:words]], \n",
    "        [\"Elementary\",articles[i+1][:words]]\n",
    "    ]\n",
    "    headers = ['Reading Level', 'Example']\n",
    "    display(HTML(tabulate(data,tablefmt='html', headers=headers)+\"<style>th,td {font-size: 10px}</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ~~Feature Extraction~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd5c07706034dc099f4909214ed66da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=30, description='i', max=60), Output()), _dom_classes=('widget-interact'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def show_features(i=(0,60,1)):\n",
    "    data = [[\"Adjectives (ADJ) like warm, fat\"],[\"Adverbs (ADV) like almost, too, very\"],[\"Articles (ART) like a, an, the\"],[\"Conjunctions (CONJ) like for, and, nor\"],[\"Interjections (INTERJ) like wow, oops, ouch\"],[\"Nouns (NOUN) like boy, girl, doctor, town\"],[\"Numerals (NUM) like 1, 155, 89\"],[\"Past participles (PASTPART) like taken, eaten\"],[\"Prepositions (PREP) like at, for, in, off\"],[\"Pronouns (PRON) like he, she, you, I\"],[\"Punctuation (PUNCT) like ?, :, ;, .\"],[\"Special symbols (SYMBOL) like @, %,\"] ,[\"Adjectives (ADJ) like warm, fat\"],[\"Adverbs (ADV) like almost, too, very\"],[\"Articles (ART) like a, an, the\"],[\"Conjunctions (CONJ) like for, and, nor\"],[\"Interjections (INTERJ) like wow, oops, ouch\"],[\"Nouns (NOUN) like boy, girl, doctor, town\"],[\"Numerals (NUM) like 1, 155, 89\"],[\"Past participles (PASTPART) like taken, eaten\"],[\"Prepositions (PREP) like at, for, in, off\"],[\"Pronouns (PRON) like he, she, you, I\"],[\"Punctuation (PUNCT) like ?, :, ;, .\"],[\"Special symbols (SYMBOL) like @, %, \"],[\"Nominal phrases (NP) like The dog on the sofa\"],[\"Adjectival phrases (AP) like The movie was terrible\"],[\"Prepositional phrases (PP) like We stayed by the river\"],[\"Adverbial phrases (ADVP) like The carpenter hit the nail with a hammer.\"],[\"Temporal auxiliary verb phrases (VTEMP) like I was wondering about.\"],[\"Aspectual auxiliary verb phrases (VASP) l have seen the light\"],[\"Modal auxiliary verb phrases (VMOD) I should study\"],[\"Copulative verb phrases (VCOP) John is happy\"],[\"Past participle verb phrases (VPASTPART) I have bought\"],[\"Gerundive verb phrases (VGER) Running is a good exercise\"],[\"Infinitive verb phrases (VINF) I want to study.\"],[\"Finite verb phrases (VF) She plays guitar\"],[\"Sub-clause phrases (SC e REL)Until Mr. Sanchez has his first cup\"],[\"Verb phrases (VF e VCOP) Ali is going to school\"],[\"Number of sentences\"],[\"Number of words\"],[\"Number of different words\"],[\"Number of different verbs forms\"],[\"Number of auxiliary verbs\"],[\"Number of main verbs\"],[\"Average number of verb phrases per sentence\"],[\"Average length of sentences\"],[\"Average length of syllables per word\"],[\"Average size of verbal chains\"],[\"Average size of coordination relation’s chains\"],[\"Frequency of words with 1-4 syllables\"],[\"Frequency of words with more than 4 syllables\"],[\"Total number of dependencies\"],[\"Total number of tree nodes\"],[\"Number of pronouns per noun phrases (NP)\"],[\"Number of NP with a definite or demonstrative determiner\"],[\"Number of NP with a indefinite determiner\"],[\"Number of subordinate clauses (SC/REL chunks)\"], [\"Number of coordination relations\"], [\"Number of omit subjects\"],[\"Flesch Reading Ease BR readability measure\"]]\n",
    "    display(HTML(tabulate(data[0:i],tablefmt='html')+\"<style>th,td {font-size: 10px}</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we see there are plenty of features we can extract.\n",
    "* Feature Engineering is a tedious process and needs a great experience.\n",
    "* Also those features neglect sentence structure as they destroy the ordering of text.\n",
    "> so we are not going to extract features. every word will be feature itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding\n",
    "So now we need a good representation of words that could match each word to a number or group of numbers so that they keep some of the semantic properties and similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.7001  ,  0.36781 ,  0.34424 , -0.42318 , -0.046018, -0.66072 ,\n",
       "       -0.33993 ,  0.18271 , -0.92863 ,  0.5684  , -0.43819 ,  0.70827 ,\n",
       "       -0.47459 , -0.079269,  1.0187  ,  0.2213  ,  0.43073 ,  0.76719 ,\n",
       "        0.18774 , -0.49214 , -0.53063 ,  0.56379 ,  0.63571 ,  0.64622 ,\n",
       "        1.2649  , -0.82901 , -1.3903  ,  0.3749  ,  0.61316 , -1.5994  ,\n",
       "        1.3005  ,  0.64347 , -0.58004 ,  1.0372  , -0.27156 , -0.43382 ,\n",
       "        0.8554  , -0.8967  ,  0.80176 , -0.33333 , -0.17654 , -0.12277 ,\n",
       "       -0.70508 , -0.28412 ,  0.71149 , -0.13487 ,  0.049514, -0.8134  ,\n",
       "        0.34293 ,  1.0381  ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['hey']\n",
    "# todo plot embeddings and show relations between words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (567, 1000)\n",
      "Shape of label tensor: (567, 3)\n"
     ]
    }
   ],
   "source": [
    "maxlen = 1000 # Cuts off reviews after 100 words\n",
    "training_samples = 450\n",
    "validation_samples = 117\n",
    "max_words = 20000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(articles)\n",
    "sequences = tokenizer.texts_to_sequences(articles)\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "labels = to_categorical(tags)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "x_train= data[:training_samples]\n",
    "y_train= labels[:training_samples]\n",
    "x_val =data[training_samples:]\n",
    "y_val =labels[training_samples:]\n",
    "# print(data)\n",
    "# print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-fb63ca41f16b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0membedding_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0membedding_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_index' is not defined"
     ]
    }
   ],
   "source": [
    "embedding_dim = 50\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_matrix[i] = glove.get(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14293234841771516864\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12718176090849362690\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 3052458719266621928\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3349741568\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 864661028407538861\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "with tf.device('/gpu:0'):\n",
    "    print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 1000, 50)          1000000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 64)                21248     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 1,021,443\n",
      "Trainable params: 1,021,443\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 1000, 50)          1000000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 64)                21248     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 1,021,443\n",
      "Trainable params: 21,443\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 450 samples, validate on 117 samples\n",
      "Epoch 1/10\n",
      "450/450 [==============================] - 24s 54ms/step - loss: 0.0079 - acc: 0.3311 - val_loss: 1.1921e-07 - val_acc: 0.3248\n",
      "Epoch 2/10\n",
      "450/450 [==============================] - 21s 46ms/step - loss: 1.1921e-07 - acc: 0.3356 - val_loss: 1.1921e-07 - val_acc: 0.3248\n",
      "Epoch 3/10\n",
      "450/450 [==============================] - 21s 47ms/step - loss: 1.1921e-07 - acc: 0.3356 - val_loss: 1.1921e-07 - val_acc: 0.3248\n",
      "Epoch 4/10\n",
      "450/450 [==============================] - 21s 46ms/step - loss: 1.1921e-07 - acc: 0.3356 - val_loss: 1.1921e-07 - val_acc: 0.3248\n",
      "Epoch 5/10\n",
      "450/450 [==============================] - 21s 46ms/step - loss: 1.1921e-07 - acc: 0.3356 - val_loss: 1.1921e-07 - val_acc: 0.3248\n",
      "Epoch 6/10\n",
      "450/450 [==============================] - 20s 45ms/step - loss: 1.1921e-07 - acc: 0.3356 - val_loss: 1.1921e-07 - val_acc: 0.3248\n",
      "Epoch 7/10\n",
      "450/450 [==============================] - 22s 49ms/step - loss: 1.1921e-07 - acc: 0.3356 - val_loss: 1.1921e-07 - val_acc: 0.3248\n",
      "Epoch 8/10\n",
      "450/450 [==============================] - 21s 47ms/step - loss: 1.1921e-07 - acc: 0.3356 - val_loss: 1.1921e-07 - val_acc: 0.3248\n",
      "Epoch 9/10\n",
      "450/450 [==============================] - 21s 46ms/step - loss: 1.1921e-07 - acc: 0.3356 - val_loss: 1.1921e-07 - val_acc: 0.3248\n",
      "Epoch 10/10\n",
      "450/450 [==============================] - 21s 47ms/step - loss: 1.1921e-07 - acc: 0.3356 - val_loss: 1.1921e-07 - val_acc: 0.3248\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "epochs=10,\n",
    "batch_size=50,\n",
    "validation_data=(x_val, y_val))\n",
    "model.save_weights('pre_trained_glove_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
