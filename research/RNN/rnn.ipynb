{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Readability Assessment through Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Readability assessment is a well known problem in natural language processing field. Giving someone the suitable text for his level of comprehension (not so easy and not so hard) could maximize his understanding and enjoyment. In this notebook we are trying to assess the readability of a given text regardless of the text subject using recurrent neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Corpus\n",
    "> OneStopEnglish corpus: A new corpus for automatic readability assessment and text simplification  \n",
    "> Sowmya Vajjala and Ivana Lučić  \n",
    "> 2018  \n",
    "> Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications, pages 297–304. Association for Computational Linguistics.  \n",
    "> [url](http://aclweb.org/anthology/W18-0535). [bib file](https://aclanthology.coli.uni-saarland.de/papers/W18-0535/w18-0535.bib)\n",
    "\n",
    "Please cite the above paper if you use this corpus in your research.\n",
    "\n",
    "[![DOI](https://zenodo.org/badge/128919409.svg)](https://zenodo.org/badge/latestdoi/128919409)\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let's dive into our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "sys.path.append(\"/home/ms10596/Documents/match\")\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from research.utils.one_stop_english import OneStopEnglish\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, HTML\n",
    "from research.utils.loading import load_glove_embeddings\n",
    "from tensorflow import keras\n",
    "corpus = OneStopEnglish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading level|Avg. Num. Words|Std. Dev|Number of Articles\n",
    "---|---|---|---\n",
    "Elementary|533.17|103.79|189\n",
    "Intermediate|676.59|117.15|189\n",
    "Advanced|820.49|162.52|189\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table>\n<thead>\n<tr><th>Reading Level  </th><th>Example                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </th></tr>\n</thead>\n<tbody>\n<tr><td>Advanced       </td><td>It has been called the hotel of mum and dad but few guesthouses have such favourable terms. As the housing crisis bites, a fifth of young adults are staying in the family home until they are at least 26 and the same proportion are not paying a penny towards their keep. A recent survey found that the proportion of adults living at home varied around the country, from just under 9% in the East Midlands to more than double that in London, where house prices and rents are highest. While many around</td></tr>\n<tr><td>Intermediate   </td><td>Some people call it the hotel of mum and dad. A fifth of young adults are staying in the family home until they are at least 26 and the same proportion are not paying a penny towards their keep. A recent survey found that the proportion of adults living at home varied around the country, from just under 9% in the East Midlands to more than double that in London, where house prices and rents are highest. While many around the country contributed financially, it found that 20% were paying nothing</td></tr>\n<tr><td>Elementary     </td><td>A fifth of young adults in the UK are staying in the family home until they are at least 26 and a fifth are not paying any rent. A recent survey found that the percentage of adults who live at home was different in different parts of the country  it was less than 9% in the East Midlands and more than double that in London, where house prices and rents are highest. Many young people pay their parents some money to live at home but 20% pay nothing at all.\nYoung adults are suffering from low wages                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </td></tr>\n</tbody>\n</table><style>th,td {font-size: 10px}</style>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def show_articles(i=(0,188,1), words=(0,1000,1)):\n",
    "    data = [\n",
    "        [\"Advanced\",corpus.articles[i+189+189][:words]], \n",
    "        [\"Intermediate\",corpus.articles[i+189][:words]], \n",
    "        [\"Elementary\",corpus.articles[i][:words]]\n",
    "    ]\n",
    "    headers = ['Reading Level', 'Example']\n",
    "    display(HTML(tabulate(data,tablefmt='html', headers=headers)+\"<style>th,td {font-size: 10px}</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ~~Feature Extraction~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table>\n<tbody>\n<tr><td>Adjectives (ADJ) like warm, fat                                        </td></tr>\n<tr><td>Adverbs (ADV) like almost, too, very                                   </td></tr>\n<tr><td>Articles (ART) like a, an, the                                         </td></tr>\n<tr><td>Conjunctions (CONJ) like for, and, nor                                 </td></tr>\n<tr><td>Interjections (INTERJ) like wow, oops, ouch                            </td></tr>\n<tr><td>Nouns (NOUN) like boy, girl, doctor, town                              </td></tr>\n<tr><td>Numerals (NUM) like 1, 155, 89                                         </td></tr>\n<tr><td>Past participles (PASTPART) like taken, eaten                          </td></tr>\n<tr><td>Prepositions (PREP) like at, for, in, off                              </td></tr>\n<tr><td>Pronouns (PRON) like he, she, you, I                                   </td></tr>\n<tr><td>Punctuation (PUNCT) like ?, :, ;, .                                    </td></tr>\n<tr><td>Special symbols (SYMBOL) like @, %,                                    </td></tr>\n<tr><td>Adjectives (ADJ) like warm, fat                                        </td></tr>\n<tr><td>Adverbs (ADV) like almost, too, very                                   </td></tr>\n<tr><td>Articles (ART) like a, an, the                                         </td></tr>\n<tr><td>Conjunctions (CONJ) like for, and, nor                                 </td></tr>\n<tr><td>Interjections (INTERJ) like wow, oops, ouch                            </td></tr>\n<tr><td>Nouns (NOUN) like boy, girl, doctor, town                              </td></tr>\n<tr><td>Numerals (NUM) like 1, 155, 89                                         </td></tr>\n<tr><td>Past participles (PASTPART) like taken, eaten                          </td></tr>\n<tr><td>Prepositions (PREP) like at, for, in, off                              </td></tr>\n<tr><td>Pronouns (PRON) like he, she, you, I                                   </td></tr>\n<tr><td>Punctuation (PUNCT) like ?, :, ;, .                                    </td></tr>\n<tr><td>Special symbols (SYMBOL) like @, %,                                    </td></tr>\n<tr><td>Nominal phrases (NP) like The dog on the sofa                          </td></tr>\n<tr><td>Adjectival phrases (AP) like The movie was terrible                    </td></tr>\n<tr><td>Prepositional phrases (PP) like We stayed by the river                 </td></tr>\n<tr><td>Adverbial phrases (ADVP) like The carpenter hit the nail with a hammer.</td></tr>\n<tr><td>Temporal auxiliary verb phrases (VTEMP) like I was wondering about.    </td></tr>\n<tr><td>Aspectual auxiliary verb phrases (VASP) l have seen the light          </td></tr>\n</tbody>\n</table><style>th,td {font-size: 10px}</style>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def show_features(i=(0,60,1)):\n",
    "    data = [[\"Adjectives (ADJ) like warm, fat\"],[\"Adverbs (ADV) like almost, too, very\"],[\"Articles (ART) like a, an, the\"],[\"Conjunctions (CONJ) like for, and, nor\"],[\"Interjections (INTERJ) like wow, oops, ouch\"],[\"Nouns (NOUN) like boy, girl, doctor, town\"],[\"Numerals (NUM) like 1, 155, 89\"],[\"Past participles (PASTPART) like taken, eaten\"],[\"Prepositions (PREP) like at, for, in, off\"],[\"Pronouns (PRON) like he, she, you, I\"],[\"Punctuation (PUNCT) like ?, :, ;, .\"],[\"Special symbols (SYMBOL) like @, %,\"] ,[\"Adjectives (ADJ) like warm, fat\"],[\"Adverbs (ADV) like almost, too, very\"],[\"Articles (ART) like a, an, the\"],[\"Conjunctions (CONJ) like for, and, nor\"],[\"Interjections (INTERJ) like wow, oops, ouch\"],[\"Nouns (NOUN) like boy, girl, doctor, town\"],[\"Numerals (NUM) like 1, 155, 89\"],[\"Past participles (PASTPART) like taken, eaten\"],[\"Prepositions (PREP) like at, for, in, off\"],[\"Pronouns (PRON) like he, she, you, I\"],[\"Punctuation (PUNCT) like ?, :, ;, .\"],[\"Special symbols (SYMBOL) like @, %, \"],[\"Nominal phrases (NP) like The dog on the sofa\"],[\"Adjectival phrases (AP) like The movie was terrible\"],[\"Prepositional phrases (PP) like We stayed by the river\"],[\"Adverbial phrases (ADVP) like The carpenter hit the nail with a hammer.\"],[\"Temporal auxiliary verb phrases (VTEMP) like I was wondering about.\"],[\"Aspectual auxiliary verb phrases (VASP) l have seen the light\"],[\"Modal auxiliary verb phrases (VMOD) I should study\"],[\"Copulative verb phrases (VCOP) John is happy\"],[\"Past participle verb phrases (VPASTPART) I have bought\"],[\"Gerundive verb phrases (VGER) Running is a good exercise\"],[\"Infinitive verb phrases (VINF) I want to study.\"],[\"Finite verb phrases (VF) She plays guitar\"],[\"Sub-clause phrases (SC e REL)Until Mr. Sanchez has his first cup\"],[\"Verb phrases (VF e VCOP) Ali is going to school\"],[\"Number of sentences\"],[\"Number of words\"],[\"Number of different words\"],[\"Number of different verbs forms\"],[\"Number of auxiliary verbs\"],[\"Number of main verbs\"],[\"Average number of verb phrases per sentence\"],[\"Average length of sentences\"],[\"Average length of syllables per word\"],[\"Average size of verbal chains\"],[\"Average size of coordination relation’s chains\"],[\"Frequency of words with 1-4 syllables\"],[\"Frequency of words with more than 4 syllables\"],[\"Total number of dependencies\"],[\"Total number of tree nodes\"],[\"Number of pronouns per noun phrases (NP)\"],[\"Number of NP with a definite or demonstrative determiner\"],[\"Number of NP with a indefinite determiner\"],[\"Number of subordinate clauses (SC/REL chunks)\"], [\"Number of coordination relations\"], [\"Number of omit subjects\"],[\"Flesch Reading Ease BR readability measure\"]]\n",
    "    display(HTML(tabulate(data[0:i],tablefmt='html')+\"<style>th,td {font-size: 10px}</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we see there are plenty of features we can extract.\n",
    "* Feature Engineering is a tedious process and needs a great experience.\n",
    "* Also those features neglect sentence structure as they destroy the ordering of text.\n",
    "> so we are not going to extract features. every word will be feature itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding\n",
    "So now we need a good representation of words that could match each word to a number or group of numbers so that they keep some of the semantic properties and similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['-0.7001', '0.36781', '0.34424', '-0.42318', '-0.046018',\n",
       "       '-0.66072', '-0.33993', '0.18271', '-0.92863', '0.5684',\n",
       "       '-0.43819', '0.70827', '-0.47459', '-0.079269', '1.0187', '0.2213',\n",
       "       '0.43073', '0.76719', '0.18774', '-0.49214', '-0.53063', '0.56379',\n",
       "       '0.63571', '0.64622', '1.2649', '-0.82901', '-1.3903', '0.3749',\n",
       "       '0.61316', '-1.5994', '1.3005', '0.64347', '-0.58004', '1.0372',\n",
       "       '-0.27156', '-0.43382', '0.8554', '-0.8967', '0.80176', '-0.33333',\n",
       "       '-0.17654', '-0.12277', '-0.70508', '-0.28412', '0.71149',\n",
       "       '-0.13487', '0.049514', '-0.8134', '0.34293', '1.0381'],\n",
       "      dtype='<U9')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove = load_glove_embeddings()\n",
    "glove['hey']\n",
    "# todo plot embeddings and show relations between words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Found 16276 unique tokens.\nShape of data tensor: (567, 100)\nShape of label tensor: (567,)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "maxlen = 100 \n",
    "# Cuts off reviews after 100 words\n",
    "training_samples = 450\n",
    "validation_samples = 117\n",
    "max_words = 10000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(corpus.articles)\n",
    "sequences = tokenizer.texts_to_sequences(corpus.articles)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "labels = np.asarray(corpus.tags)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "x_train= data[:training_samples]\n",
    "y_train= labels[:training_samples]\n",
    "x_val =data[training_samples: training_samples + validation_samples]\n",
    "y_val =labels[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}