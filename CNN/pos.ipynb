{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Readability Assessment throughConvolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Readability assessment is a well known problem in natural language processing field. Giving someone the suitable text for his level of comprehension (not so easy and not so hard) could maximize his understanding and enjoyment. In this notebook we are trying to assess the readability of a given text regardless of the text subject using recurrent neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Corpus\n",
    "> OneStopEnglish corpus: A new corpus for automatic readability assessment and text simplification  \n",
    "> Sowmya Vajjala and Ivana Lučić  \n",
    "> 2018  \n",
    "> Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications, pages 297–304. Association for Computational Linguistics.  \n",
    "> [url](http://aclweb.org/anthology/W18-0535). [bib file](https://aclanthology.coli.uni-saarland.de/papers/W18-0535/w18-0535.bib)\n",
    "\n",
    "Please cite the above paper if you use this corpus in your research.\n",
    "\n",
    "[![DOI](https://zenodo.org/badge/128919409.svg)](https://zenodo.org/badge/latestdoi/128919409)\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let's dive into our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ms10596/PycharmProjects/match\")\n",
    "from ipywidgets import interact\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from utils.loading import load_glove_embeddings\n",
    "from utils.one_stop_english import load_corpus, corpus_to_words, corpus_to_pos, detokenize\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, LSTM, Bidirectional,Conv1D,MaxPooling1D,GlobalMaxPooling1D, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "corpus = load_corpus()\n",
    "articles_words, tags = corpus_to_words(corpus)\n",
    "articles_pos, tags = corpus_to_pos(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Reading level|Avg. Num. Words|Std. Dev|Number of Articles\n",
    "---|---|---|---\n",
    "Elementary|533.17|103.79|189\n",
    "Intermediate|676.59|117.15|189\n",
    "Advanced|820.49|162.52|189\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323cc9e5b6634cdfa5b4dbbaa9f0a2b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=94, description='i', max=188), IntSlider(value=500, description='words',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def show_articles(i=(0,188,1), words=(0,1000,1)):\n",
    "    data = [\n",
    "        [\"Advanced\",detokenize(articles_words[i][:words])], \n",
    "        [\"Intermediate\",detokenize(articles_words[i+2][:words])], \n",
    "        [\"Elementary\",detokenize(articles_words[i+1][:words])]\n",
    "    ]\n",
    "    headers = ['Reading Level', 'Example']\n",
    "    display(HTML(tabulate(data,tablefmt='html', headers=headers)+\"<style>th,td {font-size: 10px}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When', 'you', 'see', 'the', 'word', 'Amazon', ',', 'whats', 'the', 'first']\n",
      "['WRB', 'PRP', 'VB', 'DT', 'NN', 'NN', ',', 'VBZ', 'DT', 'JJ']\n"
     ]
    }
   ],
   "source": [
    "print(articles_words[0][:10])\n",
    "print(articles_pos[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nn': 1, 'in': 2, 'dt': 3, 'jj': 4, 'nns': 5, 'nnp': 6, ',': 7, '.': 8, 'rb': 9, 'prp': 10, 'vb': 11, 'vbd': 12, 'cc': 13, 'vbz': 14, 'to': 15, 'vbp': 16, 'cd': 17, 'vbn': 18, 'vbg': 19, 'prp$': 20, 'md': 21, 'wdt': 22, 'wrb': 23, 'wp': 24, 'jjr': 25, 'rp': 26, ':': 27, 'jjs': 28, 'ex': 29, 'rbr': 30, 'nnps': 31, '-rrb-': 32, '-lrb-': 33, 'rbs': 34, 'pdt': 35, '$': 36, 'fw': 37, 'uh': 38, 'wp$': 39, 'sym': 40, \"''\": 41, 'ls': 42, 'pos': 43, '``': 44}\n"
     ]
    }
   ],
   "source": [
    "maxlen = 1000 # Cuts off reviews after 1000 words\n",
    "max_words = 45\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(articles_pos)\n",
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(567,)\n",
      "[23, 10, 11, 3, 1, 1, 7, 14, 3, 4, 1, 22, 14, 15, 11, 3, 4, 28, 1, 7, 3, 28, 1, 13, 3, 28, 1, 1, 13, 22, 16, 10, 16, 34, 4, 8, 3, 5, 16, 18, 15, 3, 1, 2, 3, 4, 7, 13, 9, 4, 7, 1, 2, 23, 15, 11, 3, 5, 2, 3, 1, 8, 6, 13, 6, 16, 18, 5, 15, 3, 1, 18, 2, 3, 6, 4, 1, 2, 3, 4, 4, 1, 2, 1, 27, 8, 11, 8, 3, 4, 1, 14, 18, 2, 20, 1, 15, 11, 3, 4, 1, 1, 19, 9, 8, 4, 32, 7, 13, 3, 6, 6, 5, 16, 3, 21, 11, 3, 1, 2, 3, 1, 1, 2, 4, 1, 7, 3, 1, 2, 4, 5, 13, 4, 4, 1, 14, 8, 9, 2, 5, 2, 4, 4, 5, 15, 5, 7, 19, 8, 6, 6, 8, 4, 7, 3, 1, 14, 15, 3, 1, 2, 5, 2, 3, 1, 13, 1, 2, 3, 1, 8, 2, 9, 7, 3, 5, 2, 4, 7, 4, 13, 4, 5, 2, 1, 12, 9, 4, 2, 3, 1, 1, 2, 8, 1, 14, 8, 1, 13, 17, 4, 5, 8, 13, 3, 5, 13, 4, 4, 5, 33, 5, 32, 2, 10, 16, 9, 18, 16, 2, 15, 11, 3, 28, 1, 2, 3, 1, 2, 3, 4, 1, 8, 3, 6, 6, 2, 6, 31, 13, 31, 33, 6, 32, 3, 4, 4, 1, 22, 14, 3, 4, 1, 2, 1, 1, 14, 18, 5, 33, 3, 9, 4, 9, 36, 17, 32, 2, 5, 2, 4, 5, 15, 11, 15, 3, 4, 17, 8, 6, 14, 18, 2, 5, 2, 4, 5, 7, 19, 8, 1, 14, 8, 1, 14, 8, 1, 11, 8, 11, 8, 13, 20, 34, 4, 1, 14, 2, 20, 4, 1, 8, 6, 13, 6, 16, 18, 2, 3, 8, 1, 1, 15, 11, 18, 7, 19, 3, 4, 1, 21, 9, 11, 18, 3, 1, 22, 14, 3, 4, 4, 1, 22, 14, 20, 5, 13, 14, 9, 18, 2, 4, 5, 13, 4, 5, 8, 19, 4, 5, 15, 11, 4, 5, 2, 5, 15, 11, 20, 1, 1, 13, 15, 11, 2, 3, 1, 2, 3, 5, 14, 9, 11, 7, 2, 20, 1, 7, 3, 4, 1, 7, 3, 4, 6, 2, 6, 13, 6, 12, 8, 6, 12, 20, 5, 12, 18, 4, 1, 2, 4, 5, 2, 3, 6, 6, 6, 33, 6, 7, 6, 7, 6, 7, 6, 7, 6, 13, 6, 32, 8, 5, 2, 4, 5, 16, 9, 18, 18, 2, 18, 4, 5, 22, 16, 4, 7, 4, 13, 4, 1, 5, 8, 6, 14, 18, 3, 1, 2, 20, 1, 2, 3, 6, 4, 1, 1, 7, 6, 7, 14, 19, 3, 1, 1, 22, 14, 18, 18, 9, 9, 2, 3, 1, 2, 4, 1, 22, 9, 14, 20, 4, 1, 8, 6, 14, 3, 8, 1, 1, 2, 3, 4, 4, 4, 1, 7, 3, 1, 14, 2, 3, 1, 8, 6, 14, 3, 4, 1, 2, 3, 4, 1, 2, 10, 14, 1, 7, 1, 7, 1, 13, 1, 5, 8, 10, 14, 9, 3, 1, 2, 3, 4, 4, 1, 13, 10, 14, 3, 4, 1, 1, 8, 30, 4, 7, 6, 14, 18, 3, 1, 8, 1, 7, 22, 14, 18, 2, 3, 1, 1, 2, 3, 4, 1, 8, 3, 5, 2, 6, 16, 3, 4, 1, 14, 15, 3, 1, 2, 6, 1, 7, 2, 10, 12, 9, 18, 9, 4, 2, 17, 33, 9, 2, 3, 1, 1, 12, 18, 32, 9, 2, 3, 4, 1, 21, 11, 2, 2, 3, 1, 2, 3, 4, 1, 18, 2, 3, 1, 7, 6, 6, 7, 2, 4, 1, 6, 6, 8, 2, 3, 1, 2, 6, 2, 6, 7, 31, 6, 6, 6, 3, 4, 1, 2, 4, 5, 2, 3, 1, 12, 3, 1, 2, 4, 5, 8, 10, 16, 18, 15, 11, 18, 9, 2, 3, 1, 2, 6, 2, 6, 8, 3, 4, 4, 1, 5, 21, 11, 2, 1, 2, 3, 1, 2, 17, 8]\n"
     ]
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(articles_pos)\n",
    "print(np.shape(sequences))\n",
    "print(sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23 10 11  3  1  1  7 14  3  4  1 22 14 15 11  3  4 28  1  7  3 28  1 13\n",
      "  3 28  1  1 13 22 16 10 16 34  4  8  3  5 16 18 15  3  1  2  3  4  7 13\n",
      "  9  4  7  1  2 23 15 11  3  5  2  3  1  8  6 13  6 16 18  5 15  3  1 18\n",
      "  2  3  6  4  1  2  3  4  4  1  2  1 27  8 11  8  3  4  1 14 18  2 20  1\n",
      " 15 11  3  4  1  1 19  9  8  4 32  7 13  3  6  6  5 16  3 21 11  3  1  2\n",
      "  3  1  1  2  4  1  7  3  1  2  4  5 13  4  4  1 14  8  9  2  5  2  4  4\n",
      "  5 15  5  7 19  8  6  6  8  4  7  3  1 14 15  3  1  2  5  2  3  1 13  1\n",
      "  2  3  1  8  2  9  7  3  5  2  4  7  4 13  4  5  2  1 12  9  4  2  3  1\n",
      "  1  2  8  1 14  8  1 13 17  4  5  8 13  3  5 13  4  4  5 33  5 32  2 10\n",
      " 16  9 18 16  2 15 11  3 28  1  2  3  1  2  3  4  1  8  3  6  6  2  6 31\n",
      " 13 31 33  6 32  3  4  4  1 22 14  3  4  1  2  1  1 14 18  5 33  3  9  4\n",
      "  9 36 17 32  2  5  2  4  5 15 11 15  3  4 17  8  6 14 18  2  5  2  4  5\n",
      "  7 19  8  1 14  8  1 14  8  1 11  8 11  8 13 20 34  4  1 14  2 20  4  1\n",
      "  8  6 13  6 16 18  2  3  8  1  1 15 11 18  7 19  3  4  1 21  9 11 18  3\n",
      "  1 22 14  3  4  4  1 22 14 20  5 13 14  9 18  2  4  5 13  4  5  8 19  4\n",
      "  5 15 11  4  5  2  5 15 11 20  1  1 13 15 11  2  3  1  2  3  5 14  9 11\n",
      "  7  2 20  1  7  3  4  1  7  3  4  6  2  6 13  6 12  8  6 12 20  5 12 18\n",
      "  4  1  2  4  5  2  3  6  6  6 33  6  7  6  7  6  7  6  7  6 13  6 32  8\n",
      "  5  2  4  5 16  9 18 18  2 18  4  5 22 16  4  7  4 13  4  1  5  8  6 14\n",
      " 18  3  1  2 20  1  2  3  6  4  1  1  7  6  7 14 19  3  1  1 22 14 18 18\n",
      "  9  9  2  3  1  2  4  1 22  9 14 20  4  1  8  6 14  3  8  1  1  2  3  4\n",
      "  4  4  1  7  3  1 14  2  3  1  8  6 14  3  4  1  2  3  4  1  2 10 14  1\n",
      "  7  1  7  1 13  1  5  8 10 14  9  3  1  2  3  4  4  1 13 10 14  3  4  1\n",
      "  1  8 30  4  7  6 14 18  3  1  8  1  7 22 14 18  2  3  1  1  2  3  4  1\n",
      "  8  3  5  2  6 16  3  4  1 14 15  3  1  2  6  1  7  2 10 12  9 18  9  4\n",
      "  2 17 33  9  2  3  1  1 12 18 32  9  2  3  4  1 21 11  2  2  3  1  2  3\n",
      "  4  1 18  2  3  1  7  6  6  7  2  4  1  6  6  8  2  3  1  2  6  2  6  7\n",
      " 31  6  6  6  3  4  1  2  4  5  2  3  1 12  3  1  2  4  5  8 10 16 18 15\n",
      " 11 18  9  2  3  1  2  6  2  6  8  3  4  4  1  5 21 11  2  1  2  3  1  2\n",
      " 17  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "(567, 1000)\n"
     ]
    }
   ],
   "source": [
    "data = pad_sequences(sequences, maxlen=maxlen, padding='post', truncating='post')\n",
    "print(data[0])\n",
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(567,)\n"
     ]
    }
   ],
   "source": [
    "print(tags[0])\n",
    "tags = np.array(tags)\n",
    "print(tags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(567, 1000, 45)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "data = to_categorical(data)\n",
    "print(data.shape)\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(567, 1000, 45)\n",
      "(567,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "tags = tags[indices]\n",
    "print(data.shape)\n",
    "print(tags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(128, 5, activation='relu',kernel_regularizer=l1_l2(l1=0.01, l2=0.0)))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(64, 5, activation='relu',kernel_regularizer=l1_l2(l1=0.007, l2=0.0)))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "# model.summary()\n",
    "def soft_acc(y_true, y_pred):\n",
    "    from tensorflow.python.keras import backend as K\n",
    "    return K.mean(K.equal(K.round(y_true), K.round(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 114 samples\n",
      "Epoch 1/1000\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 20.4785 - soft_acc: 0.3289 - val_loss: 16.9729 - val_soft_acc: 0.3246\n",
      "Epoch 2/1000\n",
      "453/453 [==============================] - 0s 616us/step - loss: 14.8087 - soft_acc: 0.3510 - val_loss: 12.6459 - val_soft_acc: 0.3246\n",
      "Epoch 3/1000\n",
      "453/453 [==============================] - 0s 610us/step - loss: 10.9078 - soft_acc: 0.3466 - val_loss: 8.9385 - val_soft_acc: 0.3070\n",
      "Epoch 4/1000\n",
      "453/453 [==============================] - 0s 610us/step - loss: 7.7048 - soft_acc: 0.3400 - val_loss: 6.2511 - val_soft_acc: 0.3070\n",
      "Epoch 5/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 5.2111 - soft_acc: 0.3400 - val_loss: 4.1260 - val_soft_acc: 0.3070\n",
      "Epoch 6/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 3.3232 - soft_acc: 0.3400 - val_loss: 2.5406 - val_soft_acc: 0.3070\n",
      "Epoch 7/1000\n",
      "453/453 [==============================] - 0s 619us/step - loss: 2.0908 - soft_acc: 0.3400 - val_loss: 1.9029 - val_soft_acc: 0.3070\n",
      "Epoch 8/1000\n",
      "453/453 [==============================] - 0s 622us/step - loss: 1.4714 - soft_acc: 0.3400 - val_loss: 1.3449 - val_soft_acc: 0.3070\n",
      "Epoch 9/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 1.2484 - soft_acc: 0.3400 - val_loss: 1.8125 - val_soft_acc: 0.3684\n",
      "Epoch 10/1000\n",
      "453/453 [==============================] - 0s 589us/step - loss: 1.2352 - soft_acc: 0.3554 - val_loss: 1.2612 - val_soft_acc: 0.3070\n",
      "Epoch 11/1000\n",
      "453/453 [==============================] - 0s 640us/step - loss: 1.1309 - soft_acc: 0.3400 - val_loss: 1.2142 - val_soft_acc: 0.3070\n",
      "Epoch 12/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 1.1111 - soft_acc: 0.3400 - val_loss: 1.1134 - val_soft_acc: 0.3070\n",
      "Epoch 13/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 1.0753 - soft_acc: 0.3400 - val_loss: 1.1455 - val_soft_acc: 0.3070\n",
      "Epoch 14/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 1.0801 - soft_acc: 0.3400 - val_loss: 1.3290 - val_soft_acc: 0.3333\n",
      "Epoch 15/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 1.0991 - soft_acc: 0.3444 - val_loss: 1.2192 - val_soft_acc: 0.3070\n",
      "Epoch 16/1000\n",
      "453/453 [==============================] - 0s 609us/step - loss: 1.0537 - soft_acc: 0.3400 - val_loss: 1.0700 - val_soft_acc: 0.3070\n",
      "Epoch 17/1000\n",
      "453/453 [==============================] - 0s 616us/step - loss: 1.0313 - soft_acc: 0.3400 - val_loss: 1.0424 - val_soft_acc: 0.3070\n",
      "Epoch 18/1000\n",
      "453/453 [==============================] - 0s 629us/step - loss: 1.0196 - soft_acc: 0.3400 - val_loss: 1.0873 - val_soft_acc: 0.3070\n",
      "Epoch 19/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 1.0097 - soft_acc: 0.3400 - val_loss: 1.2080 - val_soft_acc: 0.3070\n",
      "Epoch 20/1000\n",
      "453/453 [==============================] - 0s 615us/step - loss: 1.0305 - soft_acc: 0.3400 - val_loss: 1.0762 - val_soft_acc: 0.3070\n",
      "Epoch 21/1000\n",
      "453/453 [==============================] - 0s 612us/step - loss: 1.0053 - soft_acc: 0.3400 - val_loss: 1.1594 - val_soft_acc: 0.3070\n",
      "Epoch 22/1000\n",
      "453/453 [==============================] - 0s 612us/step - loss: 1.0221 - soft_acc: 0.3400 - val_loss: 1.0559 - val_soft_acc: 0.3070\n",
      "Epoch 23/1000\n",
      "453/453 [==============================] - 0s 610us/step - loss: 0.9966 - soft_acc: 0.3400 - val_loss: 1.1643 - val_soft_acc: 0.3070\n",
      "Epoch 24/1000\n",
      "453/453 [==============================] - 0s 614us/step - loss: 1.0049 - soft_acc: 0.3400 - val_loss: 1.0232 - val_soft_acc: 0.3070\n",
      "Epoch 25/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.9861 - soft_acc: 0.3400 - val_loss: 1.1241 - val_soft_acc: 0.3070\n",
      "Epoch 26/1000\n",
      "453/453 [==============================] - 0s 599us/step - loss: 0.9992 - soft_acc: 0.3400 - val_loss: 1.0195 - val_soft_acc: 0.3070\n",
      "Epoch 27/1000\n",
      "453/453 [==============================] - 0s 626us/step - loss: 0.9838 - soft_acc: 0.3400 - val_loss: 1.0278 - val_soft_acc: 0.3070\n",
      "Epoch 28/1000\n",
      "453/453 [==============================] - 0s 610us/step - loss: 0.9845 - soft_acc: 0.3400 - val_loss: 1.0996 - val_soft_acc: 0.3070\n",
      "Epoch 29/1000\n",
      "453/453 [==============================] - 0s 612us/step - loss: 0.9942 - soft_acc: 0.3400 - val_loss: 1.0441 - val_soft_acc: 0.3070\n",
      "Epoch 30/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 0.9851 - soft_acc: 0.3400 - val_loss: 1.0281 - val_soft_acc: 0.3070\n",
      "Epoch 31/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.9782 - soft_acc: 0.3400 - val_loss: 0.9983 - val_soft_acc: 0.3070\n",
      "Epoch 32/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.9869 - soft_acc: 0.3400 - val_loss: 1.0256 - val_soft_acc: 0.3070\n",
      "Epoch 33/1000\n",
      "453/453 [==============================] - 0s 610us/step - loss: 0.9752 - soft_acc: 0.3400 - val_loss: 1.0121 - val_soft_acc: 0.3070\n",
      "Epoch 34/1000\n",
      "453/453 [==============================] - 0s 610us/step - loss: 0.9735 - soft_acc: 0.3400 - val_loss: 1.0271 - val_soft_acc: 0.3070\n",
      "Epoch 35/1000\n",
      "453/453 [==============================] - 0s 615us/step - loss: 0.9797 - soft_acc: 0.3400 - val_loss: 1.0088 - val_soft_acc: 0.3070\n",
      "Epoch 36/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.9696 - soft_acc: 0.3400 - val_loss: 0.9879 - val_soft_acc: 0.3070\n",
      "Epoch 37/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.9660 - soft_acc: 0.3400 - val_loss: 1.0432 - val_soft_acc: 0.3070\n",
      "Epoch 38/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.9650 - soft_acc: 0.3400 - val_loss: 0.9969 - val_soft_acc: 0.3070\n",
      "Epoch 39/1000\n",
      "453/453 [==============================] - 0s 596us/step - loss: 0.9616 - soft_acc: 0.3400 - val_loss: 1.0149 - val_soft_acc: 0.3070\n",
      "Epoch 40/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.9662 - soft_acc: 0.3400 - val_loss: 1.0017 - val_soft_acc: 0.3070\n",
      "Epoch 41/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.9712 - soft_acc: 0.3400 - val_loss: 1.0021 - val_soft_acc: 0.3070\n",
      "Epoch 42/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.9607 - soft_acc: 0.3400 - val_loss: 0.9905 - val_soft_acc: 0.3070\n",
      "Epoch 43/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.9664 - soft_acc: 0.3400 - val_loss: 1.0435 - val_soft_acc: 0.3070\n",
      "Epoch 44/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.9707 - soft_acc: 0.3400 - val_loss: 1.0035 - val_soft_acc: 0.3070\n",
      "Epoch 45/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.9674 - soft_acc: 0.3400 - val_loss: 0.9971 - val_soft_acc: 0.3070\n",
      "Epoch 46/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.9598 - soft_acc: 0.3400 - val_loss: 1.0017 - val_soft_acc: 0.3070\n",
      "Epoch 47/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.9597 - soft_acc: 0.3400 - val_loss: 0.9837 - val_soft_acc: 0.3070\n",
      "Epoch 48/1000\n",
      "453/453 [==============================] - 0s 601us/step - loss: 0.9579 - soft_acc: 0.3400 - val_loss: 1.0117 - val_soft_acc: 0.3070\n",
      "Epoch 49/1000\n",
      "453/453 [==============================] - 0s 598us/step - loss: 0.9671 - soft_acc: 0.3400 - val_loss: 1.0057 - val_soft_acc: 0.3070\n",
      "Epoch 50/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.9609 - soft_acc: 0.3400 - val_loss: 0.9850 - val_soft_acc: 0.3070\n",
      "Epoch 51/1000\n",
      "453/453 [==============================] - 0s 594us/step - loss: 0.9603 - soft_acc: 0.3400 - val_loss: 0.9860 - val_soft_acc: 0.3070\n",
      "Epoch 52/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.9581 - soft_acc: 0.3400 - val_loss: 0.9975 - val_soft_acc: 0.3070\n",
      "Epoch 53/1000\n",
      "453/453 [==============================] - 0s 594us/step - loss: 0.9577 - soft_acc: 0.3400 - val_loss: 0.9842 - val_soft_acc: 0.3070\n",
      "Epoch 54/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.9577 - soft_acc: 0.3400 - val_loss: 1.0036 - val_soft_acc: 0.3070\n",
      "Epoch 55/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.9565 - soft_acc: 0.3400 - val_loss: 1.0099 - val_soft_acc: 0.3070\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 601us/step - loss: 0.9626 - soft_acc: 0.3400 - val_loss: 0.9994 - val_soft_acc: 0.3070\n",
      "Epoch 57/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.9587 - soft_acc: 0.3400 - val_loss: 0.9812 - val_soft_acc: 0.3070\n",
      "Epoch 58/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.9591 - soft_acc: 0.3400 - val_loss: 0.9966 - val_soft_acc: 0.3070\n",
      "Epoch 59/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.9553 - soft_acc: 0.3400 - val_loss: 0.9918 - val_soft_acc: 0.3070\n",
      "Epoch 60/1000\n",
      "453/453 [==============================] - 0s 610us/step - loss: 0.9547 - soft_acc: 0.3400 - val_loss: 0.9810 - val_soft_acc: 0.3070\n",
      "Epoch 61/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 0.9541 - soft_acc: 0.3400 - val_loss: 1.0204 - val_soft_acc: 0.3070\n",
      "Epoch 62/1000\n",
      "453/453 [==============================] - 0s 609us/step - loss: 0.9620 - soft_acc: 0.3400 - val_loss: 0.9864 - val_soft_acc: 0.3070\n",
      "Epoch 63/1000\n",
      "453/453 [==============================] - 0s 612us/step - loss: 0.9539 - soft_acc: 0.3400 - val_loss: 0.9791 - val_soft_acc: 0.3070\n",
      "Epoch 64/1000\n",
      "453/453 [==============================] - 0s 613us/step - loss: 0.9558 - soft_acc: 0.3400 - val_loss: 1.0000 - val_soft_acc: 0.3070\n",
      "Epoch 65/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.9551 - soft_acc: 0.3400 - val_loss: 0.9794 - val_soft_acc: 0.3070\n",
      "Epoch 66/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.9516 - soft_acc: 0.3400 - val_loss: 0.9847 - val_soft_acc: 0.3070\n",
      "Epoch 67/1000\n",
      "453/453 [==============================] - 0s 609us/step - loss: 0.9576 - soft_acc: 0.3400 - val_loss: 1.0063 - val_soft_acc: 0.3070\n",
      "Epoch 68/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.9564 - soft_acc: 0.3400 - val_loss: 0.9822 - val_soft_acc: 0.3070\n",
      "Epoch 69/1000\n",
      "453/453 [==============================] - 0s 601us/step - loss: 0.9567 - soft_acc: 0.3400 - val_loss: 1.0019 - val_soft_acc: 0.3070\n",
      "Epoch 70/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.9534 - soft_acc: 0.3400 - val_loss: 0.9796 - val_soft_acc: 0.3070\n",
      "Epoch 71/1000\n",
      "453/453 [==============================] - 0s 609us/step - loss: 0.9507 - soft_acc: 0.3400 - val_loss: 1.0030 - val_soft_acc: 0.3070\n",
      "Epoch 72/1000\n",
      "453/453 [==============================] - 0s 610us/step - loss: 0.9548 - soft_acc: 0.3400 - val_loss: 1.0141 - val_soft_acc: 0.3070\n",
      "Epoch 73/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.9604 - soft_acc: 0.3400 - val_loss: 0.9812 - val_soft_acc: 0.3070\n",
      "Epoch 74/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 0.9527 - soft_acc: 0.3400 - val_loss: 0.9819 - val_soft_acc: 0.3070\n",
      "Epoch 75/1000\n",
      "453/453 [==============================] - 0s 609us/step - loss: 0.9557 - soft_acc: 0.3400 - val_loss: 0.9778 - val_soft_acc: 0.3070\n",
      "Epoch 76/1000\n",
      "453/453 [==============================] - 0s 615us/step - loss: 0.9523 - soft_acc: 0.3400 - val_loss: 0.9816 - val_soft_acc: 0.3070\n",
      "Epoch 77/1000\n",
      "453/453 [==============================] - 0s 711us/step - loss: 0.9545 - soft_acc: 0.3400 - val_loss: 1.0052 - val_soft_acc: 0.3070\n",
      "Epoch 78/1000\n",
      "453/453 [==============================] - 0s 652us/step - loss: 0.9569 - soft_acc: 0.3400 - val_loss: 0.9775 - val_soft_acc: 0.3070\n",
      "Epoch 79/1000\n",
      "453/453 [==============================] - 0s 598us/step - loss: 0.9537 - soft_acc: 0.3400 - val_loss: 0.9774 - val_soft_acc: 0.3070\n",
      "Epoch 80/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.9504 - soft_acc: 0.3400 - val_loss: 0.9860 - val_soft_acc: 0.3070\n",
      "Epoch 81/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.9576 - soft_acc: 0.3400 - val_loss: 0.9955 - val_soft_acc: 0.3070\n",
      "Epoch 82/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.9516 - soft_acc: 0.3400 - val_loss: 0.9913 - val_soft_acc: 0.3070\n",
      "Epoch 83/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.9518 - soft_acc: 0.3400 - val_loss: 1.0101 - val_soft_acc: 0.3070\n",
      "Epoch 84/1000\n",
      "453/453 [==============================] - 0s 614us/step - loss: 0.9579 - soft_acc: 0.3400 - val_loss: 0.9774 - val_soft_acc: 0.3070\n",
      "Epoch 85/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.9520 - soft_acc: 0.3400 - val_loss: 0.9761 - val_soft_acc: 0.3070\n",
      "Epoch 86/1000\n",
      "453/453 [==============================] - 0s 643us/step - loss: 0.9513 - soft_acc: 0.3400 - val_loss: 0.9785 - val_soft_acc: 0.3070\n",
      "Epoch 87/1000\n",
      "453/453 [==============================] - 0s 599us/step - loss: 0.9495 - soft_acc: 0.3400 - val_loss: 0.9911 - val_soft_acc: 0.3070\n",
      "Epoch 88/1000\n",
      "453/453 [==============================] - 0s 562us/step - loss: 0.9513 - soft_acc: 0.3400 - val_loss: 0.9889 - val_soft_acc: 0.3070\n",
      "Epoch 89/1000\n",
      "453/453 [==============================] - 0s 568us/step - loss: 0.9508 - soft_acc: 0.3400 - val_loss: 0.9800 - val_soft_acc: 0.3070\n",
      "Epoch 90/1000\n",
      "453/453 [==============================] - 0s 560us/step - loss: 0.9513 - soft_acc: 0.3400 - val_loss: 0.9804 - val_soft_acc: 0.3070\n",
      "Epoch 91/1000\n",
      "453/453 [==============================] - 0s 629us/step - loss: 0.9484 - soft_acc: 0.3400 - val_loss: 0.9889 - val_soft_acc: 0.3070\n",
      "Epoch 92/1000\n",
      "453/453 [==============================] - 0s 609us/step - loss: 0.9513 - soft_acc: 0.3400 - val_loss: 0.9780 - val_soft_acc: 0.3070\n",
      "Epoch 93/1000\n",
      "453/453 [==============================] - 0s 642us/step - loss: 0.9524 - soft_acc: 0.3400 - val_loss: 0.9853 - val_soft_acc: 0.3070\n",
      "Epoch 94/1000\n",
      "453/453 [==============================] - 0s 577us/step - loss: 0.9494 - soft_acc: 0.3400 - val_loss: 0.9955 - val_soft_acc: 0.3070\n",
      "Epoch 95/1000\n",
      "453/453 [==============================] - 0s 582us/step - loss: 0.9532 - soft_acc: 0.3400 - val_loss: 0.9982 - val_soft_acc: 0.3070\n",
      "Epoch 96/1000\n",
      "453/453 [==============================] - 0s 567us/step - loss: 0.9564 - soft_acc: 0.3400 - val_loss: 0.9818 - val_soft_acc: 0.3070\n",
      "Epoch 97/1000\n",
      "453/453 [==============================] - 0s 653us/step - loss: 0.9546 - soft_acc: 0.3400 - val_loss: 0.9952 - val_soft_acc: 0.3070\n",
      "Epoch 98/1000\n",
      "453/453 [==============================] - 0s 629us/step - loss: 0.9541 - soft_acc: 0.3400 - val_loss: 0.9775 - val_soft_acc: 0.3070\n",
      "Epoch 99/1000\n",
      "453/453 [==============================] - 0s 588us/step - loss: 0.9511 - soft_acc: 0.3400 - val_loss: 0.9983 - val_soft_acc: 0.3070\n",
      "Epoch 100/1000\n",
      "453/453 [==============================] - 0s 581us/step - loss: 0.9515 - soft_acc: 0.3400 - val_loss: 0.9989 - val_soft_acc: 0.3070\n",
      "Epoch 101/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.9516 - soft_acc: 0.3400 - val_loss: 0.9828 - val_soft_acc: 0.3070\n",
      "Epoch 102/1000\n",
      "453/453 [==============================] - 0s 654us/step - loss: 0.9544 - soft_acc: 0.3400 - val_loss: 1.0019 - val_soft_acc: 0.3070\n",
      "Epoch 103/1000\n",
      "453/453 [==============================] - 0s 572us/step - loss: 0.9619 - soft_acc: 0.3400 - val_loss: 0.9798 - val_soft_acc: 0.3070\n",
      "Epoch 104/1000\n",
      "453/453 [==============================] - 0s 621us/step - loss: 0.9538 - soft_acc: 0.3400 - val_loss: 0.9966 - val_soft_acc: 0.3070\n",
      "Epoch 105/1000\n",
      "453/453 [==============================] - 0s 599us/step - loss: 0.9523 - soft_acc: 0.3400 - val_loss: 0.9777 - val_soft_acc: 0.3070\n",
      "Epoch 106/1000\n",
      "453/453 [==============================] - 0s 566us/step - loss: 0.9526 - soft_acc: 0.3400 - val_loss: 0.9812 - val_soft_acc: 0.3070\n",
      "Epoch 107/1000\n",
      "453/453 [==============================] - 0s 565us/step - loss: 0.9542 - soft_acc: 0.3400 - val_loss: 0.9826 - val_soft_acc: 0.3070\n",
      "Epoch 108/1000\n",
      "453/453 [==============================] - 0s 571us/step - loss: 0.9492 - soft_acc: 0.3400 - val_loss: 0.9834 - val_soft_acc: 0.3070\n",
      "Epoch 109/1000\n",
      "453/453 [==============================] - 0s 571us/step - loss: 0.9539 - soft_acc: 0.3400 - val_loss: 0.9779 - val_soft_acc: 0.3070\n",
      "Epoch 110/1000\n",
      "453/453 [==============================] - 0s 570us/step - loss: 0.9493 - soft_acc: 0.3400 - val_loss: 1.0078 - val_soft_acc: 0.3070\n",
      "Epoch 111/1000\n",
      "453/453 [==============================] - 0s 643us/step - loss: 0.9524 - soft_acc: 0.3400 - val_loss: 0.9903 - val_soft_acc: 0.3070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "453/453 [==============================] - 0s 621us/step - loss: 0.9496 - soft_acc: 0.3400 - val_loss: 0.9856 - val_soft_acc: 0.3070\n",
      "Epoch 113/1000\n",
      "453/453 [==============================] - 0s 646us/step - loss: 0.9571 - soft_acc: 0.3400 - val_loss: 0.9780 - val_soft_acc: 0.3070\n",
      "Epoch 114/1000\n",
      "453/453 [==============================] - 0s 588us/step - loss: 0.9500 - soft_acc: 0.3400 - val_loss: 0.9914 - val_soft_acc: 0.3070\n",
      "Epoch 115/1000\n",
      "453/453 [==============================] - 0s 571us/step - loss: 0.9505 - soft_acc: 0.3400 - val_loss: 0.9982 - val_soft_acc: 0.3070\n",
      "Epoch 116/1000\n",
      "453/453 [==============================] - 0s 573us/step - loss: 0.9498 - soft_acc: 0.3400 - val_loss: 0.9893 - val_soft_acc: 0.3070\n",
      "Epoch 117/1000\n",
      "453/453 [==============================] - 0s 579us/step - loss: 0.9509 - soft_acc: 0.3400 - val_loss: 0.9775 - val_soft_acc: 0.3070\n",
      "Epoch 118/1000\n",
      "453/453 [==============================] - 0s 568us/step - loss: 0.9557 - soft_acc: 0.3400 - val_loss: 0.9765 - val_soft_acc: 0.3070\n",
      "Epoch 119/1000\n",
      "453/453 [==============================] - 0s 573us/step - loss: 0.9514 - soft_acc: 0.3400 - val_loss: 0.9941 - val_soft_acc: 0.3070\n",
      "Epoch 120/1000\n",
      "453/453 [==============================] - 0s 565us/step - loss: 0.9525 - soft_acc: 0.3400 - val_loss: 0.9787 - val_soft_acc: 0.3070\n",
      "Epoch 121/1000\n",
      "453/453 [==============================] - 0s 576us/step - loss: 0.9474 - soft_acc: 0.3400 - val_loss: 0.9764 - val_soft_acc: 0.3070\n",
      "Epoch 122/1000\n",
      "453/453 [==============================] - 0s 567us/step - loss: 0.9490 - soft_acc: 0.3400 - val_loss: 0.9766 - val_soft_acc: 0.3070\n",
      "Epoch 123/1000\n",
      "453/453 [==============================] - 0s 571us/step - loss: 0.9493 - soft_acc: 0.3400 - val_loss: 0.9799 - val_soft_acc: 0.3070\n",
      "Epoch 124/1000\n",
      "453/453 [==============================] - 0s 574us/step - loss: 0.9500 - soft_acc: 0.3400 - val_loss: 0.9782 - val_soft_acc: 0.3070\n",
      "Epoch 125/1000\n",
      "453/453 [==============================] - 0s 567us/step - loss: 0.9493 - soft_acc: 0.3400 - val_loss: 1.0048 - val_soft_acc: 0.3070\n",
      "Epoch 126/1000\n",
      "453/453 [==============================] - 0s 579us/step - loss: 0.9527 - soft_acc: 0.3400 - val_loss: 0.9784 - val_soft_acc: 0.3070\n",
      "Epoch 127/1000\n",
      "453/453 [==============================] - 0s 582us/step - loss: 0.9509 - soft_acc: 0.3400 - val_loss: 1.0082 - val_soft_acc: 0.3070\n",
      "Epoch 128/1000\n",
      "453/453 [==============================] - 0s 629us/step - loss: 0.9557 - soft_acc: 0.3400 - val_loss: 0.9837 - val_soft_acc: 0.3070\n",
      "Epoch 129/1000\n",
      "453/453 [==============================] - 0s 631us/step - loss: 0.9493 - soft_acc: 0.3400 - val_loss: 0.9972 - val_soft_acc: 0.3070\n",
      "Epoch 130/1000\n",
      "453/453 [==============================] - 0s 576us/step - loss: 0.9542 - soft_acc: 0.3400 - val_loss: 0.9779 - val_soft_acc: 0.3070\n",
      "Epoch 131/1000\n",
      "453/453 [==============================] - 0s 599us/step - loss: 0.9507 - soft_acc: 0.3400 - val_loss: 0.9864 - val_soft_acc: 0.3070\n",
      "Epoch 132/1000\n",
      "453/453 [==============================] - 0s 635us/step - loss: 0.9490 - soft_acc: 0.3400 - val_loss: 0.9848 - val_soft_acc: 0.3070\n",
      "Epoch 133/1000\n",
      "453/453 [==============================] - 0s 616us/step - loss: 0.9484 - soft_acc: 0.3400 - val_loss: 0.9781 - val_soft_acc: 0.3070\n",
      "Epoch 134/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.9506 - soft_acc: 0.3400 - val_loss: 0.9763 - val_soft_acc: 0.3070\n",
      "Epoch 135/1000\n",
      "453/453 [==============================] - 0s 636us/step - loss: 0.9478 - soft_acc: 0.3400 - val_loss: 0.9854 - val_soft_acc: 0.3070\n",
      "Epoch 136/1000\n",
      "453/453 [==============================] - 0s 647us/step - loss: 0.9563 - soft_acc: 0.3400 - val_loss: 0.9758 - val_soft_acc: 0.3070\n",
      "Epoch 137/1000\n",
      "453/453 [==============================] - 0s 614us/step - loss: 0.9475 - soft_acc: 0.3400 - val_loss: 0.9761 - val_soft_acc: 0.3070\n",
      "Epoch 138/1000\n",
      "453/453 [==============================] - 0s 583us/step - loss: 0.9498 - soft_acc: 0.3400 - val_loss: 0.9876 - val_soft_acc: 0.3070\n",
      "Epoch 139/1000\n",
      "453/453 [==============================] - 0s 641us/step - loss: 0.9524 - soft_acc: 0.3400 - val_loss: 0.9789 - val_soft_acc: 0.3070\n",
      "Epoch 140/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.9489 - soft_acc: 0.3400 - val_loss: 0.9878 - val_soft_acc: 0.3070\n",
      "Epoch 141/1000\n",
      "453/453 [==============================] - 0s 582us/step - loss: 0.9491 - soft_acc: 0.3400 - val_loss: 0.9751 - val_soft_acc: 0.3070\n",
      "Epoch 142/1000\n",
      "453/453 [==============================] - 0s 572us/step - loss: 0.9494 - soft_acc: 0.3400 - val_loss: 0.9873 - val_soft_acc: 0.3070\n",
      "Epoch 143/1000\n",
      "453/453 [==============================] - 0s 589us/step - loss: 0.9479 - soft_acc: 0.3400 - val_loss: 1.0064 - val_soft_acc: 0.3070\n",
      "Epoch 144/1000\n",
      "453/453 [==============================] - 0s 642us/step - loss: 0.9519 - soft_acc: 0.3400 - val_loss: 0.9797 - val_soft_acc: 0.3070\n",
      "Epoch 145/1000\n",
      "453/453 [==============================] - 0s 633us/step - loss: 0.9483 - soft_acc: 0.3400 - val_loss: 0.9988 - val_soft_acc: 0.3070\n",
      "Epoch 146/1000\n",
      "453/453 [==============================] - 0s 614us/step - loss: 0.9497 - soft_acc: 0.3400 - val_loss: 0.9850 - val_soft_acc: 0.3070\n",
      "Epoch 147/1000\n",
      "453/453 [==============================] - 0s 591us/step - loss: 0.9472 - soft_acc: 0.3400 - val_loss: 0.9777 - val_soft_acc: 0.3070\n",
      "Epoch 148/1000\n",
      "453/453 [==============================] - 0s 575us/step - loss: 0.9464 - soft_acc: 0.3400 - val_loss: 0.9936 - val_soft_acc: 0.3070\n",
      "Epoch 149/1000\n",
      "453/453 [==============================] - 0s 635us/step - loss: 0.9485 - soft_acc: 0.3400 - val_loss: 0.9754 - val_soft_acc: 0.3070\n",
      "Epoch 150/1000\n",
      "453/453 [==============================] - 0s 622us/step - loss: 0.9484 - soft_acc: 0.3400 - val_loss: 0.9911 - val_soft_acc: 0.3070\n",
      "Epoch 151/1000\n",
      "453/453 [==============================] - 0s 575us/step - loss: 0.9492 - soft_acc: 0.3400 - val_loss: 0.9776 - val_soft_acc: 0.3070\n",
      "Epoch 152/1000\n",
      "453/453 [==============================] - 0s 569us/step - loss: 0.9479 - soft_acc: 0.3400 - val_loss: 1.0007 - val_soft_acc: 0.3070\n",
      "Epoch 153/1000\n",
      "453/453 [==============================] - 0s 569us/step - loss: 0.9473 - soft_acc: 0.3400 - val_loss: 0.9815 - val_soft_acc: 0.3070\n",
      "Epoch 154/1000\n",
      "453/453 [==============================] - 0s 575us/step - loss: 0.9514 - soft_acc: 0.3400 - val_loss: 0.9749 - val_soft_acc: 0.3070\n",
      "Epoch 155/1000\n",
      "453/453 [==============================] - 0s 567us/step - loss: 0.9491 - soft_acc: 0.3400 - val_loss: 0.9755 - val_soft_acc: 0.3070\n",
      "Epoch 156/1000\n",
      "453/453 [==============================] - 0s 572us/step - loss: 0.9458 - soft_acc: 0.3400 - val_loss: 0.9927 - val_soft_acc: 0.3070\n",
      "Epoch 157/1000\n",
      "453/453 [==============================] - 0s 627us/step - loss: 0.9447 - soft_acc: 0.3400 - val_loss: 0.9758 - val_soft_acc: 0.3070\n",
      "Epoch 158/1000\n",
      "453/453 [==============================] - 0s 614us/step - loss: 0.9438 - soft_acc: 0.3400 - val_loss: 0.9919 - val_soft_acc: 0.3070\n",
      "Epoch 159/1000\n",
      "453/453 [==============================] - 0s 609us/step - loss: 0.9496 - soft_acc: 0.3400 - val_loss: 0.9769 - val_soft_acc: 0.3070\n",
      "Epoch 160/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.9465 - soft_acc: 0.3400 - val_loss: 0.9730 - val_soft_acc: 0.3070\n",
      "Epoch 161/1000\n",
      "453/453 [==============================] - 0s 567us/step - loss: 0.9519 - soft_acc: 0.3400 - val_loss: 0.9741 - val_soft_acc: 0.3070\n",
      "Epoch 162/1000\n",
      "453/453 [==============================] - 0s 571us/step - loss: 0.9476 - soft_acc: 0.3400 - val_loss: 0.9756 - val_soft_acc: 0.3070\n",
      "Epoch 163/1000\n",
      "453/453 [==============================] - 0s 568us/step - loss: 0.9470 - soft_acc: 0.3400 - val_loss: 0.9745 - val_soft_acc: 0.3070\n",
      "Epoch 164/1000\n",
      "453/453 [==============================] - 0s 572us/step - loss: 0.9447 - soft_acc: 0.3400 - val_loss: 0.9843 - val_soft_acc: 0.3070\n",
      "Epoch 165/1000\n",
      "453/453 [==============================] - 0s 623us/step - loss: 0.9496 - soft_acc: 0.3400 - val_loss: 0.9743 - val_soft_acc: 0.3070\n",
      "Epoch 166/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.9447 - soft_acc: 0.3400 - val_loss: 0.9758 - val_soft_acc: 0.3070\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 572us/step - loss: 0.9469 - soft_acc: 0.3400 - val_loss: 0.9801 - val_soft_acc: 0.3070\n",
      "Epoch 168/1000\n",
      "453/453 [==============================] - 0s 586us/step - loss: 0.9443 - soft_acc: 0.3400 - val_loss: 1.0022 - val_soft_acc: 0.3070\n",
      "Epoch 169/1000\n",
      "453/453 [==============================] - 0s 626us/step - loss: 0.9482 - soft_acc: 0.3400 - val_loss: 0.9735 - val_soft_acc: 0.3070\n",
      "Epoch 170/1000\n",
      "453/453 [==============================] - 0s 645us/step - loss: 0.9435 - soft_acc: 0.3400 - val_loss: 0.9809 - val_soft_acc: 0.3070\n",
      "Epoch 171/1000\n",
      "453/453 [==============================] - 0s 645us/step - loss: 0.9497 - soft_acc: 0.3400 - val_loss: 0.9747 - val_soft_acc: 0.3070\n",
      "Epoch 172/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.9450 - soft_acc: 0.3400 - val_loss: 0.9848 - val_soft_acc: 0.3070\n",
      "Epoch 173/1000\n",
      "453/453 [==============================] - 0s 626us/step - loss: 0.9433 - soft_acc: 0.3400 - val_loss: 0.9745 - val_soft_acc: 0.3070\n",
      "Epoch 174/1000\n",
      "453/453 [==============================] - 0s 574us/step - loss: 0.9467 - soft_acc: 0.3400 - val_loss: 0.9731 - val_soft_acc: 0.3070\n",
      "Epoch 175/1000\n",
      "453/453 [==============================] - 0s 576us/step - loss: 0.9449 - soft_acc: 0.3400 - val_loss: 0.9855 - val_soft_acc: 0.3070\n",
      "Epoch 176/1000\n",
      "453/453 [==============================] - 0s 567us/step - loss: 0.9448 - soft_acc: 0.3400 - val_loss: 0.9735 - val_soft_acc: 0.3070\n",
      "Epoch 177/1000\n",
      "453/453 [==============================] - 0s 570us/step - loss: 0.9461 - soft_acc: 0.3400 - val_loss: 0.9870 - val_soft_acc: 0.3070\n",
      "Epoch 178/1000\n",
      "453/453 [==============================] - 0s 570us/step - loss: 0.9428 - soft_acc: 0.3400 - val_loss: 0.9728 - val_soft_acc: 0.3070\n",
      "Epoch 179/1000\n",
      "453/453 [==============================] - 0s 571us/step - loss: 0.9428 - soft_acc: 0.3400 - val_loss: 0.9752 - val_soft_acc: 0.3070\n",
      "Epoch 180/1000\n",
      "453/453 [==============================] - 0s 568us/step - loss: 0.9474 - soft_acc: 0.3400 - val_loss: 0.9768 - val_soft_acc: 0.3070\n",
      "Epoch 181/1000\n",
      "453/453 [==============================] - 0s 568us/step - loss: 0.9439 - soft_acc: 0.3400 - val_loss: 0.9722 - val_soft_acc: 0.3070\n",
      "Epoch 182/1000\n",
      "453/453 [==============================] - 0s 595us/step - loss: 0.9421 - soft_acc: 0.3400 - val_loss: 0.9883 - val_soft_acc: 0.3070\n",
      "Epoch 183/1000\n",
      "453/453 [==============================] - 0s 645us/step - loss: 0.9418 - soft_acc: 0.3400 - val_loss: 0.9735 - val_soft_acc: 0.3070\n",
      "Epoch 184/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 0.9421 - soft_acc: 0.3400 - val_loss: 0.9732 - val_soft_acc: 0.3070\n",
      "Epoch 185/1000\n",
      "453/453 [==============================] - 0s 572us/step - loss: 0.9410 - soft_acc: 0.3400 - val_loss: 0.9809 - val_soft_acc: 0.3070\n",
      "Epoch 186/1000\n",
      "453/453 [==============================] - 0s 575us/step - loss: 0.9404 - soft_acc: 0.3400 - val_loss: 0.9739 - val_soft_acc: 0.3070\n",
      "Epoch 187/1000\n",
      "453/453 [==============================] - 0s 575us/step - loss: 0.9420 - soft_acc: 0.3400 - val_loss: 0.9720 - val_soft_acc: 0.3070\n",
      "Epoch 188/1000\n",
      "453/453 [==============================] - 0s 567us/step - loss: 0.9439 - soft_acc: 0.3400 - val_loss: 0.9741 - val_soft_acc: 0.3070\n",
      "Epoch 189/1000\n",
      "453/453 [==============================] - 0s 577us/step - loss: 0.9407 - soft_acc: 0.3400 - val_loss: 0.9723 - val_soft_acc: 0.3070\n",
      "Epoch 190/1000\n",
      "453/453 [==============================] - 0s 574us/step - loss: 0.9388 - soft_acc: 0.3400 - val_loss: 0.9743 - val_soft_acc: 0.3070\n",
      "Epoch 191/1000\n",
      "453/453 [==============================] - 0s 571us/step - loss: 0.9412 - soft_acc: 0.3400 - val_loss: 0.9928 - val_soft_acc: 0.3070\n",
      "Epoch 192/1000\n",
      "453/453 [==============================] - 0s 573us/step - loss: 0.9394 - soft_acc: 0.3400 - val_loss: 0.9727 - val_soft_acc: 0.3070\n",
      "Epoch 193/1000\n",
      "453/453 [==============================] - 0s 637us/step - loss: 0.9411 - soft_acc: 0.3400 - val_loss: 0.9719 - val_soft_acc: 0.3070\n",
      "Epoch 194/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.9418 - soft_acc: 0.3400 - val_loss: 0.9835 - val_soft_acc: 0.3070\n",
      "Epoch 195/1000\n",
      "453/453 [==============================] - 0s 649us/step - loss: 0.9379 - soft_acc: 0.3400 - val_loss: 0.9874 - val_soft_acc: 0.3070\n",
      "Epoch 196/1000\n",
      "453/453 [==============================] - 0s 612us/step - loss: 0.9406 - soft_acc: 0.3400 - val_loss: 0.9876 - val_soft_acc: 0.3070\n",
      "Epoch 197/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.9403 - soft_acc: 0.3400 - val_loss: 0.9728 - val_soft_acc: 0.3070\n",
      "Epoch 198/1000\n",
      "453/453 [==============================] - 0s 646us/step - loss: 0.9403 - soft_acc: 0.3400 - val_loss: 0.9767 - val_soft_acc: 0.3070\n",
      "Epoch 199/1000\n",
      "453/453 [==============================] - 0s 617us/step - loss: 0.9364 - soft_acc: 0.3400 - val_loss: 0.9740 - val_soft_acc: 0.3070\n",
      "Epoch 200/1000\n",
      "453/453 [==============================] - 0s 631us/step - loss: 0.9379 - soft_acc: 0.3400 - val_loss: 0.9714 - val_soft_acc: 0.3070\n",
      "Epoch 201/1000\n",
      "453/453 [==============================] - 0s 638us/step - loss: 0.9413 - soft_acc: 0.3400 - val_loss: 0.9729 - val_soft_acc: 0.3070\n",
      "Epoch 202/1000\n",
      "453/453 [==============================] - 0s 627us/step - loss: 0.9362 - soft_acc: 0.3400 - val_loss: 0.9734 - val_soft_acc: 0.3070\n",
      "Epoch 203/1000\n",
      "453/453 [==============================] - 0s 653us/step - loss: 0.9353 - soft_acc: 0.3400 - val_loss: 1.0093 - val_soft_acc: 0.3070\n",
      "Epoch 204/1000\n",
      "453/453 [==============================] - 0s 633us/step - loss: 0.9396 - soft_acc: 0.3400 - val_loss: 0.9714 - val_soft_acc: 0.3070\n",
      "Epoch 205/1000\n",
      "453/453 [==============================] - 0s 638us/step - loss: 0.9384 - soft_acc: 0.3400 - val_loss: 0.9710 - val_soft_acc: 0.3070\n",
      "Epoch 206/1000\n",
      "453/453 [==============================] - 0s 643us/step - loss: 0.9354 - soft_acc: 0.3400 - val_loss: 0.9695 - val_soft_acc: 0.3070\n",
      "Epoch 207/1000\n",
      "453/453 [==============================] - 0s 636us/step - loss: 0.9348 - soft_acc: 0.3400 - val_loss: 0.9747 - val_soft_acc: 0.3070\n",
      "Epoch 208/1000\n",
      "453/453 [==============================] - 0s 648us/step - loss: 0.9366 - soft_acc: 0.3400 - val_loss: 0.9895 - val_soft_acc: 0.3070\n",
      "Epoch 209/1000\n",
      "453/453 [==============================] - 0s 642us/step - loss: 0.9371 - soft_acc: 0.3400 - val_loss: 0.9959 - val_soft_acc: 0.3070\n",
      "Epoch 210/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 0.9376 - soft_acc: 0.3400 - val_loss: 0.9684 - val_soft_acc: 0.3070\n",
      "Epoch 211/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.9328 - soft_acc: 0.3400 - val_loss: 0.9693 - val_soft_acc: 0.3070\n",
      "Epoch 212/1000\n",
      "453/453 [==============================] - 0s 630us/step - loss: 0.9318 - soft_acc: 0.3400 - val_loss: 0.9688 - val_soft_acc: 0.3070\n",
      "Epoch 213/1000\n",
      "453/453 [==============================] - 0s 623us/step - loss: 0.9338 - soft_acc: 0.3400 - val_loss: 0.9700 - val_soft_acc: 0.3070\n",
      "Epoch 214/1000\n",
      "453/453 [==============================] - 0s 626us/step - loss: 0.9345 - soft_acc: 0.3400 - val_loss: 0.9693 - val_soft_acc: 0.3070\n",
      "Epoch 215/1000\n",
      "453/453 [==============================] - 0s 593us/step - loss: 0.9344 - soft_acc: 0.3400 - val_loss: 0.9824 - val_soft_acc: 0.3070\n",
      "Epoch 216/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.9342 - soft_acc: 0.3400 - val_loss: 0.9685 - val_soft_acc: 0.3070\n",
      "Epoch 217/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.9303 - soft_acc: 0.3400 - val_loss: 0.9687 - val_soft_acc: 0.3070\n",
      "Epoch 218/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.9335 - soft_acc: 0.3400 - val_loss: 0.9677 - val_soft_acc: 0.3070\n",
      "Epoch 219/1000\n",
      "453/453 [==============================] - 0s 601us/step - loss: 0.9335 - soft_acc: 0.3400 - val_loss: 0.9658 - val_soft_acc: 0.3070\n",
      "Epoch 220/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.9300 - soft_acc: 0.3400 - val_loss: 0.9680 - val_soft_acc: 0.3070\n",
      "Epoch 221/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.9288 - soft_acc: 0.3400 - val_loss: 0.9677 - val_soft_acc: 0.3070\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 606us/step - loss: 0.9301 - soft_acc: 0.3400 - val_loss: 0.9842 - val_soft_acc: 0.3070\n",
      "Epoch 223/1000\n",
      "453/453 [==============================] - 0s 610us/step - loss: 0.9313 - soft_acc: 0.3400 - val_loss: 0.9686 - val_soft_acc: 0.3070\n",
      "Epoch 224/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.9274 - soft_acc: 0.3400 - val_loss: 0.9747 - val_soft_acc: 0.3070\n",
      "Epoch 225/1000\n",
      "453/453 [==============================] - 0s 615us/step - loss: 0.9399 - soft_acc: 0.3400 - val_loss: 0.9659 - val_soft_acc: 0.3070\n",
      "Epoch 226/1000\n",
      "453/453 [==============================] - 0s 610us/step - loss: 0.9313 - soft_acc: 0.3400 - val_loss: 0.9645 - val_soft_acc: 0.3070\n",
      "Epoch 227/1000\n",
      "453/453 [==============================] - 0s 612us/step - loss: 0.9268 - soft_acc: 0.3400 - val_loss: 0.9643 - val_soft_acc: 0.3070\n",
      "Epoch 228/1000\n",
      "453/453 [==============================] - 0s 636us/step - loss: 0.9276 - soft_acc: 0.3400 - val_loss: 0.9765 - val_soft_acc: 0.3070\n",
      "Epoch 229/1000\n",
      "453/453 [==============================] - 0s 632us/step - loss: 0.9305 - soft_acc: 0.3400 - val_loss: 0.9812 - val_soft_acc: 0.3070\n",
      "Epoch 230/1000\n",
      "453/453 [==============================] - 0s 619us/step - loss: 0.9284 - soft_acc: 0.3400 - val_loss: 0.9663 - val_soft_acc: 0.3070\n",
      "Epoch 231/1000\n",
      "453/453 [==============================] - 0s 622us/step - loss: 0.9297 - soft_acc: 0.3400 - val_loss: 0.9634 - val_soft_acc: 0.3070\n",
      "Epoch 232/1000\n",
      "453/453 [==============================] - 0s 651us/step - loss: 0.9258 - soft_acc: 0.3400 - val_loss: 0.9739 - val_soft_acc: 0.3070\n",
      "Epoch 233/1000\n",
      "453/453 [==============================] - 0s 635us/step - loss: 0.9254 - soft_acc: 0.3400 - val_loss: 0.9640 - val_soft_acc: 0.3070\n",
      "Epoch 234/1000\n",
      "453/453 [==============================] - 0s 629us/step - loss: 0.9255 - soft_acc: 0.3400 - val_loss: 0.9671 - val_soft_acc: 0.3070\n",
      "Epoch 235/1000\n",
      "453/453 [==============================] - 0s 623us/step - loss: 0.9283 - soft_acc: 0.3400 - val_loss: 0.9732 - val_soft_acc: 0.3070\n",
      "Epoch 236/1000\n",
      "453/453 [==============================] - 0s 625us/step - loss: 0.9253 - soft_acc: 0.3400 - val_loss: 0.9645 - val_soft_acc: 0.3070\n",
      "Epoch 237/1000\n",
      "453/453 [==============================] - 0s 644us/step - loss: 0.9253 - soft_acc: 0.3400 - val_loss: 0.9645 - val_soft_acc: 0.3070\n",
      "Epoch 238/1000\n",
      "453/453 [==============================] - 0s 615us/step - loss: 0.9270 - soft_acc: 0.3400 - val_loss: 0.9747 - val_soft_acc: 0.3070\n",
      "Epoch 239/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.9256 - soft_acc: 0.3400 - val_loss: 0.9632 - val_soft_acc: 0.3070\n",
      "Epoch 240/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.9226 - soft_acc: 0.3400 - val_loss: 0.9809 - val_soft_acc: 0.3070\n",
      "Epoch 241/1000\n",
      "453/453 [==============================] - 0s 636us/step - loss: 0.9240 - soft_acc: 0.3400 - val_loss: 0.9739 - val_soft_acc: 0.3070\n",
      "Epoch 242/1000\n",
      "453/453 [==============================] - 0s 622us/step - loss: 0.9232 - soft_acc: 0.3400 - val_loss: 0.9637 - val_soft_acc: 0.3070\n",
      "Epoch 243/1000\n",
      "453/453 [==============================] - 0s 629us/step - loss: 0.9220 - soft_acc: 0.3400 - val_loss: 0.9620 - val_soft_acc: 0.3070\n",
      "Epoch 244/1000\n",
      "453/453 [==============================] - 0s 622us/step - loss: 0.9220 - soft_acc: 0.3400 - val_loss: 0.9681 - val_soft_acc: 0.3070\n",
      "Epoch 245/1000\n",
      "453/453 [==============================] - 0s 612us/step - loss: 0.9250 - soft_acc: 0.3400 - val_loss: 0.9730 - val_soft_acc: 0.3070\n",
      "Epoch 246/1000\n",
      "453/453 [==============================] - 0s 610us/step - loss: 0.9214 - soft_acc: 0.3400 - val_loss: 0.9661 - val_soft_acc: 0.3070\n",
      "Epoch 247/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.9254 - soft_acc: 0.3400 - val_loss: 0.9802 - val_soft_acc: 0.3070\n",
      "Epoch 248/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.9237 - soft_acc: 0.3400 - val_loss: 0.9646 - val_soft_acc: 0.3070\n",
      "Epoch 249/1000\n",
      "453/453 [==============================] - 0s 593us/step - loss: 0.9192 - soft_acc: 0.3400 - val_loss: 0.9673 - val_soft_acc: 0.3070\n",
      "Epoch 250/1000\n",
      "453/453 [==============================] - 0s 609us/step - loss: 0.9202 - soft_acc: 0.3400 - val_loss: 0.9643 - val_soft_acc: 0.3070\n",
      "Epoch 251/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.9206 - soft_acc: 0.3400 - val_loss: 0.9773 - val_soft_acc: 0.3070\n",
      "Epoch 252/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.9196 - soft_acc: 0.3400 - val_loss: 0.9628 - val_soft_acc: 0.3070\n",
      "Epoch 253/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.9199 - soft_acc: 0.3400 - val_loss: 0.9624 - val_soft_acc: 0.3070\n",
      "Epoch 254/1000\n",
      "453/453 [==============================] - 0s 610us/step - loss: 0.9186 - soft_acc: 0.3400 - val_loss: 0.9694 - val_soft_acc: 0.3070\n",
      "Epoch 255/1000\n",
      "453/453 [==============================] - 0s 628us/step - loss: 0.9174 - soft_acc: 0.3400 - val_loss: 0.9659 - val_soft_acc: 0.3070\n",
      "Epoch 256/1000\n",
      "453/453 [==============================] - 0s 624us/step - loss: 0.9207 - soft_acc: 0.3400 - val_loss: 0.9954 - val_soft_acc: 0.3070\n",
      "Epoch 257/1000\n",
      "453/453 [==============================] - 0s 627us/step - loss: 0.9194 - soft_acc: 0.3400 - val_loss: 0.9636 - val_soft_acc: 0.3070\n",
      "Epoch 258/1000\n",
      "453/453 [==============================] - 0s 628us/step - loss: 0.9204 - soft_acc: 0.3400 - val_loss: 0.9600 - val_soft_acc: 0.3070\n",
      "Epoch 259/1000\n",
      "453/453 [==============================] - 0s 630us/step - loss: 0.9176 - soft_acc: 0.3400 - val_loss: 0.9598 - val_soft_acc: 0.3070\n",
      "Epoch 260/1000\n",
      "453/453 [==============================] - 0s 595us/step - loss: 0.9150 - soft_acc: 0.3400 - val_loss: 0.9624 - val_soft_acc: 0.3070\n",
      "Epoch 261/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.9197 - soft_acc: 0.3400 - val_loss: 0.9643 - val_soft_acc: 0.3070\n",
      "Epoch 262/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.9167 - soft_acc: 0.3400 - val_loss: 0.9661 - val_soft_acc: 0.3070\n",
      "Epoch 263/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.9234 - soft_acc: 0.3400 - val_loss: 0.9640 - val_soft_acc: 0.3070\n",
      "Epoch 264/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.9209 - soft_acc: 0.3400 - val_loss: 0.9631 - val_soft_acc: 0.3070\n",
      "Epoch 265/1000\n",
      "453/453 [==============================] - 0s 619us/step - loss: 0.9218 - soft_acc: 0.3400 - val_loss: 0.9795 - val_soft_acc: 0.3070\n",
      "Epoch 266/1000\n",
      "453/453 [==============================] - 0s 623us/step - loss: 0.9155 - soft_acc: 0.3400 - val_loss: 0.9616 - val_soft_acc: 0.3070\n",
      "Epoch 267/1000\n",
      "453/453 [==============================] - 0s 623us/step - loss: 0.9182 - soft_acc: 0.3400 - val_loss: 0.9600 - val_soft_acc: 0.3070\n",
      "Epoch 268/1000\n",
      "453/453 [==============================] - 0s 625us/step - loss: 0.9121 - soft_acc: 0.3400 - val_loss: 0.9587 - val_soft_acc: 0.3070\n",
      "Epoch 269/1000\n",
      "453/453 [==============================] - 0s 624us/step - loss: 0.9136 - soft_acc: 0.3400 - val_loss: 0.9819 - val_soft_acc: 0.3070\n",
      "Epoch 270/1000\n",
      "453/453 [==============================] - 0s 625us/step - loss: 0.9134 - soft_acc: 0.3400 - val_loss: 0.9724 - val_soft_acc: 0.3070\n",
      "Epoch 271/1000\n",
      "453/453 [==============================] - 0s 617us/step - loss: 0.9145 - soft_acc: 0.3400 - val_loss: 0.9576 - val_soft_acc: 0.3070\n",
      "Epoch 272/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.9116 - soft_acc: 0.3400 - val_loss: 0.9797 - val_soft_acc: 0.3070\n",
      "Epoch 273/1000\n",
      "453/453 [==============================] - 0s 601us/step - loss: 0.9123 - soft_acc: 0.3400 - val_loss: 0.9612 - val_soft_acc: 0.3070\n",
      "Epoch 274/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.9141 - soft_acc: 0.3400 - val_loss: 0.9785 - val_soft_acc: 0.3070\n",
      "Epoch 275/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.9121 - soft_acc: 0.3400 - val_loss: 0.9570 - val_soft_acc: 0.3070\n",
      "Epoch 276/1000\n",
      "453/453 [==============================] - 0s 630us/step - loss: 0.9145 - soft_acc: 0.3400 - val_loss: 0.9633 - val_soft_acc: 0.3070\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 623us/step - loss: 0.9149 - soft_acc: 0.3400 - val_loss: 0.9662 - val_soft_acc: 0.3070\n",
      "Epoch 278/1000\n",
      "453/453 [==============================] - 0s 622us/step - loss: 0.9154 - soft_acc: 0.3400 - val_loss: 0.9599 - val_soft_acc: 0.3070\n",
      "Epoch 279/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.9082 - soft_acc: 0.3400 - val_loss: 0.9586 - val_soft_acc: 0.3070\n",
      "Epoch 280/1000\n",
      "453/453 [==============================] - 0s 613us/step - loss: 0.9081 - soft_acc: 0.3400 - val_loss: 0.9769 - val_soft_acc: 0.3070\n",
      "Epoch 281/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.9098 - soft_acc: 0.3400 - val_loss: 0.9635 - val_soft_acc: 0.3070\n",
      "Epoch 282/1000\n",
      "453/453 [==============================] - 0s 614us/step - loss: 0.9091 - soft_acc: 0.3400 - val_loss: 0.9643 - val_soft_acc: 0.3070\n",
      "Epoch 283/1000\n",
      "453/453 [==============================] - 0s 614us/step - loss: 0.9112 - soft_acc: 0.3400 - val_loss: 0.9614 - val_soft_acc: 0.3158\n",
      "Epoch 284/1000\n",
      "453/453 [==============================] - 0s 601us/step - loss: 0.9061 - soft_acc: 0.3422 - val_loss: 0.9632 - val_soft_acc: 0.3070\n",
      "Epoch 285/1000\n",
      "453/453 [==============================] - 0s 612us/step - loss: 0.9097 - soft_acc: 0.3400 - val_loss: 0.9748 - val_soft_acc: 0.3070\n",
      "Epoch 286/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.9099 - soft_acc: 0.3400 - val_loss: 0.9664 - val_soft_acc: 0.3158\n",
      "Epoch 287/1000\n",
      "453/453 [==============================] - 0s 619us/step - loss: 0.9084 - soft_acc: 0.3377 - val_loss: 0.9788 - val_soft_acc: 0.3070\n",
      "Epoch 288/1000\n",
      "453/453 [==============================] - 0s 599us/step - loss: 0.9055 - soft_acc: 0.3400 - val_loss: 0.9633 - val_soft_acc: 0.3070\n",
      "Epoch 289/1000\n",
      "453/453 [==============================] - 0s 612us/step - loss: 0.9059 - soft_acc: 0.3400 - val_loss: 0.9572 - val_soft_acc: 0.3070\n",
      "Epoch 290/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.9039 - soft_acc: 0.3400 - val_loss: 0.9576 - val_soft_acc: 0.3070\n",
      "Epoch 291/1000\n",
      "453/453 [==============================] - 0s 612us/step - loss: 0.9026 - soft_acc: 0.3400 - val_loss: 0.9577 - val_soft_acc: 0.3070\n",
      "Epoch 292/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.9025 - soft_acc: 0.3422 - val_loss: 0.9602 - val_soft_acc: 0.3158\n",
      "Epoch 293/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.9045 - soft_acc: 0.3400 - val_loss: 0.9590 - val_soft_acc: 0.3070\n",
      "Epoch 294/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.8985 - soft_acc: 0.3422 - val_loss: 0.9605 - val_soft_acc: 0.3070\n",
      "Epoch 295/1000\n",
      "453/453 [==============================] - 0s 612us/step - loss: 0.8989 - soft_acc: 0.3377 - val_loss: 0.9623 - val_soft_acc: 0.3158\n",
      "Epoch 296/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.8992 - soft_acc: 0.3400 - val_loss: 0.9967 - val_soft_acc: 0.3158\n",
      "Epoch 297/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.9062 - soft_acc: 0.3422 - val_loss: 0.9872 - val_soft_acc: 0.3158\n",
      "Epoch 298/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.9010 - soft_acc: 0.3422 - val_loss: 0.9665 - val_soft_acc: 0.3070\n",
      "Epoch 299/1000\n",
      "453/453 [==============================] - 0s 609us/step - loss: 0.8986 - soft_acc: 0.3400 - val_loss: 0.9700 - val_soft_acc: 0.3070\n",
      "Epoch 300/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.9008 - soft_acc: 0.3400 - val_loss: 0.9581 - val_soft_acc: 0.3070\n",
      "Epoch 301/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.8973 - soft_acc: 0.3377 - val_loss: 0.9615 - val_soft_acc: 0.3158\n",
      "Epoch 302/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 0.8974 - soft_acc: 0.3444 - val_loss: 0.9589 - val_soft_acc: 0.3158\n",
      "Epoch 303/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.8969 - soft_acc: 0.3444 - val_loss: 0.9653 - val_soft_acc: 0.3070\n",
      "Epoch 304/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.9008 - soft_acc: 0.3400 - val_loss: 0.9625 - val_soft_acc: 0.3070\n",
      "Epoch 305/1000\n",
      "453/453 [==============================] - 0s 609us/step - loss: 0.8956 - soft_acc: 0.3422 - val_loss: 0.9724 - val_soft_acc: 0.3158\n",
      "Epoch 306/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.8981 - soft_acc: 0.3466 - val_loss: 0.9614 - val_soft_acc: 0.3158\n",
      "Epoch 307/1000\n",
      "453/453 [==============================] - 0s 624us/step - loss: 0.8944 - soft_acc: 0.3444 - val_loss: 0.9748 - val_soft_acc: 0.3158\n",
      "Epoch 308/1000\n",
      "453/453 [==============================] - 0s 634us/step - loss: 0.8971 - soft_acc: 0.3444 - val_loss: 0.9635 - val_soft_acc: 0.3070\n",
      "Epoch 309/1000\n",
      "453/453 [==============================] - 0s 626us/step - loss: 0.8958 - soft_acc: 0.3466 - val_loss: 1.0211 - val_soft_acc: 0.3246\n",
      "Epoch 310/1000\n",
      "453/453 [==============================] - 0s 629us/step - loss: 0.9007 - soft_acc: 0.3554 - val_loss: 0.9602 - val_soft_acc: 0.3246\n",
      "Epoch 311/1000\n",
      "453/453 [==============================] - 0s 612us/step - loss: 0.8895 - soft_acc: 0.3444 - val_loss: 0.9597 - val_soft_acc: 0.3158\n",
      "Epoch 312/1000\n",
      "453/453 [==============================] - 0s 637us/step - loss: 0.8870 - soft_acc: 0.3466 - val_loss: 0.9535 - val_soft_acc: 0.3158\n",
      "Epoch 313/1000\n",
      "453/453 [==============================] - 0s 658us/step - loss: 0.8853 - soft_acc: 0.3466 - val_loss: 0.9688 - val_soft_acc: 0.3246\n",
      "Epoch 314/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.8956 - soft_acc: 0.3466 - val_loss: 0.9568 - val_soft_acc: 0.3246\n",
      "Epoch 315/1000\n",
      "453/453 [==============================] - 0s 631us/step - loss: 0.8862 - soft_acc: 0.3532 - val_loss: 0.9578 - val_soft_acc: 0.3246\n",
      "Epoch 316/1000\n",
      "453/453 [==============================] - 0s 601us/step - loss: 0.8857 - soft_acc: 0.3532 - val_loss: 0.9516 - val_soft_acc: 0.3246\n",
      "Epoch 317/1000\n",
      "453/453 [==============================] - 0s 664us/step - loss: 0.8839 - soft_acc: 0.3488 - val_loss: 0.9768 - val_soft_acc: 0.3070\n",
      "Epoch 318/1000\n",
      "453/453 [==============================] - 0s 614us/step - loss: 0.8800 - soft_acc: 0.3576 - val_loss: 0.9586 - val_soft_acc: 0.3158\n",
      "Epoch 319/1000\n",
      "453/453 [==============================] - 0s 622us/step - loss: 0.8740 - soft_acc: 0.3554 - val_loss: 0.9724 - val_soft_acc: 0.3070\n",
      "Epoch 320/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.8799 - soft_acc: 0.3554 - val_loss: 0.9433 - val_soft_acc: 0.3333\n",
      "Epoch 321/1000\n",
      "453/453 [==============================] - 0s 601us/step - loss: 0.8702 - soft_acc: 0.3576 - val_loss: 0.9459 - val_soft_acc: 0.3246\n",
      "Epoch 322/1000\n",
      "453/453 [==============================] - 0s 601us/step - loss: 0.8671 - soft_acc: 0.3620 - val_loss: 0.9806 - val_soft_acc: 0.3246\n",
      "Epoch 323/1000\n",
      "453/453 [==============================] - 0s 595us/step - loss: 0.8796 - soft_acc: 0.3642 - val_loss: 0.9745 - val_soft_acc: 0.3333\n",
      "Epoch 324/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.8807 - soft_acc: 0.3466 - val_loss: 0.9570 - val_soft_acc: 0.3158\n",
      "Epoch 325/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.8604 - soft_acc: 0.3731 - val_loss: 0.9375 - val_soft_acc: 0.3421\n",
      "Epoch 326/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.8576 - soft_acc: 0.3642 - val_loss: 0.9724 - val_soft_acc: 0.3333\n",
      "Epoch 327/1000\n",
      "453/453 [==============================] - 0s 610us/step - loss: 0.8557 - soft_acc: 0.3841 - val_loss: 0.9560 - val_soft_acc: 0.3333\n",
      "Epoch 328/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.8478 - soft_acc: 0.3841 - val_loss: 0.9480 - val_soft_acc: 0.3421\n",
      "Epoch 329/1000\n",
      "453/453 [==============================] - 0s 595us/step - loss: 0.8411 - soft_acc: 0.3863 - val_loss: 0.9186 - val_soft_acc: 0.3596\n",
      "Epoch 330/1000\n",
      "453/453 [==============================] - 0s 598us/step - loss: 0.8325 - soft_acc: 0.4062 - val_loss: 0.9228 - val_soft_acc: 0.4035\n",
      "Epoch 331/1000\n",
      "453/453 [==============================] - 0s 598us/step - loss: 0.8317 - soft_acc: 0.4084 - val_loss: 0.9259 - val_soft_acc: 0.4123\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 603us/step - loss: 0.8290 - soft_acc: 0.4305 - val_loss: 0.9373 - val_soft_acc: 0.4123\n",
      "Epoch 333/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.8209 - soft_acc: 0.4260 - val_loss: 0.9094 - val_soft_acc: 0.3596\n",
      "Epoch 334/1000\n",
      "453/453 [==============================] - 0s 609us/step - loss: 0.8150 - soft_acc: 0.4305 - val_loss: 0.9212 - val_soft_acc: 0.3684\n",
      "Epoch 335/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.8142 - soft_acc: 0.4437 - val_loss: 0.8996 - val_soft_acc: 0.3860\n",
      "Epoch 336/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.8101 - soft_acc: 0.4636 - val_loss: 0.9479 - val_soft_acc: 0.4211\n",
      "Epoch 337/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.8137 - soft_acc: 0.4570 - val_loss: 0.9194 - val_soft_acc: 0.3947\n",
      "Epoch 338/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.8068 - soft_acc: 0.4724 - val_loss: 0.9697 - val_soft_acc: 0.4035\n",
      "Epoch 339/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.8189 - soft_acc: 0.4658 - val_loss: 0.8929 - val_soft_acc: 0.4123\n",
      "Epoch 340/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 0.8026 - soft_acc: 0.4790 - val_loss: 0.9292 - val_soft_acc: 0.4211\n",
      "Epoch 341/1000\n",
      "453/453 [==============================] - 0s 601us/step - loss: 0.8001 - soft_acc: 0.4768 - val_loss: 0.9092 - val_soft_acc: 0.4298\n",
      "Epoch 342/1000\n",
      "453/453 [==============================] - 0s 610us/step - loss: 0.7979 - soft_acc: 0.4857 - val_loss: 0.9363 - val_soft_acc: 0.4298\n",
      "Epoch 343/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.8089 - soft_acc: 0.4857 - val_loss: 0.9002 - val_soft_acc: 0.4123\n",
      "Epoch 344/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.7905 - soft_acc: 0.4790 - val_loss: 0.9350 - val_soft_acc: 0.4474\n",
      "Epoch 345/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.7979 - soft_acc: 0.4834 - val_loss: 0.8974 - val_soft_acc: 0.4298\n",
      "Epoch 346/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.7855 - soft_acc: 0.4945 - val_loss: 0.9079 - val_soft_acc: 0.4298\n",
      "Epoch 347/1000\n",
      "453/453 [==============================] - 0s 609us/step - loss: 0.7912 - soft_acc: 0.4879 - val_loss: 0.9061 - val_soft_acc: 0.4649\n",
      "Epoch 348/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.7860 - soft_acc: 0.4945 - val_loss: 0.9439 - val_soft_acc: 0.4737\n",
      "Epoch 349/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.7875 - soft_acc: 0.5099 - val_loss: 0.9321 - val_soft_acc: 0.4737\n",
      "Epoch 350/1000\n",
      "453/453 [==============================] - 0s 612us/step - loss: 0.7886 - soft_acc: 0.5143 - val_loss: 0.9103 - val_soft_acc: 0.4825\n",
      "Epoch 351/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.7859 - soft_acc: 0.4945 - val_loss: 0.9001 - val_soft_acc: 0.4298\n",
      "Epoch 352/1000\n",
      "453/453 [==============================] - 0s 613us/step - loss: 0.7806 - soft_acc: 0.5077 - val_loss: 0.9056 - val_soft_acc: 0.4737\n",
      "Epoch 353/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.7785 - soft_acc: 0.5077 - val_loss: 0.9240 - val_soft_acc: 0.4825\n",
      "Epoch 354/1000\n",
      "453/453 [==============================] - 0s 609us/step - loss: 0.7800 - soft_acc: 0.4879 - val_loss: 0.9032 - val_soft_acc: 0.4123\n",
      "Epoch 355/1000\n",
      "453/453 [==============================] - 0s 681us/step - loss: 0.7759 - soft_acc: 0.5077 - val_loss: 0.9010 - val_soft_acc: 0.4123\n",
      "Epoch 356/1000\n",
      "453/453 [==============================] - 0s 639us/step - loss: 0.7725 - soft_acc: 0.5099 - val_loss: 0.9651 - val_soft_acc: 0.4737\n",
      "Epoch 357/1000\n",
      "453/453 [==============================] - 0s 624us/step - loss: 0.7761 - soft_acc: 0.5077 - val_loss: 0.9145 - val_soft_acc: 0.4825\n",
      "Epoch 358/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 0.7684 - soft_acc: 0.5166 - val_loss: 0.8987 - val_soft_acc: 0.4298\n",
      "Epoch 359/1000\n",
      "453/453 [==============================] - 0s 597us/step - loss: 0.7740 - soft_acc: 0.5099 - val_loss: 0.9978 - val_soft_acc: 0.4649\n",
      "Epoch 360/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.7814 - soft_acc: 0.5497 - val_loss: 0.8915 - val_soft_acc: 0.4474\n",
      "Epoch 361/1000\n",
      "453/453 [==============================] - 0s 613us/step - loss: 0.7644 - soft_acc: 0.5055 - val_loss: 0.8994 - val_soft_acc: 0.4211\n",
      "Epoch 362/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.7695 - soft_acc: 0.4989 - val_loss: 0.9188 - val_soft_acc: 0.4649\n",
      "Epoch 363/1000\n",
      "453/453 [==============================] - 0s 597us/step - loss: 0.7709 - soft_acc: 0.5121 - val_loss: 0.9123 - val_soft_acc: 0.4123\n",
      "Epoch 364/1000\n",
      "453/453 [==============================] - 0s 628us/step - loss: 0.7695 - soft_acc: 0.5166 - val_loss: 0.8937 - val_soft_acc: 0.4649\n",
      "Epoch 365/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.7647 - soft_acc: 0.5298 - val_loss: 0.9699 - val_soft_acc: 0.3947\n",
      "Epoch 366/1000\n",
      "453/453 [==============================] - 0s 626us/step - loss: 0.7742 - soft_acc: 0.4967 - val_loss: 0.8935 - val_soft_acc: 0.4298\n",
      "Epoch 367/1000\n",
      "453/453 [==============================] - 0s 651us/step - loss: 0.7626 - soft_acc: 0.5121 - val_loss: 0.8882 - val_soft_acc: 0.4737\n",
      "Epoch 368/1000\n",
      "453/453 [==============================] - 0s 636us/step - loss: 0.7559 - soft_acc: 0.5188 - val_loss: 0.9153 - val_soft_acc: 0.4825\n",
      "Epoch 369/1000\n",
      "453/453 [==============================] - 0s 596us/step - loss: 0.7605 - soft_acc: 0.5298 - val_loss: 0.9893 - val_soft_acc: 0.4825\n",
      "Epoch 370/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 0.7660 - soft_acc: 0.5364 - val_loss: 0.9117 - val_soft_acc: 0.4298\n",
      "Epoch 371/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.7604 - soft_acc: 0.5232 - val_loss: 0.8931 - val_soft_acc: 0.4386\n",
      "Epoch 372/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.7592 - soft_acc: 0.5276 - val_loss: 0.9507 - val_soft_acc: 0.4737\n",
      "Epoch 373/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.7571 - soft_acc: 0.5386 - val_loss: 0.9368 - val_soft_acc: 0.4035\n",
      "Epoch 374/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.7638 - soft_acc: 0.5099 - val_loss: 0.8938 - val_soft_acc: 0.4474\n",
      "Epoch 375/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 0.7481 - soft_acc: 0.5254 - val_loss: 0.9042 - val_soft_acc: 0.5000\n",
      "Epoch 376/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.7487 - soft_acc: 0.5320 - val_loss: 0.8762 - val_soft_acc: 0.4737\n",
      "Epoch 377/1000\n",
      "453/453 [==============================] - 0s 596us/step - loss: 0.7440 - soft_acc: 0.5453 - val_loss: 0.9146 - val_soft_acc: 0.4123\n",
      "Epoch 378/1000\n",
      "453/453 [==============================] - 0s 590us/step - loss: 0.7502 - soft_acc: 0.5408 - val_loss: 0.9016 - val_soft_acc: 0.4123\n",
      "Epoch 379/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.7433 - soft_acc: 0.5430 - val_loss: 1.0004 - val_soft_acc: 0.3860\n",
      "Epoch 380/1000\n",
      "453/453 [==============================] - 0s 595us/step - loss: 0.7638 - soft_acc: 0.5166 - val_loss: 0.8969 - val_soft_acc: 0.4737\n",
      "Epoch 381/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.7406 - soft_acc: 0.5497 - val_loss: 1.0060 - val_soft_acc: 0.3860\n",
      "Epoch 382/1000\n",
      "453/453 [==============================] - 0s 643us/step - loss: 0.7666 - soft_acc: 0.5298 - val_loss: 0.9056 - val_soft_acc: 0.4912\n",
      "Epoch 383/1000\n",
      "453/453 [==============================] - 0s 619us/step - loss: 0.7352 - soft_acc: 0.5541 - val_loss: 0.9184 - val_soft_acc: 0.4123\n",
      "Epoch 384/1000\n",
      "453/453 [==============================] - 0s 627us/step - loss: 0.7402 - soft_acc: 0.5475 - val_loss: 0.9016 - val_soft_acc: 0.4386\n",
      "Epoch 385/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.7387 - soft_acc: 0.5364 - val_loss: 0.9767 - val_soft_acc: 0.4737\n",
      "Epoch 386/1000\n",
      "453/453 [==============================] - 0s 595us/step - loss: 0.7421 - soft_acc: 0.5430 - val_loss: 0.8804 - val_soft_acc: 0.5000\n",
      "Epoch 387/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 609us/step - loss: 0.7363 - soft_acc: 0.5607 - val_loss: 0.8925 - val_soft_acc: 0.4912\n",
      "Epoch 388/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.7416 - soft_acc: 0.5806 - val_loss: 0.9047 - val_soft_acc: 0.4912\n",
      "Epoch 389/1000\n",
      "453/453 [==============================] - 0s 612us/step - loss: 0.7308 - soft_acc: 0.5762 - val_loss: 0.9168 - val_soft_acc: 0.4211\n",
      "Epoch 390/1000\n",
      "453/453 [==============================] - 0s 610us/step - loss: 0.7415 - soft_acc: 0.5541 - val_loss: 0.8839 - val_soft_acc: 0.5000\n",
      "Epoch 391/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.7269 - soft_acc: 0.5828 - val_loss: 0.9341 - val_soft_acc: 0.4912\n",
      "Epoch 392/1000\n",
      "453/453 [==============================] - 0s 613us/step - loss: 0.7288 - soft_acc: 0.5717 - val_loss: 1.0242 - val_soft_acc: 0.4649\n",
      "Epoch 393/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.7498 - soft_acc: 0.5806 - val_loss: 0.9464 - val_soft_acc: 0.4912\n",
      "Epoch 394/1000\n",
      "453/453 [==============================] - 0s 610us/step - loss: 0.7259 - soft_acc: 0.5894 - val_loss: 0.9571 - val_soft_acc: 0.5088\n",
      "Epoch 395/1000\n",
      "453/453 [==============================] - 0s 614us/step - loss: 0.7311 - soft_acc: 0.5695 - val_loss: 0.8942 - val_soft_acc: 0.4912\n",
      "Epoch 396/1000\n",
      "453/453 [==============================] - 0s 614us/step - loss: 0.7156 - soft_acc: 0.5894 - val_loss: 0.9130 - val_soft_acc: 0.5088\n",
      "Epoch 397/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.7304 - soft_acc: 0.5762 - val_loss: 0.8893 - val_soft_acc: 0.5175\n",
      "Epoch 398/1000\n",
      "453/453 [==============================] - 0s 612us/step - loss: 0.7312 - soft_acc: 0.5806 - val_loss: 0.9796 - val_soft_acc: 0.3684\n",
      "Epoch 399/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.7355 - soft_acc: 0.5563 - val_loss: 0.9016 - val_soft_acc: 0.4649\n",
      "Epoch 400/1000\n",
      "453/453 [==============================] - 0s 630us/step - loss: 0.7184 - soft_acc: 0.5982 - val_loss: 0.9529 - val_soft_acc: 0.4035\n",
      "Epoch 401/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.7180 - soft_acc: 0.5762 - val_loss: 0.9443 - val_soft_acc: 0.4211\n",
      "Epoch 402/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.7274 - soft_acc: 0.5762 - val_loss: 0.9296 - val_soft_acc: 0.4912\n",
      "Epoch 403/1000\n",
      "453/453 [==============================] - 0s 613us/step - loss: 0.7167 - soft_acc: 0.6093 - val_loss: 0.9171 - val_soft_acc: 0.4386\n",
      "Epoch 404/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.7201 - soft_acc: 0.5695 - val_loss: 0.8866 - val_soft_acc: 0.5175\n",
      "Epoch 405/1000\n",
      "453/453 [==============================] - 0s 635us/step - loss: 0.7208 - soft_acc: 0.5938 - val_loss: 0.8804 - val_soft_acc: 0.5175\n",
      "Epoch 406/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.7095 - soft_acc: 0.5938 - val_loss: 0.8838 - val_soft_acc: 0.5263\n",
      "Epoch 407/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.7068 - soft_acc: 0.5828 - val_loss: 0.9345 - val_soft_acc: 0.4211\n",
      "Epoch 408/1000\n",
      "453/453 [==============================] - 0s 596us/step - loss: 0.7193 - soft_acc: 0.5762 - val_loss: 0.9867 - val_soft_acc: 0.4649\n",
      "Epoch 409/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.7104 - soft_acc: 0.6026 - val_loss: 0.9488 - val_soft_acc: 0.4912\n",
      "Epoch 410/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.7159 - soft_acc: 0.5982 - val_loss: 1.0918 - val_soft_acc: 0.4737\n",
      "Epoch 411/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.7305 - soft_acc: 0.5982 - val_loss: 0.8911 - val_soft_acc: 0.5088\n",
      "Epoch 412/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.7005 - soft_acc: 0.6093 - val_loss: 0.8825 - val_soft_acc: 0.5263\n",
      "Epoch 413/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.7009 - soft_acc: 0.6137 - val_loss: 1.0319 - val_soft_acc: 0.3860\n",
      "Epoch 414/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.7148 - soft_acc: 0.5762 - val_loss: 1.0078 - val_soft_acc: 0.4649\n",
      "Epoch 415/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.7129 - soft_acc: 0.6026 - val_loss: 0.9013 - val_soft_acc: 0.5439\n",
      "Epoch 416/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.6974 - soft_acc: 0.6203 - val_loss: 0.9548 - val_soft_acc: 0.4649\n",
      "Epoch 417/1000\n",
      "453/453 [==============================] - 0s 599us/step - loss: 0.7075 - soft_acc: 0.6093 - val_loss: 1.0404 - val_soft_acc: 0.4561\n",
      "Epoch 418/1000\n",
      "453/453 [==============================] - 0s 599us/step - loss: 0.7134 - soft_acc: 0.6093 - val_loss: 0.9180 - val_soft_acc: 0.4561\n",
      "Epoch 419/1000\n",
      "453/453 [==============================] - 0s 595us/step - loss: 0.6935 - soft_acc: 0.6269 - val_loss: 0.8983 - val_soft_acc: 0.4825\n",
      "Epoch 420/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.6925 - soft_acc: 0.6004 - val_loss: 0.8894 - val_soft_acc: 0.5000\n",
      "Epoch 421/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.6848 - soft_acc: 0.6269 - val_loss: 0.9112 - val_soft_acc: 0.5175\n",
      "Epoch 422/1000\n",
      "453/453 [==============================] - 0s 599us/step - loss: 0.6938 - soft_acc: 0.6115 - val_loss: 0.9191 - val_soft_acc: 0.5263\n",
      "Epoch 423/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.6895 - soft_acc: 0.6115 - val_loss: 0.8903 - val_soft_acc: 0.4912\n",
      "Epoch 424/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.6934 - soft_acc: 0.6313 - val_loss: 0.9698 - val_soft_acc: 0.4825\n",
      "Epoch 425/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.6895 - soft_acc: 0.6358 - val_loss: 0.9422 - val_soft_acc: 0.5088\n",
      "Epoch 426/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.6890 - soft_acc: 0.6313 - val_loss: 0.8939 - val_soft_acc: 0.5000\n",
      "Epoch 427/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.6797 - soft_acc: 0.6269 - val_loss: 0.9718 - val_soft_acc: 0.4737\n",
      "Epoch 428/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.6893 - soft_acc: 0.6358 - val_loss: 0.9495 - val_soft_acc: 0.4298\n",
      "Epoch 429/1000\n",
      "453/453 [==============================] - 0s 609us/step - loss: 0.6942 - soft_acc: 0.6291 - val_loss: 0.8921 - val_soft_acc: 0.5351\n",
      "Epoch 430/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.6721 - soft_acc: 0.6402 - val_loss: 0.8911 - val_soft_acc: 0.5088\n",
      "Epoch 431/1000\n",
      "453/453 [==============================] - 0s 601us/step - loss: 0.6865 - soft_acc: 0.6181 - val_loss: 0.8987 - val_soft_acc: 0.5175\n",
      "Epoch 432/1000\n",
      "453/453 [==============================] - 0s 599us/step - loss: 0.6693 - soft_acc: 0.6490 - val_loss: 0.8960 - val_soft_acc: 0.5263\n",
      "Epoch 433/1000\n",
      "453/453 [==============================] - 0s 599us/step - loss: 0.6685 - soft_acc: 0.6578 - val_loss: 1.0826 - val_soft_acc: 0.3947\n",
      "Epoch 434/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.7031 - soft_acc: 0.6071 - val_loss: 0.9539 - val_soft_acc: 0.4912\n",
      "Epoch 435/1000\n",
      "453/453 [==============================] - 0s 596us/step - loss: 0.6690 - soft_acc: 0.6512 - val_loss: 0.9079 - val_soft_acc: 0.4737\n",
      "Epoch 436/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.6663 - soft_acc: 0.6512 - val_loss: 1.0816 - val_soft_acc: 0.3947\n",
      "Epoch 437/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.6859 - soft_acc: 0.6313 - val_loss: 0.9289 - val_soft_acc: 0.4649\n",
      "Epoch 438/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.6730 - soft_acc: 0.6313 - val_loss: 0.9444 - val_soft_acc: 0.4649\n",
      "Epoch 439/1000\n",
      "453/453 [==============================] - 0s 595us/step - loss: 0.6819 - soft_acc: 0.6225 - val_loss: 0.9042 - val_soft_acc: 0.5263\n",
      "Epoch 440/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.6647 - soft_acc: 0.6358 - val_loss: 0.9475 - val_soft_acc: 0.4737\n",
      "Epoch 441/1000\n",
      "453/453 [==============================] - 0s 599us/step - loss: 0.6749 - soft_acc: 0.6313 - val_loss: 0.9127 - val_soft_acc: 0.4649\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 596us/step - loss: 0.6673 - soft_acc: 0.6468 - val_loss: 0.9369 - val_soft_acc: 0.5439\n",
      "Epoch 443/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.6599 - soft_acc: 0.6534 - val_loss: 0.9551 - val_soft_acc: 0.5088\n",
      "Epoch 444/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.6627 - soft_acc: 0.6468 - val_loss: 0.9663 - val_soft_acc: 0.4649\n",
      "Epoch 445/1000\n",
      "453/453 [==============================] - 0s 583us/step - loss: 0.6779 - soft_acc: 0.6380 - val_loss: 0.9010 - val_soft_acc: 0.5351\n",
      "Epoch 446/1000\n",
      "453/453 [==============================] - 0s 568us/step - loss: 0.6593 - soft_acc: 0.6336 - val_loss: 0.9134 - val_soft_acc: 0.5439\n",
      "Epoch 447/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.6598 - soft_acc: 0.6600 - val_loss: 0.9072 - val_soft_acc: 0.5088\n",
      "Epoch 448/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 0.6560 - soft_acc: 0.6534 - val_loss: 1.1376 - val_soft_acc: 0.4035\n",
      "Epoch 449/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.6781 - soft_acc: 0.6291 - val_loss: 0.9159 - val_soft_acc: 0.5088\n",
      "Epoch 450/1000\n",
      "453/453 [==============================] - 0s 614us/step - loss: 0.6593 - soft_acc: 0.6468 - val_loss: 1.0487 - val_soft_acc: 0.4123\n",
      "Epoch 451/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.6584 - soft_acc: 0.6667 - val_loss: 0.9527 - val_soft_acc: 0.5000\n",
      "Epoch 452/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.6605 - soft_acc: 0.6446 - val_loss: 0.9483 - val_soft_acc: 0.4561\n",
      "Epoch 453/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.6563 - soft_acc: 0.6512 - val_loss: 1.0600 - val_soft_acc: 0.4123\n",
      "Epoch 454/1000\n",
      "453/453 [==============================] - 0s 623us/step - loss: 0.6587 - soft_acc: 0.6490 - val_loss: 0.9129 - val_soft_acc: 0.5088\n",
      "Epoch 455/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.6557 - soft_acc: 0.6336 - val_loss: 0.9156 - val_soft_acc: 0.5351\n",
      "Epoch 456/1000\n",
      "453/453 [==============================] - 0s 610us/step - loss: 0.6466 - soft_acc: 0.6556 - val_loss: 0.9241 - val_soft_acc: 0.5000\n",
      "Epoch 457/1000\n",
      "453/453 [==============================] - 0s 609us/step - loss: 0.6592 - soft_acc: 0.6468 - val_loss: 0.9929 - val_soft_acc: 0.4386\n",
      "Epoch 458/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.6491 - soft_acc: 0.6556 - val_loss: 0.9215 - val_soft_acc: 0.5000\n",
      "Epoch 459/1000\n",
      "453/453 [==============================] - 0s 609us/step - loss: 0.6497 - soft_acc: 0.6512 - val_loss: 0.9158 - val_soft_acc: 0.5175\n",
      "Epoch 460/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.6566 - soft_acc: 0.6490 - val_loss: 0.9375 - val_soft_acc: 0.4737\n",
      "Epoch 461/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.6628 - soft_acc: 0.6291 - val_loss: 0.9546 - val_soft_acc: 0.4649\n",
      "Epoch 462/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.6484 - soft_acc: 0.6578 - val_loss: 0.9143 - val_soft_acc: 0.5614\n",
      "Epoch 463/1000\n",
      "453/453 [==============================] - 0s 601us/step - loss: 0.6528 - soft_acc: 0.6689 - val_loss: 0.9391 - val_soft_acc: 0.5000\n",
      "Epoch 464/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.6478 - soft_acc: 0.6733 - val_loss: 0.9111 - val_soft_acc: 0.5175\n",
      "Epoch 465/1000\n",
      "453/453 [==============================] - 0s 598us/step - loss: 0.6471 - soft_acc: 0.6380 - val_loss: 0.9941 - val_soft_acc: 0.4474\n",
      "Epoch 466/1000\n",
      "453/453 [==============================] - 0s 610us/step - loss: 0.6490 - soft_acc: 0.6556 - val_loss: 1.0282 - val_soft_acc: 0.4123\n",
      "Epoch 467/1000\n",
      "453/453 [==============================] - 0s 593us/step - loss: 0.6462 - soft_acc: 0.6777 - val_loss: 0.9995 - val_soft_acc: 0.4474\n",
      "Epoch 468/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.6602 - soft_acc: 0.6380 - val_loss: 0.9594 - val_soft_acc: 0.4561\n",
      "Epoch 469/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.6454 - soft_acc: 0.6600 - val_loss: 1.0015 - val_soft_acc: 0.4649\n",
      "Epoch 470/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.6378 - soft_acc: 0.6821 - val_loss: 0.9600 - val_soft_acc: 0.5000\n",
      "Epoch 471/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.6399 - soft_acc: 0.6645 - val_loss: 1.0552 - val_soft_acc: 0.4298\n",
      "Epoch 472/1000\n",
      "453/453 [==============================] - 0s 595us/step - loss: 0.6468 - soft_acc: 0.6600 - val_loss: 0.9199 - val_soft_acc: 0.5439\n",
      "Epoch 473/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.6333 - soft_acc: 0.6777 - val_loss: 0.9962 - val_soft_acc: 0.4649\n",
      "Epoch 474/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.6429 - soft_acc: 0.6556 - val_loss: 0.9117 - val_soft_acc: 0.5439\n",
      "Epoch 475/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.6410 - soft_acc: 0.6512 - val_loss: 0.9160 - val_soft_acc: 0.5263\n",
      "Epoch 476/1000\n",
      "453/453 [==============================] - 0s 599us/step - loss: 0.6379 - soft_acc: 0.6843 - val_loss: 0.9345 - val_soft_acc: 0.4737\n",
      "Epoch 477/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.6345 - soft_acc: 0.6645 - val_loss: 0.9366 - val_soft_acc: 0.5263\n",
      "Epoch 478/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.6381 - soft_acc: 0.6711 - val_loss: 1.0297 - val_soft_acc: 0.4386\n",
      "Epoch 479/1000\n",
      "453/453 [==============================] - 0s 593us/step - loss: 0.6528 - soft_acc: 0.6733 - val_loss: 0.9339 - val_soft_acc: 0.5000\n",
      "Epoch 480/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.6270 - soft_acc: 0.6976 - val_loss: 1.1059 - val_soft_acc: 0.4035\n",
      "Epoch 481/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.6468 - soft_acc: 0.6667 - val_loss: 0.9680 - val_soft_acc: 0.4649\n",
      "Epoch 482/1000\n",
      "453/453 [==============================] - 0s 594us/step - loss: 0.6307 - soft_acc: 0.6755 - val_loss: 0.9318 - val_soft_acc: 0.5000\n",
      "Epoch 483/1000\n",
      "453/453 [==============================] - 0s 601us/step - loss: 0.6367 - soft_acc: 0.6843 - val_loss: 0.9969 - val_soft_acc: 0.4825\n",
      "Epoch 484/1000\n",
      "453/453 [==============================] - 0s 596us/step - loss: 0.6224 - soft_acc: 0.6998 - val_loss: 0.9381 - val_soft_acc: 0.4649\n",
      "Epoch 485/1000\n",
      "453/453 [==============================] - 0s 592us/step - loss: 0.6374 - soft_acc: 0.6777 - val_loss: 1.0468 - val_soft_acc: 0.4123\n",
      "Epoch 486/1000\n",
      "453/453 [==============================] - 0s 601us/step - loss: 0.6285 - soft_acc: 0.6909 - val_loss: 1.0511 - val_soft_acc: 0.4211\n",
      "Epoch 487/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.6337 - soft_acc: 0.6711 - val_loss: 1.0612 - val_soft_acc: 0.4035\n",
      "Epoch 488/1000\n",
      "453/453 [==============================] - 0s 599us/step - loss: 0.6275 - soft_acc: 0.6865 - val_loss: 0.9511 - val_soft_acc: 0.4649\n",
      "Epoch 489/1000\n",
      "453/453 [==============================] - 0s 601us/step - loss: 0.6262 - soft_acc: 0.6711 - val_loss: 0.9431 - val_soft_acc: 0.4737\n",
      "Epoch 490/1000\n",
      "453/453 [==============================] - 0s 595us/step - loss: 0.6190 - soft_acc: 0.6865 - val_loss: 0.9179 - val_soft_acc: 0.4825\n",
      "Epoch 491/1000\n",
      "453/453 [==============================] - 0s 601us/step - loss: 0.6325 - soft_acc: 0.6733 - val_loss: 1.2128 - val_soft_acc: 0.4035\n",
      "Epoch 492/1000\n",
      "453/453 [==============================] - 0s 596us/step - loss: 0.6598 - soft_acc: 0.6645 - val_loss: 0.9723 - val_soft_acc: 0.4737\n",
      "Epoch 493/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 0.6199 - soft_acc: 0.7020 - val_loss: 0.9782 - val_soft_acc: 0.4649\n",
      "Epoch 494/1000\n",
      "453/453 [==============================] - 0s 590us/step - loss: 0.6361 - soft_acc: 0.6689 - val_loss: 0.9209 - val_soft_acc: 0.4912\n",
      "Epoch 495/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.6325 - soft_acc: 0.6821 - val_loss: 0.9195 - val_soft_acc: 0.5088\n",
      "Epoch 496/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.6145 - soft_acc: 0.6843 - val_loss: 0.9752 - val_soft_acc: 0.4649\n",
      "Epoch 497/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 598us/step - loss: 0.6293 - soft_acc: 0.6843 - val_loss: 0.9388 - val_soft_acc: 0.4649\n",
      "Epoch 498/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.6117 - soft_acc: 0.6865 - val_loss: 1.1841 - val_soft_acc: 0.4123\n",
      "Epoch 499/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.6356 - soft_acc: 0.6623 - val_loss: 1.1629 - val_soft_acc: 0.4123\n",
      "Epoch 500/1000\n",
      "453/453 [==============================] - 0s 609us/step - loss: 0.6310 - soft_acc: 0.6755 - val_loss: 0.9464 - val_soft_acc: 0.5000\n",
      "Epoch 501/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.6095 - soft_acc: 0.7108 - val_loss: 1.0060 - val_soft_acc: 0.4737\n",
      "Epoch 502/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.6356 - soft_acc: 0.6887 - val_loss: 0.9683 - val_soft_acc: 0.4561\n",
      "Epoch 503/1000\n",
      "453/453 [==============================] - 0s 612us/step - loss: 0.6131 - soft_acc: 0.6954 - val_loss: 1.0692 - val_soft_acc: 0.4211\n",
      "Epoch 504/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.6140 - soft_acc: 0.6998 - val_loss: 1.2575 - val_soft_acc: 0.3947\n",
      "Epoch 505/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.6384 - soft_acc: 0.6711 - val_loss: 0.9491 - val_soft_acc: 0.4825\n",
      "Epoch 506/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.6318 - soft_acc: 0.6777 - val_loss: 0.9428 - val_soft_acc: 0.4912\n",
      "Epoch 507/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.6153 - soft_acc: 0.7042 - val_loss: 0.9696 - val_soft_acc: 0.4649\n",
      "Epoch 508/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 0.6150 - soft_acc: 0.6976 - val_loss: 0.9395 - val_soft_acc: 0.4912\n",
      "Epoch 509/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 0.6099 - soft_acc: 0.6932 - val_loss: 0.9636 - val_soft_acc: 0.4737\n",
      "Epoch 510/1000\n",
      "453/453 [==============================] - 0s 609us/step - loss: 0.6266 - soft_acc: 0.6865 - val_loss: 0.9407 - val_soft_acc: 0.4825\n",
      "Epoch 511/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.6025 - soft_acc: 0.7086 - val_loss: 1.1715 - val_soft_acc: 0.3947\n",
      "Epoch 512/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.6311 - soft_acc: 0.6865 - val_loss: 1.0598 - val_soft_acc: 0.4123\n",
      "Epoch 513/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.6118 - soft_acc: 0.7086 - val_loss: 0.9952 - val_soft_acc: 0.5000\n",
      "Epoch 514/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.6167 - soft_acc: 0.7086 - val_loss: 1.2011 - val_soft_acc: 0.4035\n",
      "Epoch 515/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 0.6331 - soft_acc: 0.6954 - val_loss: 0.9378 - val_soft_acc: 0.5263\n",
      "Epoch 516/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.6099 - soft_acc: 0.6976 - val_loss: 0.9486 - val_soft_acc: 0.4649\n",
      "Epoch 517/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.6015 - soft_acc: 0.7086 - val_loss: 1.1352 - val_soft_acc: 0.4298\n",
      "Epoch 518/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.6294 - soft_acc: 0.6932 - val_loss: 1.0799 - val_soft_acc: 0.4211\n",
      "Epoch 519/1000\n",
      "453/453 [==============================] - 0s 599us/step - loss: 0.6190 - soft_acc: 0.6932 - val_loss: 0.9824 - val_soft_acc: 0.4825\n",
      "Epoch 520/1000\n",
      "453/453 [==============================] - 0s 599us/step - loss: 0.6229 - soft_acc: 0.6799 - val_loss: 0.9522 - val_soft_acc: 0.4912\n",
      "Epoch 521/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.6098 - soft_acc: 0.6976 - val_loss: 1.0677 - val_soft_acc: 0.3947\n",
      "Epoch 522/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.6097 - soft_acc: 0.7086 - val_loss: 1.0843 - val_soft_acc: 0.4035\n",
      "Epoch 523/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.6036 - soft_acc: 0.7241 - val_loss: 0.9577 - val_soft_acc: 0.4561\n",
      "Epoch 524/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.6034 - soft_acc: 0.7086 - val_loss: 1.1575 - val_soft_acc: 0.4035\n",
      "Epoch 525/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.6188 - soft_acc: 0.7086 - val_loss: 0.9557 - val_soft_acc: 0.4912\n",
      "Epoch 526/1000\n",
      "453/453 [==============================] - 0s 599us/step - loss: 0.6214 - soft_acc: 0.6887 - val_loss: 1.1180 - val_soft_acc: 0.4474\n",
      "Epoch 527/1000\n",
      "453/453 [==============================] - 0s 593us/step - loss: 0.6188 - soft_acc: 0.7042 - val_loss: 0.9623 - val_soft_acc: 0.4912\n",
      "Epoch 528/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.6026 - soft_acc: 0.7064 - val_loss: 1.0555 - val_soft_acc: 0.4825\n",
      "Epoch 529/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 0.6306 - soft_acc: 0.6799 - val_loss: 0.9770 - val_soft_acc: 0.4298\n",
      "Epoch 530/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.6000 - soft_acc: 0.6998 - val_loss: 1.0815 - val_soft_acc: 0.4211\n",
      "Epoch 531/1000\n",
      "453/453 [==============================] - 0s 598us/step - loss: 0.6180 - soft_acc: 0.6909 - val_loss: 0.9549 - val_soft_acc: 0.4649\n",
      "Epoch 532/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.5997 - soft_acc: 0.7263 - val_loss: 0.9553 - val_soft_acc: 0.5000\n",
      "Epoch 533/1000\n",
      "453/453 [==============================] - 0s 601us/step - loss: 0.6164 - soft_acc: 0.6821 - val_loss: 1.1330 - val_soft_acc: 0.4211\n",
      "Epoch 534/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.6185 - soft_acc: 0.7064 - val_loss: 1.0261 - val_soft_acc: 0.5000\n",
      "Epoch 535/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.6167 - soft_acc: 0.6954 - val_loss: 0.9859 - val_soft_acc: 0.4386\n",
      "Epoch 536/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.6104 - soft_acc: 0.6954 - val_loss: 1.0057 - val_soft_acc: 0.5088\n",
      "Epoch 537/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.6023 - soft_acc: 0.7130 - val_loss: 1.2299 - val_soft_acc: 0.3860\n",
      "Epoch 538/1000\n",
      "453/453 [==============================] - 0s 595us/step - loss: 0.6226 - soft_acc: 0.6887 - val_loss: 0.9605 - val_soft_acc: 0.5000\n",
      "Epoch 539/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.6020 - soft_acc: 0.7020 - val_loss: 1.1052 - val_soft_acc: 0.4298\n",
      "Epoch 540/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 0.6062 - soft_acc: 0.7108 - val_loss: 1.0194 - val_soft_acc: 0.5000\n",
      "Epoch 541/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.6147 - soft_acc: 0.7086 - val_loss: 1.0441 - val_soft_acc: 0.4912\n",
      "Epoch 542/1000\n",
      "453/453 [==============================] - 0s 601us/step - loss: 0.6207 - soft_acc: 0.6887 - val_loss: 1.0296 - val_soft_acc: 0.4298\n",
      "Epoch 543/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.6017 - soft_acc: 0.7174 - val_loss: 1.0179 - val_soft_acc: 0.4561\n",
      "Epoch 544/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.6088 - soft_acc: 0.6843 - val_loss: 0.9585 - val_soft_acc: 0.4561\n",
      "Epoch 545/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.5925 - soft_acc: 0.7219 - val_loss: 0.9547 - val_soft_acc: 0.4737\n",
      "Epoch 546/1000\n",
      "453/453 [==============================] - 0s 601us/step - loss: 0.6147 - soft_acc: 0.6932 - val_loss: 0.9596 - val_soft_acc: 0.5000\n",
      "Epoch 547/1000\n",
      "453/453 [==============================] - 0s 601us/step - loss: 0.5995 - soft_acc: 0.7108 - val_loss: 0.9891 - val_soft_acc: 0.5088\n",
      "Epoch 548/1000\n",
      "453/453 [==============================] - 0s 593us/step - loss: 0.6089 - soft_acc: 0.7064 - val_loss: 0.9781 - val_soft_acc: 0.4474\n",
      "Epoch 549/1000\n",
      "453/453 [==============================] - 0s 598us/step - loss: 0.6054 - soft_acc: 0.6954 - val_loss: 1.0410 - val_soft_acc: 0.4298\n",
      "Epoch 550/1000\n",
      "453/453 [==============================] - 0s 591us/step - loss: 0.6011 - soft_acc: 0.6976 - val_loss: 1.0641 - val_soft_acc: 0.4298\n",
      "Epoch 551/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.6002 - soft_acc: 0.7174 - val_loss: 0.9567 - val_soft_acc: 0.4825\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 598us/step - loss: 0.5992 - soft_acc: 0.7108 - val_loss: 1.0624 - val_soft_acc: 0.4474\n",
      "Epoch 553/1000\n",
      "453/453 [==============================] - 0s 609us/step - loss: 0.6050 - soft_acc: 0.7042 - val_loss: 0.9921 - val_soft_acc: 0.4474\n",
      "Epoch 554/1000\n",
      "453/453 [==============================] - 0s 609us/step - loss: 0.5989 - soft_acc: 0.7020 - val_loss: 0.9480 - val_soft_acc: 0.4825\n",
      "Epoch 555/1000\n",
      "453/453 [==============================] - 0s 610us/step - loss: 0.5991 - soft_acc: 0.7108 - val_loss: 0.9731 - val_soft_acc: 0.4912\n",
      "Epoch 556/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.6160 - soft_acc: 0.7086 - val_loss: 1.0868 - val_soft_acc: 0.4825\n",
      "Epoch 557/1000\n",
      "453/453 [==============================] - 0s 609us/step - loss: 0.6082 - soft_acc: 0.6843 - val_loss: 0.9636 - val_soft_acc: 0.4386\n",
      "Epoch 558/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 0.6042 - soft_acc: 0.7064 - val_loss: 1.0139 - val_soft_acc: 0.4386\n",
      "Epoch 559/1000\n",
      "453/453 [==============================] - 0s 610us/step - loss: 0.5985 - soft_acc: 0.7417 - val_loss: 1.0087 - val_soft_acc: 0.4474\n",
      "Epoch 560/1000\n",
      "453/453 [==============================] - 0s 622us/step - loss: 0.6010 - soft_acc: 0.7329 - val_loss: 1.0359 - val_soft_acc: 0.5263\n",
      "Epoch 561/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.6178 - soft_acc: 0.6954 - val_loss: 1.0259 - val_soft_acc: 0.4386\n",
      "Epoch 562/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.5947 - soft_acc: 0.7064 - val_loss: 1.1297 - val_soft_acc: 0.4298\n",
      "Epoch 563/1000\n",
      "453/453 [==============================] - 0s 610us/step - loss: 0.6100 - soft_acc: 0.7020 - val_loss: 1.0222 - val_soft_acc: 0.4561\n",
      "Epoch 564/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.5933 - soft_acc: 0.7064 - val_loss: 1.1050 - val_soft_acc: 0.4211\n",
      "Epoch 565/1000\n",
      "453/453 [==============================] - 0s 615us/step - loss: 0.6011 - soft_acc: 0.7020 - val_loss: 0.9667 - val_soft_acc: 0.4474\n",
      "Epoch 566/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.5939 - soft_acc: 0.7086 - val_loss: 0.9891 - val_soft_acc: 0.4649\n",
      "Epoch 567/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.5993 - soft_acc: 0.7285 - val_loss: 0.9985 - val_soft_acc: 0.4561\n",
      "Epoch 568/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.6022 - soft_acc: 0.7020 - val_loss: 1.0966 - val_soft_acc: 0.4123\n",
      "Epoch 569/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.5996 - soft_acc: 0.7329 - val_loss: 1.0089 - val_soft_acc: 0.4386\n",
      "Epoch 570/1000\n",
      "453/453 [==============================] - 0s 613us/step - loss: 0.6001 - soft_acc: 0.6932 - val_loss: 0.9609 - val_soft_acc: 0.4737\n",
      "Epoch 571/1000\n",
      "453/453 [==============================] - 0s 629us/step - loss: 0.5869 - soft_acc: 0.7152 - val_loss: 1.0038 - val_soft_acc: 0.5439\n",
      "Epoch 572/1000\n",
      "453/453 [==============================] - 0s 628us/step - loss: 0.6074 - soft_acc: 0.6887 - val_loss: 0.9733 - val_soft_acc: 0.5263\n",
      "Epoch 573/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.5983 - soft_acc: 0.7219 - val_loss: 0.9776 - val_soft_acc: 0.5175\n",
      "Epoch 574/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.6043 - soft_acc: 0.7152 - val_loss: 0.9528 - val_soft_acc: 0.4737\n",
      "Epoch 575/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.6059 - soft_acc: 0.6954 - val_loss: 1.0557 - val_soft_acc: 0.4298\n",
      "Epoch 576/1000\n",
      "453/453 [==============================] - 0s 643us/step - loss: 0.5940 - soft_acc: 0.7108 - val_loss: 1.0141 - val_soft_acc: 0.5263\n",
      "Epoch 577/1000\n",
      "453/453 [==============================] - 0s 622us/step - loss: 0.6026 - soft_acc: 0.7020 - val_loss: 1.0031 - val_soft_acc: 0.4298\n",
      "Epoch 578/1000\n",
      "453/453 [==============================] - 0s 660us/step - loss: 0.5958 - soft_acc: 0.7196 - val_loss: 1.2126 - val_soft_acc: 0.4123\n",
      "Epoch 579/1000\n",
      "453/453 [==============================] - 0s 623us/step - loss: 0.6110 - soft_acc: 0.7108 - val_loss: 1.0031 - val_soft_acc: 0.5351\n",
      "Epoch 580/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.6030 - soft_acc: 0.7086 - val_loss: 1.0744 - val_soft_acc: 0.4211\n",
      "Epoch 581/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.5911 - soft_acc: 0.7152 - val_loss: 1.2860 - val_soft_acc: 0.4035\n",
      "Epoch 582/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.6152 - soft_acc: 0.7086 - val_loss: 0.9973 - val_soft_acc: 0.5263\n",
      "Epoch 583/1000\n",
      "453/453 [==============================] - 0s 597us/step - loss: 0.6101 - soft_acc: 0.6799 - val_loss: 1.0178 - val_soft_acc: 0.4386\n",
      "Epoch 584/1000\n",
      "453/453 [==============================] - 0s 624us/step - loss: 0.5901 - soft_acc: 0.7263 - val_loss: 1.0485 - val_soft_acc: 0.4298\n",
      "Epoch 585/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.6034 - soft_acc: 0.7064 - val_loss: 0.9685 - val_soft_acc: 0.4649\n",
      "Epoch 586/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.5822 - soft_acc: 0.7219 - val_loss: 1.0818 - val_soft_acc: 0.4035\n",
      "Epoch 587/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.5967 - soft_acc: 0.6998 - val_loss: 0.9723 - val_soft_acc: 0.4561\n",
      "Epoch 588/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.5893 - soft_acc: 0.7263 - val_loss: 1.1380 - val_soft_acc: 0.3860\n",
      "Epoch 589/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.6060 - soft_acc: 0.6998 - val_loss: 1.2338 - val_soft_acc: 0.3947\n",
      "Epoch 590/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.5965 - soft_acc: 0.7064 - val_loss: 1.1165 - val_soft_acc: 0.3947\n",
      "Epoch 591/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.6084 - soft_acc: 0.7130 - val_loss: 1.0232 - val_soft_acc: 0.4298\n",
      "Epoch 592/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.5819 - soft_acc: 0.7196 - val_loss: 1.0521 - val_soft_acc: 0.4298\n",
      "Epoch 593/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.5929 - soft_acc: 0.7241 - val_loss: 1.1251 - val_soft_acc: 0.3860\n",
      "Epoch 594/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.5915 - soft_acc: 0.7307 - val_loss: 1.2005 - val_soft_acc: 0.3947\n",
      "Epoch 595/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.6033 - soft_acc: 0.7086 - val_loss: 1.0034 - val_soft_acc: 0.4649\n",
      "Epoch 596/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.5904 - soft_acc: 0.7108 - val_loss: 0.9862 - val_soft_acc: 0.4737\n",
      "Epoch 597/1000\n",
      "453/453 [==============================] - 0s 601us/step - loss: 0.5929 - soft_acc: 0.7174 - val_loss: 1.1458 - val_soft_acc: 0.3947\n",
      "Epoch 598/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.5906 - soft_acc: 0.7329 - val_loss: 0.9753 - val_soft_acc: 0.4737\n",
      "Epoch 599/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.5817 - soft_acc: 0.7263 - val_loss: 1.1886 - val_soft_acc: 0.3947\n",
      "Epoch 600/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.6126 - soft_acc: 0.7108 - val_loss: 1.0252 - val_soft_acc: 0.5175\n",
      "Epoch 601/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.5992 - soft_acc: 0.7241 - val_loss: 1.0109 - val_soft_acc: 0.4561\n",
      "Epoch 602/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.6001 - soft_acc: 0.7108 - val_loss: 0.9658 - val_soft_acc: 0.4825\n",
      "Epoch 603/1000\n",
      "453/453 [==============================] - 0s 619us/step - loss: 0.5889 - soft_acc: 0.7285 - val_loss: 1.1361 - val_soft_acc: 0.3772\n",
      "Epoch 604/1000\n",
      "453/453 [==============================] - 0s 615us/step - loss: 0.6038 - soft_acc: 0.7064 - val_loss: 0.9608 - val_soft_acc: 0.4825\n",
      "Epoch 605/1000\n",
      "453/453 [==============================] - 0s 600us/step - loss: 0.5842 - soft_acc: 0.7285 - val_loss: 1.0045 - val_soft_acc: 0.5263\n",
      "Epoch 606/1000\n",
      "453/453 [==============================] - 0s 601us/step - loss: 0.5865 - soft_acc: 0.7086 - val_loss: 1.0067 - val_soft_acc: 0.4474\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 608us/step - loss: 0.5796 - soft_acc: 0.7285 - val_loss: 0.9774 - val_soft_acc: 0.5439\n",
      "Epoch 608/1000\n",
      "453/453 [==============================] - 0s 625us/step - loss: 0.6051 - soft_acc: 0.7020 - val_loss: 0.9882 - val_soft_acc: 0.5351\n",
      "Epoch 609/1000\n",
      "453/453 [==============================] - 0s 612us/step - loss: 0.5992 - soft_acc: 0.7020 - val_loss: 0.9729 - val_soft_acc: 0.5175\n",
      "Epoch 610/1000\n",
      "453/453 [==============================] - 0s 609us/step - loss: 0.6002 - soft_acc: 0.7196 - val_loss: 1.0526 - val_soft_acc: 0.4474\n",
      "Epoch 611/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.5856 - soft_acc: 0.7307 - val_loss: 1.0346 - val_soft_acc: 0.5263\n",
      "Epoch 612/1000\n",
      "453/453 [==============================] - 0s 610us/step - loss: 0.6004 - soft_acc: 0.7020 - val_loss: 1.1117 - val_soft_acc: 0.3947\n",
      "Epoch 613/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.5898 - soft_acc: 0.7108 - val_loss: 1.0159 - val_soft_acc: 0.4298\n",
      "Epoch 614/1000\n",
      "453/453 [==============================] - 0s 616us/step - loss: 0.5827 - soft_acc: 0.7351 - val_loss: 0.9932 - val_soft_acc: 0.5263\n",
      "Epoch 615/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.5905 - soft_acc: 0.7174 - val_loss: 1.1792 - val_soft_acc: 0.3947\n",
      "Epoch 616/1000\n",
      "453/453 [==============================] - 0s 609us/step - loss: 0.5983 - soft_acc: 0.7263 - val_loss: 0.9703 - val_soft_acc: 0.4825\n",
      "Epoch 617/1000\n",
      "453/453 [==============================] - 0s 614us/step - loss: 0.5873 - soft_acc: 0.7285 - val_loss: 1.0285 - val_soft_acc: 0.5263\n",
      "Epoch 618/1000\n",
      "453/453 [==============================] - 0s 612us/step - loss: 0.6009 - soft_acc: 0.7130 - val_loss: 1.1326 - val_soft_acc: 0.3772\n",
      "Epoch 619/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.5915 - soft_acc: 0.7042 - val_loss: 0.9963 - val_soft_acc: 0.5351\n",
      "Epoch 620/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.5917 - soft_acc: 0.7219 - val_loss: 1.0359 - val_soft_acc: 0.4474\n",
      "Epoch 621/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 0.5819 - soft_acc: 0.7373 - val_loss: 1.0382 - val_soft_acc: 0.4474\n",
      "Epoch 622/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 0.5932 - soft_acc: 0.7241 - val_loss: 1.1418 - val_soft_acc: 0.3947\n",
      "Epoch 623/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.5948 - soft_acc: 0.7174 - val_loss: 1.2157 - val_soft_acc: 0.3860\n",
      "Epoch 624/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 0.5953 - soft_acc: 0.7307 - val_loss: 1.0629 - val_soft_acc: 0.5263\n",
      "Epoch 625/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.5936 - soft_acc: 0.7130 - val_loss: 0.9724 - val_soft_acc: 0.5614\n",
      "Epoch 626/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.5820 - soft_acc: 0.7196 - val_loss: 1.0119 - val_soft_acc: 0.4474\n",
      "Epoch 627/1000\n",
      "453/453 [==============================] - 0s 608us/step - loss: 0.6078 - soft_acc: 0.7086 - val_loss: 1.0755 - val_soft_acc: 0.4912\n",
      "Epoch 628/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.5928 - soft_acc: 0.7196 - val_loss: 1.0610 - val_soft_acc: 0.3947\n",
      "Epoch 629/1000\n",
      "453/453 [==============================] - 0s 601us/step - loss: 0.5920 - soft_acc: 0.7263 - val_loss: 0.9952 - val_soft_acc: 0.4737\n",
      "Epoch 630/1000\n",
      "453/453 [==============================] - 0s 613us/step - loss: 0.5766 - soft_acc: 0.7373 - val_loss: 0.9743 - val_soft_acc: 0.4825\n",
      "Epoch 631/1000\n",
      "453/453 [==============================] - 0s 615us/step - loss: 0.5775 - soft_acc: 0.7263 - val_loss: 1.0039 - val_soft_acc: 0.5526\n",
      "Epoch 632/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.5829 - soft_acc: 0.7373 - val_loss: 0.9786 - val_soft_acc: 0.4737\n",
      "Epoch 633/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.5935 - soft_acc: 0.7064 - val_loss: 1.0473 - val_soft_acc: 0.4386\n",
      "Epoch 634/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.5903 - soft_acc: 0.7241 - val_loss: 0.9681 - val_soft_acc: 0.5175\n",
      "Epoch 635/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.5749 - soft_acc: 0.7461 - val_loss: 0.9702 - val_soft_acc: 0.5175\n",
      "Epoch 636/1000\n",
      "453/453 [==============================] - 0s 622us/step - loss: 0.5867 - soft_acc: 0.7241 - val_loss: 1.2188 - val_soft_acc: 0.4035\n",
      "Epoch 637/1000\n",
      "453/453 [==============================] - 0s 630us/step - loss: 0.5988 - soft_acc: 0.7219 - val_loss: 1.0011 - val_soft_acc: 0.4561\n",
      "Epoch 638/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.5784 - soft_acc: 0.7528 - val_loss: 0.9970 - val_soft_acc: 0.4561\n",
      "Epoch 639/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.5860 - soft_acc: 0.7196 - val_loss: 1.0206 - val_soft_acc: 0.4561\n",
      "Epoch 640/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.5826 - soft_acc: 0.7351 - val_loss: 0.9920 - val_soft_acc: 0.5088\n",
      "Epoch 641/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.5747 - soft_acc: 0.7307 - val_loss: 1.3368 - val_soft_acc: 0.3860\n",
      "Epoch 642/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.6085 - soft_acc: 0.7020 - val_loss: 1.0680 - val_soft_acc: 0.4298\n",
      "Epoch 643/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.5725 - soft_acc: 0.7461 - val_loss: 1.1355 - val_soft_acc: 0.4912\n",
      "Epoch 644/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 0.5990 - soft_acc: 0.7196 - val_loss: 1.1464 - val_soft_acc: 0.4298\n",
      "Epoch 645/1000\n",
      "453/453 [==============================] - 0s 607us/step - loss: 0.5920 - soft_acc: 0.7439 - val_loss: 1.0164 - val_soft_acc: 0.5439\n",
      "Epoch 646/1000\n",
      "453/453 [==============================] - 0s 630us/step - loss: 0.5805 - soft_acc: 0.7329 - val_loss: 1.0725 - val_soft_acc: 0.4912\n",
      "Epoch 647/1000\n",
      "453/453 [==============================] - 0s 616us/step - loss: 0.5873 - soft_acc: 0.7395 - val_loss: 1.0987 - val_soft_acc: 0.4035\n",
      "Epoch 648/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.5741 - soft_acc: 0.7417 - val_loss: 1.1116 - val_soft_acc: 0.4035\n",
      "Epoch 649/1000\n",
      "453/453 [==============================] - 0s 594us/step - loss: 0.5812 - soft_acc: 0.7483 - val_loss: 1.0385 - val_soft_acc: 0.4649\n",
      "Epoch 650/1000\n",
      "453/453 [==============================] - 0s 613us/step - loss: 0.5640 - soft_acc: 0.7550 - val_loss: 1.0110 - val_soft_acc: 0.5263\n",
      "Epoch 651/1000\n",
      "453/453 [==============================] - 0s 601us/step - loss: 0.5733 - soft_acc: 0.7395 - val_loss: 1.0045 - val_soft_acc: 0.4649\n",
      "Epoch 652/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.5708 - soft_acc: 0.7417 - val_loss: 1.0479 - val_soft_acc: 0.5088\n",
      "Epoch 653/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.5939 - soft_acc: 0.7307 - val_loss: 1.0063 - val_soft_acc: 0.4825\n",
      "Epoch 654/1000\n",
      "453/453 [==============================] - 0s 629us/step - loss: 0.5743 - soft_acc: 0.7373 - val_loss: 1.1362 - val_soft_acc: 0.4035\n",
      "Epoch 655/1000\n",
      "453/453 [==============================] - 0s 659us/step - loss: 0.5779 - soft_acc: 0.7417 - val_loss: 1.2113 - val_soft_acc: 0.4123\n",
      "Epoch 656/1000\n",
      "453/453 [==============================] - 0s 827us/step - loss: 0.5874 - soft_acc: 0.7351 - val_loss: 1.2010 - val_soft_acc: 0.3947\n",
      "Epoch 657/1000\n",
      "453/453 [==============================] - 0s 824us/step - loss: 0.5835 - soft_acc: 0.7506 - val_loss: 1.0694 - val_soft_acc: 0.4649\n",
      "Epoch 658/1000\n",
      "453/453 [==============================] - 0s 857us/step - loss: 0.5645 - soft_acc: 0.7528 - val_loss: 1.1582 - val_soft_acc: 0.3772\n",
      "Epoch 659/1000\n",
      "453/453 [==============================] - 0s 839us/step - loss: 0.5784 - soft_acc: 0.7616 - val_loss: 1.0032 - val_soft_acc: 0.5088\n",
      "Epoch 660/1000\n",
      "453/453 [==============================] - 0s 841us/step - loss: 0.5755 - soft_acc: 0.7550 - val_loss: 1.0058 - val_soft_acc: 0.5175\n",
      "Epoch 661/1000\n",
      "453/453 [==============================] - 0s 871us/step - loss: 0.5834 - soft_acc: 0.7439 - val_loss: 0.9970 - val_soft_acc: 0.5088\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 854us/step - loss: 0.5698 - soft_acc: 0.7704 - val_loss: 0.9970 - val_soft_acc: 0.5000\n",
      "Epoch 663/1000\n",
      "453/453 [==============================] - 0s 877us/step - loss: 0.5791 - soft_acc: 0.7461 - val_loss: 0.9758 - val_soft_acc: 0.5351\n",
      "Epoch 664/1000\n",
      "453/453 [==============================] - 0s 899us/step - loss: 0.5737 - soft_acc: 0.7351 - val_loss: 1.0086 - val_soft_acc: 0.4649\n",
      "Epoch 665/1000\n",
      "453/453 [==============================] - 0s 867us/step - loss: 0.5780 - soft_acc: 0.7461 - val_loss: 1.2232 - val_soft_acc: 0.4035\n",
      "Epoch 666/1000\n",
      "453/453 [==============================] - 0s 924us/step - loss: 0.5748 - soft_acc: 0.7682 - val_loss: 1.0063 - val_soft_acc: 0.5088\n",
      "Epoch 667/1000\n",
      "453/453 [==============================] - 0s 905us/step - loss: 0.5690 - soft_acc: 0.7682 - val_loss: 1.0461 - val_soft_acc: 0.5000\n",
      "Epoch 668/1000\n",
      "453/453 [==============================] - 0s 877us/step - loss: 0.5747 - soft_acc: 0.7550 - val_loss: 1.2000 - val_soft_acc: 0.3947\n",
      "Epoch 669/1000\n",
      "453/453 [==============================] - 0s 875us/step - loss: 0.5777 - soft_acc: 0.7483 - val_loss: 1.0838 - val_soft_acc: 0.4474\n",
      "Epoch 670/1000\n",
      "453/453 [==============================] - 0s 907us/step - loss: 0.5783 - soft_acc: 0.7307 - val_loss: 1.0119 - val_soft_acc: 0.4912\n",
      "Epoch 671/1000\n",
      "453/453 [==============================] - 0s 921us/step - loss: 0.5728 - soft_acc: 0.7616 - val_loss: 1.0238 - val_soft_acc: 0.5088\n",
      "Epoch 672/1000\n",
      "453/453 [==============================] - 0s 861us/step - loss: 0.5868 - soft_acc: 0.7108 - val_loss: 1.0220 - val_soft_acc: 0.4737\n",
      "Epoch 673/1000\n",
      "453/453 [==============================] - 0s 837us/step - loss: 0.5674 - soft_acc: 0.7461 - val_loss: 1.0027 - val_soft_acc: 0.5000\n",
      "Epoch 674/1000\n",
      "453/453 [==============================] - 0s 827us/step - loss: 0.5659 - soft_acc: 0.7660 - val_loss: 1.1654 - val_soft_acc: 0.3860\n",
      "Epoch 675/1000\n",
      "453/453 [==============================] - 0s 819us/step - loss: 0.5720 - soft_acc: 0.7461 - val_loss: 1.0141 - val_soft_acc: 0.5088\n",
      "Epoch 676/1000\n",
      "453/453 [==============================] - 0s 805us/step - loss: 0.5678 - soft_acc: 0.7638 - val_loss: 1.0112 - val_soft_acc: 0.5088\n",
      "Epoch 677/1000\n",
      "453/453 [==============================] - 0s 812us/step - loss: 0.5816 - soft_acc: 0.7550 - val_loss: 1.1129 - val_soft_acc: 0.4912\n",
      "Epoch 678/1000\n",
      "453/453 [==============================] - 0s 814us/step - loss: 0.5861 - soft_acc: 0.7395 - val_loss: 1.0751 - val_soft_acc: 0.5088\n",
      "Epoch 679/1000\n",
      "453/453 [==============================] - 0s 810us/step - loss: 0.5749 - soft_acc: 0.7395 - val_loss: 1.0370 - val_soft_acc: 0.5175\n",
      "Epoch 680/1000\n",
      "453/453 [==============================] - 0s 809us/step - loss: 0.5654 - soft_acc: 0.7638 - val_loss: 1.0693 - val_soft_acc: 0.4474\n",
      "Epoch 681/1000\n",
      "453/453 [==============================] - 0s 763us/step - loss: 0.5652 - soft_acc: 0.7572 - val_loss: 1.0735 - val_soft_acc: 0.4825\n",
      "Epoch 682/1000\n",
      "453/453 [==============================] - 0s 778us/step - loss: 0.5818 - soft_acc: 0.7439 - val_loss: 1.0048 - val_soft_acc: 0.4737\n",
      "Epoch 683/1000\n",
      "453/453 [==============================] - 0s 788us/step - loss: 0.5592 - soft_acc: 0.7616 - val_loss: 1.1244 - val_soft_acc: 0.4561\n",
      "Epoch 684/1000\n",
      "453/453 [==============================] - 0s 782us/step - loss: 0.5914 - soft_acc: 0.7196 - val_loss: 1.1245 - val_soft_acc: 0.4211\n",
      "Epoch 685/1000\n",
      "453/453 [==============================] - 0s 763us/step - loss: 0.5647 - soft_acc: 0.7704 - val_loss: 1.0080 - val_soft_acc: 0.4825\n",
      "Epoch 686/1000\n",
      "453/453 [==============================] - 0s 766us/step - loss: 0.5541 - soft_acc: 0.7903 - val_loss: 1.1340 - val_soft_acc: 0.4386\n",
      "Epoch 687/1000\n",
      "453/453 [==============================] - 0s 773us/step - loss: 0.5893 - soft_acc: 0.7594 - val_loss: 0.9972 - val_soft_acc: 0.5263\n",
      "Epoch 688/1000\n",
      "453/453 [==============================] - 0s 677us/step - loss: 0.5662 - soft_acc: 0.7704 - val_loss: 1.2814 - val_soft_acc: 0.4123\n",
      "Epoch 689/1000\n",
      "453/453 [==============================] - 0s 568us/step - loss: 0.5952 - soft_acc: 0.7682 - val_loss: 1.0261 - val_soft_acc: 0.5088\n",
      "Epoch 690/1000\n",
      "453/453 [==============================] - 0s 570us/step - loss: 0.5775 - soft_acc: 0.7439 - val_loss: 1.1248 - val_soft_acc: 0.4298\n",
      "Epoch 691/1000\n",
      "453/453 [==============================] - 0s 579us/step - loss: 0.5736 - soft_acc: 0.7792 - val_loss: 1.0145 - val_soft_acc: 0.4912\n",
      "Epoch 692/1000\n",
      "453/453 [==============================] - 0s 640us/step - loss: 0.5738 - soft_acc: 0.7572 - val_loss: 1.0631 - val_soft_acc: 0.4561\n",
      "Epoch 693/1000\n",
      "453/453 [==============================] - 0s 584us/step - loss: 0.5653 - soft_acc: 0.7616 - val_loss: 1.0150 - val_soft_acc: 0.5088\n",
      "Epoch 694/1000\n",
      "453/453 [==============================] - 0s 574us/step - loss: 0.5733 - soft_acc: 0.7307 - val_loss: 1.0444 - val_soft_acc: 0.4737\n",
      "Epoch 695/1000\n",
      "453/453 [==============================] - 0s 569us/step - loss: 0.5702 - soft_acc: 0.7748 - val_loss: 1.1218 - val_soft_acc: 0.4298\n",
      "Epoch 696/1000\n",
      "453/453 [==============================] - 0s 562us/step - loss: 0.5641 - soft_acc: 0.7815 - val_loss: 1.0391 - val_soft_acc: 0.5000\n",
      "Epoch 697/1000\n",
      "453/453 [==============================] - 0s 571us/step - loss: 0.5728 - soft_acc: 0.7528 - val_loss: 1.0161 - val_soft_acc: 0.4912\n",
      "Epoch 698/1000\n",
      "453/453 [==============================] - 0s 565us/step - loss: 0.5729 - soft_acc: 0.7550 - val_loss: 1.0799 - val_soft_acc: 0.5000\n",
      "Epoch 699/1000\n",
      "453/453 [==============================] - 0s 572us/step - loss: 0.5747 - soft_acc: 0.7395 - val_loss: 1.1284 - val_soft_acc: 0.4386\n",
      "Epoch 700/1000\n",
      "453/453 [==============================] - 0s 573us/step - loss: 0.5743 - soft_acc: 0.7395 - val_loss: 1.0143 - val_soft_acc: 0.5175\n",
      "Epoch 701/1000\n",
      "453/453 [==============================] - 0s 573us/step - loss: 0.5595 - soft_acc: 0.7815 - val_loss: 1.1060 - val_soft_acc: 0.4737\n",
      "Epoch 702/1000\n",
      "453/453 [==============================] - 0s 567us/step - loss: 0.5661 - soft_acc: 0.7550 - val_loss: 1.0518 - val_soft_acc: 0.4649\n",
      "Epoch 703/1000\n",
      "453/453 [==============================] - 0s 566us/step - loss: 0.5601 - soft_acc: 0.7682 - val_loss: 1.0893 - val_soft_acc: 0.5088\n",
      "Epoch 704/1000\n",
      "453/453 [==============================] - 0s 564us/step - loss: 0.5784 - soft_acc: 0.7417 - val_loss: 1.0906 - val_soft_acc: 0.4561\n",
      "Epoch 705/1000\n",
      "453/453 [==============================] - 0s 567us/step - loss: 0.5698 - soft_acc: 0.7660 - val_loss: 1.0214 - val_soft_acc: 0.5000\n",
      "Epoch 706/1000\n",
      "453/453 [==============================] - 0s 564us/step - loss: 0.5599 - soft_acc: 0.7881 - val_loss: 1.1073 - val_soft_acc: 0.4561\n",
      "Epoch 707/1000\n",
      "453/453 [==============================] - 0s 567us/step - loss: 0.5632 - soft_acc: 0.7792 - val_loss: 1.0444 - val_soft_acc: 0.5088\n",
      "Epoch 708/1000\n",
      "453/453 [==============================] - 0s 564us/step - loss: 0.5755 - soft_acc: 0.7461 - val_loss: 0.9829 - val_soft_acc: 0.4737\n",
      "Epoch 709/1000\n",
      "453/453 [==============================] - 0s 572us/step - loss: 0.5696 - soft_acc: 0.7550 - val_loss: 1.0708 - val_soft_acc: 0.4649\n",
      "Epoch 710/1000\n",
      "453/453 [==============================] - 0s 578us/step - loss: 0.5539 - soft_acc: 0.7792 - val_loss: 1.0804 - val_soft_acc: 0.4737\n",
      "Epoch 711/1000\n",
      "453/453 [==============================] - 0s 567us/step - loss: 0.5849 - soft_acc: 0.7285 - val_loss: 1.0615 - val_soft_acc: 0.4825\n",
      "Epoch 712/1000\n",
      "453/453 [==============================] - 0s 570us/step - loss: 0.5763 - soft_acc: 0.7572 - val_loss: 1.1380 - val_soft_acc: 0.4298\n",
      "Epoch 713/1000\n",
      "453/453 [==============================] - 0s 574us/step - loss: 0.5671 - soft_acc: 0.7616 - val_loss: 1.0239 - val_soft_acc: 0.4912\n",
      "Epoch 714/1000\n",
      "453/453 [==============================] - 0s 563us/step - loss: 0.5684 - soft_acc: 0.7550 - val_loss: 1.0499 - val_soft_acc: 0.4825\n",
      "Epoch 715/1000\n",
      "453/453 [==============================] - 0s 569us/step - loss: 0.5530 - soft_acc: 0.7837 - val_loss: 1.0511 - val_soft_acc: 0.4825\n",
      "Epoch 716/1000\n",
      "453/453 [==============================] - 0s 572us/step - loss: 0.5933 - soft_acc: 0.7307 - val_loss: 1.1623 - val_soft_acc: 0.4474\n",
      "Epoch 717/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 580us/step - loss: 0.5726 - soft_acc: 0.7528 - val_loss: 1.0991 - val_soft_acc: 0.4561\n",
      "Epoch 718/1000\n",
      "453/453 [==============================] - 0s 571us/step - loss: 0.5572 - soft_acc: 0.7638 - val_loss: 1.0549 - val_soft_acc: 0.4825\n",
      "Epoch 719/1000\n",
      "453/453 [==============================] - 0s 582us/step - loss: 0.5699 - soft_acc: 0.7528 - val_loss: 1.0597 - val_soft_acc: 0.4737\n",
      "Epoch 720/1000\n",
      "453/453 [==============================] - 0s 571us/step - loss: 0.5616 - soft_acc: 0.7704 - val_loss: 1.2934 - val_soft_acc: 0.4035\n",
      "Epoch 721/1000\n",
      "453/453 [==============================] - 0s 577us/step - loss: 0.5789 - soft_acc: 0.7461 - val_loss: 1.0169 - val_soft_acc: 0.4825\n",
      "Epoch 722/1000\n",
      "453/453 [==============================] - 0s 564us/step - loss: 0.5630 - soft_acc: 0.7748 - val_loss: 1.0584 - val_soft_acc: 0.4912\n",
      "Epoch 723/1000\n",
      "453/453 [==============================] - 0s 583us/step - loss: 0.5691 - soft_acc: 0.7770 - val_loss: 1.0215 - val_soft_acc: 0.5000\n",
      "Epoch 724/1000\n",
      "453/453 [==============================] - 0s 571us/step - loss: 0.5609 - soft_acc: 0.7550 - val_loss: 1.0790 - val_soft_acc: 0.4561\n",
      "Epoch 725/1000\n",
      "453/453 [==============================] - 0s 578us/step - loss: 0.5681 - soft_acc: 0.7682 - val_loss: 1.1219 - val_soft_acc: 0.4825\n",
      "Epoch 726/1000\n",
      "453/453 [==============================] - 0s 580us/step - loss: 0.5862 - soft_acc: 0.7329 - val_loss: 1.0316 - val_soft_acc: 0.5175\n",
      "Epoch 727/1000\n",
      "453/453 [==============================] - 0s 570us/step - loss: 0.5760 - soft_acc: 0.7616 - val_loss: 1.1121 - val_soft_acc: 0.4825\n",
      "Epoch 728/1000\n",
      "453/453 [==============================] - 0s 577us/step - loss: 0.5695 - soft_acc: 0.7528 - val_loss: 1.0185 - val_soft_acc: 0.4561\n",
      "Epoch 729/1000\n",
      "453/453 [==============================] - 0s 574us/step - loss: 0.5716 - soft_acc: 0.7550 - val_loss: 1.0271 - val_soft_acc: 0.4912\n",
      "Epoch 730/1000\n",
      "453/453 [==============================] - 0s 578us/step - loss: 0.5596 - soft_acc: 0.7770 - val_loss: 1.1118 - val_soft_acc: 0.4912\n",
      "Epoch 731/1000\n",
      "453/453 [==============================] - 0s 577us/step - loss: 0.5768 - soft_acc: 0.7483 - val_loss: 1.0882 - val_soft_acc: 0.4474\n",
      "Epoch 732/1000\n",
      "453/453 [==============================] - 0s 578us/step - loss: 0.5635 - soft_acc: 0.7550 - val_loss: 1.1038 - val_soft_acc: 0.5000\n",
      "Epoch 733/1000\n",
      "453/453 [==============================] - 0s 571us/step - loss: 0.5698 - soft_acc: 0.7307 - val_loss: 1.0958 - val_soft_acc: 0.4737\n",
      "Epoch 734/1000\n",
      "453/453 [==============================] - 0s 577us/step - loss: 0.5794 - soft_acc: 0.7506 - val_loss: 1.1332 - val_soft_acc: 0.4561\n",
      "Epoch 735/1000\n",
      "453/453 [==============================] - 0s 569us/step - loss: 0.5800 - soft_acc: 0.7506 - val_loss: 1.0184 - val_soft_acc: 0.4737\n",
      "Epoch 736/1000\n",
      "453/453 [==============================] - 0s 587us/step - loss: 0.5546 - soft_acc: 0.7792 - val_loss: 1.1112 - val_soft_acc: 0.4561\n",
      "Epoch 737/1000\n",
      "453/453 [==============================] - 0s 570us/step - loss: 0.5771 - soft_acc: 0.7395 - val_loss: 1.0106 - val_soft_acc: 0.5000\n",
      "Epoch 738/1000\n",
      "453/453 [==============================] - 0s 570us/step - loss: 0.5562 - soft_acc: 0.7748 - val_loss: 1.0521 - val_soft_acc: 0.4561\n",
      "Epoch 739/1000\n",
      "453/453 [==============================] - 0s 566us/step - loss: 0.5554 - soft_acc: 0.7748 - val_loss: 1.0646 - val_soft_acc: 0.4649\n",
      "Epoch 740/1000\n",
      "453/453 [==============================] - 0s 566us/step - loss: 0.5776 - soft_acc: 0.7329 - val_loss: 1.0857 - val_soft_acc: 0.5088\n",
      "Epoch 741/1000\n",
      "453/453 [==============================] - 0s 569us/step - loss: 0.5716 - soft_acc: 0.7572 - val_loss: 1.0517 - val_soft_acc: 0.4825\n",
      "Epoch 742/1000\n",
      "453/453 [==============================] - 0s 574us/step - loss: 0.5575 - soft_acc: 0.7704 - val_loss: 1.0196 - val_soft_acc: 0.5000\n",
      "Epoch 743/1000\n",
      "453/453 [==============================] - 0s 588us/step - loss: 0.5678 - soft_acc: 0.7770 - val_loss: 1.1031 - val_soft_acc: 0.4386\n",
      "Epoch 744/1000\n",
      "453/453 [==============================] - 0s 610us/step - loss: 0.5657 - soft_acc: 0.7550 - val_loss: 1.1073 - val_soft_acc: 0.4825\n",
      "Epoch 745/1000\n",
      "453/453 [==============================] - 0s 583us/step - loss: 0.5638 - soft_acc: 0.7572 - val_loss: 1.1096 - val_soft_acc: 0.4298\n",
      "Epoch 746/1000\n",
      "453/453 [==============================] - 0s 566us/step - loss: 0.5782 - soft_acc: 0.7439 - val_loss: 1.0142 - val_soft_acc: 0.4912\n",
      "Epoch 747/1000\n",
      "453/453 [==============================] - 0s 564us/step - loss: 0.5639 - soft_acc: 0.7682 - val_loss: 1.0265 - val_soft_acc: 0.4649\n",
      "Epoch 748/1000\n",
      "453/453 [==============================] - 0s 576us/step - loss: 0.5574 - soft_acc: 0.7748 - val_loss: 1.0137 - val_soft_acc: 0.4737\n",
      "Epoch 749/1000\n",
      "453/453 [==============================] - 0s 567us/step - loss: 0.5615 - soft_acc: 0.7638 - val_loss: 1.0844 - val_soft_acc: 0.4649\n",
      "Epoch 750/1000\n",
      "453/453 [==============================] - 0s 566us/step - loss: 0.5693 - soft_acc: 0.7638 - val_loss: 1.1036 - val_soft_acc: 0.4561\n",
      "Epoch 751/1000\n",
      "453/453 [==============================] - 0s 573us/step - loss: 0.5596 - soft_acc: 0.7660 - val_loss: 1.0748 - val_soft_acc: 0.4649\n",
      "Epoch 752/1000\n",
      "453/453 [==============================] - 0s 569us/step - loss: 0.5599 - soft_acc: 0.7770 - val_loss: 0.9934 - val_soft_acc: 0.4912\n",
      "Epoch 753/1000\n",
      "453/453 [==============================] - 0s 562us/step - loss: 0.5561 - soft_acc: 0.7528 - val_loss: 1.1328 - val_soft_acc: 0.4386\n",
      "Epoch 754/1000\n",
      "453/453 [==============================] - 0s 573us/step - loss: 0.5675 - soft_acc: 0.7572 - val_loss: 1.0220 - val_soft_acc: 0.4825\n",
      "Epoch 755/1000\n",
      "453/453 [==============================] - 0s 572us/step - loss: 0.5544 - soft_acc: 0.7528 - val_loss: 1.3004 - val_soft_acc: 0.4211\n",
      "Epoch 756/1000\n",
      "453/453 [==============================] - 0s 568us/step - loss: 0.5800 - soft_acc: 0.7483 - val_loss: 1.0581 - val_soft_acc: 0.4737\n",
      "Epoch 757/1000\n",
      "453/453 [==============================] - 0s 581us/step - loss: 0.5491 - soft_acc: 0.7660 - val_loss: 1.1953 - val_soft_acc: 0.4298\n",
      "Epoch 758/1000\n",
      "453/453 [==============================] - 0s 581us/step - loss: 0.5792 - soft_acc: 0.7572 - val_loss: 1.0224 - val_soft_acc: 0.4737\n",
      "Epoch 759/1000\n",
      "453/453 [==============================] - 0s 606us/step - loss: 0.5578 - soft_acc: 0.7638 - val_loss: 1.0146 - val_soft_acc: 0.4825\n",
      "Epoch 760/1000\n",
      "453/453 [==============================] - 0s 592us/step - loss: 0.5490 - soft_acc: 0.7881 - val_loss: 1.0927 - val_soft_acc: 0.4737\n",
      "Epoch 761/1000\n",
      "453/453 [==============================] - 0s 594us/step - loss: 0.5670 - soft_acc: 0.7594 - val_loss: 0.9958 - val_soft_acc: 0.5175\n",
      "Epoch 762/1000\n",
      "453/453 [==============================] - 0s 591us/step - loss: 0.5539 - soft_acc: 0.7660 - val_loss: 0.9987 - val_soft_acc: 0.4912\n",
      "Epoch 763/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.5657 - soft_acc: 0.7483 - val_loss: 1.1101 - val_soft_acc: 0.4386\n",
      "Epoch 764/1000\n",
      "453/453 [==============================] - 0s 596us/step - loss: 0.5627 - soft_acc: 0.7638 - val_loss: 1.2040 - val_soft_acc: 0.4211\n",
      "Epoch 765/1000\n",
      "453/453 [==============================] - 0s 581us/step - loss: 0.5879 - soft_acc: 0.7439 - val_loss: 1.0584 - val_soft_acc: 0.5000\n",
      "Epoch 766/1000\n",
      "453/453 [==============================] - 0s 568us/step - loss: 0.5598 - soft_acc: 0.7748 - val_loss: 1.1207 - val_soft_acc: 0.4474\n",
      "Epoch 767/1000\n",
      "453/453 [==============================] - 0s 571us/step - loss: 0.5570 - soft_acc: 0.7660 - val_loss: 1.0812 - val_soft_acc: 0.5000\n",
      "Epoch 768/1000\n",
      "453/453 [==============================] - 0s 576us/step - loss: 0.5578 - soft_acc: 0.7660 - val_loss: 1.1507 - val_soft_acc: 0.4386\n",
      "Epoch 769/1000\n",
      "453/453 [==============================] - 0s 571us/step - loss: 0.5557 - soft_acc: 0.7682 - val_loss: 1.1287 - val_soft_acc: 0.4561\n",
      "Epoch 770/1000\n",
      "453/453 [==============================] - 0s 558us/step - loss: 0.5548 - soft_acc: 0.7726 - val_loss: 1.1575 - val_soft_acc: 0.4035\n",
      "Epoch 771/1000\n",
      "453/453 [==============================] - 0s 568us/step - loss: 0.5720 - soft_acc: 0.7550 - val_loss: 1.1679 - val_soft_acc: 0.4561\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 560us/step - loss: 0.5520 - soft_acc: 0.7815 - val_loss: 1.0113 - val_soft_acc: 0.4912\n",
      "Epoch 773/1000\n",
      "453/453 [==============================] - 0s 566us/step - loss: 0.5692 - soft_acc: 0.7439 - val_loss: 1.0340 - val_soft_acc: 0.4649\n",
      "Epoch 774/1000\n",
      "453/453 [==============================] - 0s 572us/step - loss: 0.5571 - soft_acc: 0.7792 - val_loss: 1.1483 - val_soft_acc: 0.4386\n",
      "Epoch 775/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.5675 - soft_acc: 0.7616 - val_loss: 1.0408 - val_soft_acc: 0.4825\n",
      "Epoch 776/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.5620 - soft_acc: 0.7770 - val_loss: 1.0917 - val_soft_acc: 0.4649\n",
      "Epoch 777/1000\n",
      "453/453 [==============================] - 0s 576us/step - loss: 0.5626 - soft_acc: 0.7616 - val_loss: 1.0093 - val_soft_acc: 0.4825\n",
      "Epoch 778/1000\n",
      "453/453 [==============================] - 0s 592us/step - loss: 0.5554 - soft_acc: 0.7660 - val_loss: 1.1226 - val_soft_acc: 0.4298\n",
      "Epoch 779/1000\n",
      "453/453 [==============================] - 0s 569us/step - loss: 0.5595 - soft_acc: 0.7770 - val_loss: 1.0353 - val_soft_acc: 0.4649\n",
      "Epoch 780/1000\n",
      "453/453 [==============================] - 0s 562us/step - loss: 0.5674 - soft_acc: 0.7726 - val_loss: 1.0382 - val_soft_acc: 0.4649\n",
      "Epoch 781/1000\n",
      "453/453 [==============================] - 0s 575us/step - loss: 0.5709 - soft_acc: 0.7572 - val_loss: 1.1624 - val_soft_acc: 0.4386\n",
      "Epoch 782/1000\n",
      "453/453 [==============================] - 0s 588us/step - loss: 0.5696 - soft_acc: 0.7528 - val_loss: 1.0407 - val_soft_acc: 0.4649\n",
      "Epoch 783/1000\n",
      "453/453 [==============================] - 0s 593us/step - loss: 0.5537 - soft_acc: 0.7638 - val_loss: 1.0371 - val_soft_acc: 0.5000\n",
      "Epoch 784/1000\n",
      "453/453 [==============================] - 0s 568us/step - loss: 0.5686 - soft_acc: 0.7572 - val_loss: 1.0391 - val_soft_acc: 0.5000\n",
      "Epoch 785/1000\n",
      "453/453 [==============================] - 0s 568us/step - loss: 0.5493 - soft_acc: 0.7704 - val_loss: 1.0224 - val_soft_acc: 0.5000\n",
      "Epoch 786/1000\n",
      "453/453 [==============================] - 0s 575us/step - loss: 0.5668 - soft_acc: 0.7682 - val_loss: 1.0505 - val_soft_acc: 0.4912\n",
      "Epoch 787/1000\n",
      "453/453 [==============================] - 0s 587us/step - loss: 0.5775 - soft_acc: 0.7417 - val_loss: 1.0508 - val_soft_acc: 0.4737\n",
      "Epoch 788/1000\n",
      "453/453 [==============================] - 0s 593us/step - loss: 0.5612 - soft_acc: 0.7660 - val_loss: 1.0778 - val_soft_acc: 0.4737\n",
      "Epoch 789/1000\n",
      "453/453 [==============================] - 0s 593us/step - loss: 0.5538 - soft_acc: 0.7704 - val_loss: 1.0325 - val_soft_acc: 0.5088\n",
      "Epoch 790/1000\n",
      "453/453 [==============================] - 0s 588us/step - loss: 0.5560 - soft_acc: 0.7704 - val_loss: 1.0357 - val_soft_acc: 0.4561\n",
      "Epoch 791/1000\n",
      "453/453 [==============================] - 0s 602us/step - loss: 0.5525 - soft_acc: 0.7748 - val_loss: 1.0791 - val_soft_acc: 0.4561\n",
      "Epoch 792/1000\n",
      "453/453 [==============================] - 0s 590us/step - loss: 0.5716 - soft_acc: 0.7461 - val_loss: 1.0668 - val_soft_acc: 0.4737\n",
      "Epoch 793/1000\n",
      "453/453 [==============================] - 0s 598us/step - loss: 0.5528 - soft_acc: 0.7881 - val_loss: 1.0358 - val_soft_acc: 0.5000\n",
      "Epoch 794/1000\n",
      "453/453 [==============================] - 0s 629us/step - loss: 0.5578 - soft_acc: 0.7815 - val_loss: 1.0334 - val_soft_acc: 0.4825\n",
      "Epoch 795/1000\n",
      "453/453 [==============================] - 0s 573us/step - loss: 0.5481 - soft_acc: 0.7550 - val_loss: 1.0391 - val_soft_acc: 0.4649\n",
      "Epoch 796/1000\n",
      "453/453 [==============================] - 0s 623us/step - loss: 0.5666 - soft_acc: 0.7594 - val_loss: 1.0193 - val_soft_acc: 0.5000\n",
      "Epoch 797/1000\n",
      "453/453 [==============================] - 0s 604us/step - loss: 0.5589 - soft_acc: 0.7616 - val_loss: 1.0036 - val_soft_acc: 0.5175\n",
      "Epoch 798/1000\n",
      "453/453 [==============================] - 0s 601us/step - loss: 0.5598 - soft_acc: 0.7748 - val_loss: 1.0184 - val_soft_acc: 0.5175\n",
      "Epoch 799/1000\n",
      "453/453 [==============================] - 0s 587us/step - loss: 0.5549 - soft_acc: 0.7638 - val_loss: 1.0280 - val_soft_acc: 0.4825\n",
      "Epoch 800/1000\n",
      "453/453 [==============================] - 0s 603us/step - loss: 0.5498 - soft_acc: 0.7638 - val_loss: 1.0135 - val_soft_acc: 0.4825\n",
      "Epoch 801/1000\n",
      "453/453 [==============================] - 0s 620us/step - loss: 0.5542 - soft_acc: 0.7837 - val_loss: 1.1637 - val_soft_acc: 0.4474\n",
      "Epoch 802/1000\n",
      "453/453 [==============================] - 0s 595us/step - loss: 0.5709 - soft_acc: 0.7483 - val_loss: 1.0835 - val_soft_acc: 0.4298\n",
      "Epoch 803/1000\n",
      "453/453 [==============================] - 0s 580us/step - loss: 0.5469 - soft_acc: 0.7660 - val_loss: 1.0479 - val_soft_acc: 0.4912\n",
      "Epoch 804/1000\n",
      "453/453 [==============================] - 0s 577us/step - loss: 0.5625 - soft_acc: 0.7461 - val_loss: 1.1348 - val_soft_acc: 0.4561\n",
      "Epoch 805/1000\n",
      "453/453 [==============================] - 0s 577us/step - loss: 0.5493 - soft_acc: 0.7483 - val_loss: 1.1165 - val_soft_acc: 0.4649\n",
      "Epoch 806/1000\n",
      "453/453 [==============================] - 0s 577us/step - loss: 0.5611 - soft_acc: 0.7748 - val_loss: 1.0109 - val_soft_acc: 0.5000\n",
      "Epoch 807/1000\n",
      "453/453 [==============================] - 0s 571us/step - loss: 0.5531 - soft_acc: 0.7792 - val_loss: 1.0259 - val_soft_acc: 0.5000\n",
      "Epoch 808/1000\n",
      "453/453 [==============================] - 0s 574us/step - loss: 0.5483 - soft_acc: 0.7815 - val_loss: 1.0101 - val_soft_acc: 0.5088\n",
      "Epoch 809/1000\n",
      "453/453 [==============================] - 0s 570us/step - loss: 0.5599 - soft_acc: 0.7770 - val_loss: 1.1551 - val_soft_acc: 0.4561\n",
      "Epoch 810/1000\n",
      "453/453 [==============================] - 0s 568us/step - loss: 0.5564 - soft_acc: 0.7748 - val_loss: 1.1806 - val_soft_acc: 0.4386\n",
      "Epoch 811/1000\n",
      "453/453 [==============================] - 0s 568us/step - loss: 0.5621 - soft_acc: 0.7616 - val_loss: 1.0394 - val_soft_acc: 0.5088\n",
      "Epoch 812/1000\n",
      "453/453 [==============================] - 0s 573us/step - loss: 0.5467 - soft_acc: 0.8079 - val_loss: 1.0443 - val_soft_acc: 0.4825\n",
      "Epoch 813/1000\n",
      "453/453 [==============================] - 0s 575us/step - loss: 0.5428 - soft_acc: 0.7859 - val_loss: 1.1056 - val_soft_acc: 0.4825\n",
      "Epoch 814/1000\n",
      "453/453 [==============================] - 0s 564us/step - loss: 0.5654 - soft_acc: 0.7528 - val_loss: 1.0538 - val_soft_acc: 0.4737\n",
      "Epoch 815/1000\n",
      "453/453 [==============================] - 0s 568us/step - loss: 0.5428 - soft_acc: 0.7881 - val_loss: 1.0044 - val_soft_acc: 0.5088\n",
      "Epoch 816/1000\n",
      "453/453 [==============================] - 0s 572us/step - loss: 0.5467 - soft_acc: 0.7682 - val_loss: 1.2230 - val_soft_acc: 0.3860\n",
      "Epoch 817/1000\n",
      "453/453 [==============================] - 0s 568us/step - loss: 0.5923 - soft_acc: 0.7373 - val_loss: 1.0173 - val_soft_acc: 0.4912\n",
      "Epoch 818/1000\n",
      "453/453 [==============================] - 0s 590us/step - loss: 0.5432 - soft_acc: 0.7792 - val_loss: 1.0266 - val_soft_acc: 0.5000\n",
      "Epoch 819/1000\n",
      "453/453 [==============================] - 0s 593us/step - loss: 0.5515 - soft_acc: 0.7682 - val_loss: 1.1673 - val_soft_acc: 0.4649\n",
      "Epoch 820/1000\n",
      "453/453 [==============================] - 0s 599us/step - loss: 0.5698 - soft_acc: 0.7682 - val_loss: 1.0719 - val_soft_acc: 0.4737\n",
      "Epoch 821/1000\n",
      "453/453 [==============================] - 0s 611us/step - loss: 0.5558 - soft_acc: 0.7682 - val_loss: 1.0198 - val_soft_acc: 0.5351\n",
      "Epoch 822/1000\n",
      "453/453 [==============================] - 0s 599us/step - loss: 0.5450 - soft_acc: 0.7616 - val_loss: 0.9957 - val_soft_acc: 0.5351\n",
      "Epoch 823/1000\n",
      "453/453 [==============================] - 0s 621us/step - loss: 0.5443 - soft_acc: 0.7792 - val_loss: 1.0632 - val_soft_acc: 0.5088\n",
      "Epoch 824/1000\n",
      "453/453 [==============================] - 0s 599us/step - loss: 0.5630 - soft_acc: 0.7594 - val_loss: 1.0222 - val_soft_acc: 0.4737\n",
      "Epoch 825/1000\n",
      "453/453 [==============================] - 0s 586us/step - loss: 0.5525 - soft_acc: 0.7594 - val_loss: 0.9899 - val_soft_acc: 0.4912\n",
      "Epoch 826/1000\n",
      "453/453 [==============================] - 0s 584us/step - loss: 0.5484 - soft_acc: 0.7815 - val_loss: 1.0033 - val_soft_acc: 0.5351\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 589us/step - loss: 0.5512 - soft_acc: 0.7682 - val_loss: 1.0634 - val_soft_acc: 0.4825\n",
      "Epoch 828/1000\n",
      "453/453 [==============================] - 0s 576us/step - loss: 0.5452 - soft_acc: 0.7748 - val_loss: 1.0998 - val_soft_acc: 0.4912\n",
      "Epoch 829/1000\n",
      "453/453 [==============================] - 0s 589us/step - loss: 0.5522 - soft_acc: 0.7748 - val_loss: 1.2286 - val_soft_acc: 0.4211\n",
      "Epoch 830/1000\n",
      "453/453 [==============================] - 0s 578us/step - loss: 0.5764 - soft_acc: 0.7528 - val_loss: 1.0438 - val_soft_acc: 0.5000\n",
      "Epoch 831/1000\n",
      "453/453 [==============================] - 0s 580us/step - loss: 0.5496 - soft_acc: 0.7881 - val_loss: 1.0550 - val_soft_acc: 0.4737\n",
      "Epoch 832/1000\n",
      "453/453 [==============================] - 0s 586us/step - loss: 0.5429 - soft_acc: 0.7837 - val_loss: 0.9968 - val_soft_acc: 0.5175\n",
      "Epoch 833/1000\n",
      "453/453 [==============================] - 0s 582us/step - loss: 0.5513 - soft_acc: 0.7704 - val_loss: 1.1378 - val_soft_acc: 0.4561\n",
      "Epoch 834/1000\n",
      "453/453 [==============================] - 0s 584us/step - loss: 0.5641 - soft_acc: 0.7373 - val_loss: 1.1778 - val_soft_acc: 0.4386\n",
      "Epoch 835/1000\n",
      "453/453 [==============================] - 0s 573us/step - loss: 0.5519 - soft_acc: 0.7815 - val_loss: 1.0517 - val_soft_acc: 0.5263\n",
      "Epoch 836/1000\n",
      "453/453 [==============================] - 0s 590us/step - loss: 0.5554 - soft_acc: 0.7594 - val_loss: 1.0249 - val_soft_acc: 0.5351\n",
      "Epoch 837/1000\n",
      "453/453 [==============================] - 0s 586us/step - loss: 0.5569 - soft_acc: 0.7704 - val_loss: 1.2057 - val_soft_acc: 0.4386\n",
      "Epoch 838/1000\n",
      "453/453 [==============================] - 0s 590us/step - loss: 0.5586 - soft_acc: 0.7638 - val_loss: 1.1301 - val_soft_acc: 0.4386\n",
      "Epoch 839/1000\n",
      "453/453 [==============================] - 0s 585us/step - loss: 0.5587 - soft_acc: 0.7638 - val_loss: 1.0086 - val_soft_acc: 0.4912\n",
      "Epoch 840/1000\n",
      "453/453 [==============================] - 0s 595us/step - loss: 0.5442 - soft_acc: 0.7638 - val_loss: 1.0697 - val_soft_acc: 0.4649\n",
      "Epoch 841/1000\n",
      "453/453 [==============================] - 0s 584us/step - loss: 0.5480 - soft_acc: 0.7748 - val_loss: 1.0225 - val_soft_acc: 0.5000\n",
      "Epoch 842/1000\n",
      "453/453 [==============================] - 0s 575us/step - loss: 0.5486 - soft_acc: 0.7748 - val_loss: 1.0813 - val_soft_acc: 0.4649\n",
      "Epoch 843/1000\n",
      "453/453 [==============================] - 0s 577us/step - loss: 0.5737 - soft_acc: 0.7329 - val_loss: 1.0580 - val_soft_acc: 0.4737\n",
      "Epoch 844/1000\n",
      "453/453 [==============================] - 0s 572us/step - loss: 0.5410 - soft_acc: 0.7792 - val_loss: 1.0379 - val_soft_acc: 0.5175\n",
      "Epoch 845/1000\n",
      "453/453 [==============================] - 0s 573us/step - loss: 0.5490 - soft_acc: 0.7792 - val_loss: 1.0498 - val_soft_acc: 0.4825\n",
      "Epoch 846/1000\n",
      "453/453 [==============================] - 0s 578us/step - loss: 0.5474 - soft_acc: 0.7815 - val_loss: 1.0375 - val_soft_acc: 0.4737\n",
      "Epoch 847/1000\n",
      "453/453 [==============================] - 0s 573us/step - loss: 0.5591 - soft_acc: 0.7616 - val_loss: 1.0111 - val_soft_acc: 0.5263\n",
      "Epoch 848/1000\n",
      "453/453 [==============================] - 0s 572us/step - loss: 0.5537 - soft_acc: 0.7572 - val_loss: 1.1586 - val_soft_acc: 0.4561\n",
      "Epoch 849/1000\n",
      "453/453 [==============================] - 0s 573us/step - loss: 0.5564 - soft_acc: 0.7572 - val_loss: 1.0146 - val_soft_acc: 0.5263\n",
      "Epoch 850/1000\n",
      "453/453 [==============================] - 0s 571us/step - loss: 0.5541 - soft_acc: 0.7483 - val_loss: 1.0765 - val_soft_acc: 0.4737\n",
      "Epoch 851/1000\n",
      "453/453 [==============================] - 0s 571us/step - loss: 0.5440 - soft_acc: 0.7770 - val_loss: 1.0301 - val_soft_acc: 0.5000\n",
      "Epoch 852/1000\n",
      "453/453 [==============================] - 0s 577us/step - loss: 0.5433 - soft_acc: 0.7682 - val_loss: 1.0696 - val_soft_acc: 0.5088\n",
      "Epoch 853/1000\n",
      "453/453 [==============================] - 0s 571us/step - loss: 0.5796 - soft_acc: 0.7351 - val_loss: 0.9900 - val_soft_acc: 0.5439\n",
      "Epoch 854/1000\n",
      "453/453 [==============================] - 0s 577us/step - loss: 0.5433 - soft_acc: 0.7726 - val_loss: 1.1103 - val_soft_acc: 0.4561\n",
      "Epoch 855/1000\n",
      "453/453 [==============================] - 0s 584us/step - loss: 0.5591 - soft_acc: 0.7792 - val_loss: 1.0115 - val_soft_acc: 0.5000\n",
      "Epoch 856/1000\n",
      "453/453 [==============================] - 0s 568us/step - loss: 0.5443 - soft_acc: 0.7770 - val_loss: 1.0227 - val_soft_acc: 0.4825\n",
      "Epoch 857/1000\n",
      "453/453 [==============================] - 0s 592us/step - loss: 0.5560 - soft_acc: 0.7572 - val_loss: 1.0532 - val_soft_acc: 0.5263\n",
      "Epoch 858/1000\n",
      "453/453 [==============================] - 0s 570us/step - loss: 0.5685 - soft_acc: 0.7572 - val_loss: 1.0797 - val_soft_acc: 0.4825\n",
      "Epoch 859/1000\n",
      "453/453 [==============================] - 0s 586us/step - loss: 0.5434 - soft_acc: 0.7726 - val_loss: 1.0462 - val_soft_acc: 0.5088\n",
      "Epoch 860/1000\n",
      "453/453 [==============================] - 0s 579us/step - loss: 0.5608 - soft_acc: 0.7616 - val_loss: 1.0210 - val_soft_acc: 0.4912\n",
      "Epoch 861/1000\n",
      "453/453 [==============================] - 0s 578us/step - loss: 0.5523 - soft_acc: 0.7815 - val_loss: 1.0457 - val_soft_acc: 0.4825\n",
      "Epoch 862/1000\n",
      "453/453 [==============================] - 0s 581us/step - loss: 0.5524 - soft_acc: 0.7726 - val_loss: 1.0571 - val_soft_acc: 0.5439\n",
      "Epoch 863/1000\n",
      "453/453 [==============================] - 0s 579us/step - loss: 0.5651 - soft_acc: 0.7395 - val_loss: 0.9965 - val_soft_acc: 0.5439\n",
      "Epoch 864/1000\n",
      "453/453 [==============================] - 0s 575us/step - loss: 0.5482 - soft_acc: 0.7704 - val_loss: 1.0023 - val_soft_acc: 0.5088\n",
      "Epoch 865/1000\n",
      "453/453 [==============================] - 0s 576us/step - loss: 0.5431 - soft_acc: 0.7748 - val_loss: 1.0322 - val_soft_acc: 0.5263\n",
      "Epoch 866/1000\n",
      "453/453 [==============================] - 0s 583us/step - loss: 0.5596 - soft_acc: 0.7506 - val_loss: 1.0421 - val_soft_acc: 0.4825\n",
      "Epoch 867/1000\n",
      "453/453 [==============================] - 0s 581us/step - loss: 0.5554 - soft_acc: 0.7528 - val_loss: 1.0312 - val_soft_acc: 0.5088\n",
      "Epoch 868/1000\n",
      "453/453 [==============================] - 0s 577us/step - loss: 0.5402 - soft_acc: 0.7815 - val_loss: 1.1986 - val_soft_acc: 0.4386\n",
      "Epoch 869/1000\n",
      "453/453 [==============================] - 0s 581us/step - loss: 0.5643 - soft_acc: 0.7550 - val_loss: 0.9914 - val_soft_acc: 0.5000\n",
      "Epoch 870/1000\n",
      "453/453 [==============================] - 0s 575us/step - loss: 0.5422 - soft_acc: 0.7815 - val_loss: 1.1075 - val_soft_acc: 0.4825\n",
      "Epoch 871/1000\n",
      "453/453 [==============================] - 0s 575us/step - loss: 0.5586 - soft_acc: 0.7748 - val_loss: 1.0538 - val_soft_acc: 0.5088\n",
      "Epoch 872/1000\n",
      "453/453 [==============================] - 0s 595us/step - loss: 0.5486 - soft_acc: 0.7682 - val_loss: 1.0332 - val_soft_acc: 0.5263\n",
      "Epoch 873/1000\n",
      "453/453 [==============================] - 0s 580us/step - loss: 0.5534 - soft_acc: 0.7704 - val_loss: 1.1706 - val_soft_acc: 0.4386\n",
      "Epoch 874/1000\n",
      "453/453 [==============================] - 0s 582us/step - loss: 0.5561 - soft_acc: 0.7660 - val_loss: 1.0262 - val_soft_acc: 0.5351\n",
      "Epoch 875/1000\n",
      "453/453 [==============================] - 0s 571us/step - loss: 0.5463 - soft_acc: 0.7837 - val_loss: 1.0109 - val_soft_acc: 0.5175\n",
      "Epoch 876/1000\n",
      " 50/453 [==>...........................] - ETA: 0s - loss: 0.5624 - soft_acc: 0.7800"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='acc',patience=20, mode='auto')\n",
    "model.compile(optimizer=RMSprop(),\n",
    "loss='mse',\n",
    "metrics=[soft_acc])\n",
    "history = model.fit(data, tags,\n",
    "epochs=1000,  \n",
    "batch_size=50,\n",
    "validation_split=0.2,\n",
    "callbacks=[])\n",
    "# model.save_weights('pre_trained_glove_model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "soft_acc = history.history['soft_acc']\n",
    "soft_val_acc = history.history['val_soft_acc']\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.figure(figsize=(30,5))\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, soft_acc, 'ro', label='Soft Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.plot(epochs, soft_val_acc, 'r', label='Soft Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure(figsize=(30,5))\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(data, tags)\n",
    "print(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
