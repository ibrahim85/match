{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Readability Assessment through Learning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Readability assessment is a well known problem in natural language processing field. \n",
    "* Giving someone the suitable text for his level of comprehension (not so easy and not so hard) could maximize his understanding and enjoyment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this notebook we are trying to assess the readability of a given text regardless of the text topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Corpus\n",
    "> OneStopEnglish corpus: A new corpus for automatic readability assessment and text simplification  \n",
    "> Sowmya Vajjala and Ivana Lučić  \n",
    "> 2018  \n",
    "> Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications, pages 297–304. Association for Computational Linguistics.  \n",
    "> [url](http://aclweb.org/anthology/W18-0535). [bib file](https://aclanthology.coli.uni-saarland.de/papers/W18-0535/w18-0535.bib)\n",
    "\n",
    "Please cite the above paper if you use this corpus in your research.\n",
    "\n",
    "[![DOI](https://zenodo.org/badge/128919409.svg)](https://zenodo.org/badge/latestdoi/128919409)\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now let's dive into our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ms10596/PycharmProjects/match\")\n",
    "from ipywidgets import interact\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from utils.loading import load_glove_embeddings, load_old_corpus\n",
    "from utils.one_stop_english import load_corpus, corpus_to_words, corpus_to_pos, detokenize\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, LSTM, Bidirectional,Conv1D,MaxPooling1D,GlobalMaxPooling1D, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "corpus = load_corpus()\n",
    "articles_words, tags = corpus_to_words(corpus)\n",
    "articles_pos, tags = corpus_to_pos(corpus)\n",
    "old_articles_pos, old_articles_tags = load_old_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Reading level|Avg. Num. Words|Std. Dev|Number of Articles\n",
    "---|---|---|---\n",
    "Elementary|533.17|103.79|189\n",
    "Intermediate|676.59|117.15|189\n",
    "Advanced|820.49|162.52|189\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0bfe9ef22554211bef3384e88df7426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=94, description='i', max=188), IntSlider(value=500, description='words',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def show_articles(i=(0,188,1), words=(0,1000,1)):\n",
    "    data = [\n",
    "        [\"Advanced\",detokenize(articles_words[i][:words])], \n",
    "        [\"Intermediate\",detokenize(articles_words[i+2][:words])], \n",
    "        [\"Elementary\",detokenize(articles_words[i+1][:words])]\n",
    "    ]\n",
    "    headers = ['Reading Level', 'Example']\n",
    "    display(HTML(tabulate(data,tablefmt='html', headers=headers)+\"<style>th,td {font-size: 20px}</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Converting words to part of speech tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When', 'you', 'see', 'the', 'word', 'Amazon', ',', 'whats', 'the', 'first']\n",
      "['WRB', 'PRP', 'VB', 'DT', 'NN', 'NN', ',', 'VBZ', 'DT', 'JJ']\n"
     ]
    }
   ],
   "source": [
    "print(articles_words[0][:10])\n",
    "print(articles_pos[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Converting part of speech to sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "maxlen = 1000 # Cuts off reviews after 1000 words\n",
    "max_words = 45\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(articles_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(567,)\n",
      "(183,)\n"
     ]
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(articles_pos)\n",
    "old_sequences = tokenizer.texts_to_sequences(old_articles_pos)\n",
    "print(np.shape(sequences))\n",
    "print(np.shape(old_sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(567, 1000)\n",
      "(183, 1000)\n"
     ]
    }
   ],
   "source": [
    "data = pad_sequences(sequences, maxlen=maxlen, padding='post', truncating='post')\n",
    "old_data = pad_sequences(old_sequences, maxlen=maxlen, padding='post', truncating='post')\n",
    "print(np.shape(data))\n",
    "print(np.shape(old_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(567,)\n",
      "(183,)\n"
     ]
    }
   ],
   "source": [
    "tags = np.array(tags)\n",
    "old_tags = np.array(old_articles_tags)\n",
    "print(tags.shape)\n",
    "print(old_tags.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Convert sequences to one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(567, 1000, 45)\n",
      "(183, 1000, 45)\n"
     ]
    }
   ],
   "source": [
    "data = to_categorical(data)\n",
    "old_data = to_categorical(old_data)\n",
    "print(data.shape)\n",
    "print(old_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Randomize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(567, 1000, 45)\n",
      "(567,)\n",
      "(183, 1000, 45)\n",
      "(183,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "data = data[indices]\n",
    "tags = tags[indices]\n",
    "\n",
    "old_indices = np.arange(old_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "old_data = old_data[old_indices]\n",
    "old_tags = old_tags[old_indices]\n",
    "print(data.shape)\n",
    "print(tags.shape)\n",
    "\n",
    "print(old_data.shape)\n",
    "print(old_tags.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structuring the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(7, 10, activation='relu',kernel_regularizer=l1(0.038), input_shape=(1000,45)))\n",
    "# model.add(MaxPooling1D(5))\n",
    "# model.add(Conv1D(64, 5, activation='relu',kernel_regularizer=l1_l2(l1=0.001, l2=0.001)))\n",
    "# model.add(MaxPooling1D(5))\n",
    "# model.add(Conv1D(32, 5, activation='relu',kernel_regularizer=l1_l2(l1=0.0003, l2=0.0003)))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(1))\n",
    "def soft_acc(y_true, y_pred):\n",
    "    from tensorflow.python.keras import backend as K\n",
    "    return K.mean(K.equal(K.round(y_true), K.round(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 114 samples\n",
      "Epoch 1/2000\n",
      "453/453 [==============================] - 3s 8ms/step - loss: 7.6696 - soft_acc: 0.3355 - val_loss: 6.5118 - val_soft_acc: 0.3246\n",
      "Epoch 2/2000\n",
      "453/453 [==============================] - 0s 295us/step - loss: 5.7842 - soft_acc: 0.3311 - val_loss: 5.1584 - val_soft_acc: 0.3246\n",
      "Epoch 3/2000\n",
      "453/453 [==============================] - 0s 304us/step - loss: 4.6190 - soft_acc: 0.3510 - val_loss: 4.1569 - val_soft_acc: 0.3246\n",
      "Epoch 4/2000\n",
      "453/453 [==============================] - 0s 289us/step - loss: 3.7293 - soft_acc: 0.3466 - val_loss: 3.3865 - val_soft_acc: 0.3158\n",
      "Epoch 5/2000\n",
      "453/453 [==============================] - 0s 287us/step - loss: 3.0297 - soft_acc: 0.3422 - val_loss: 2.7117 - val_soft_acc: 0.3070\n",
      "Epoch 6/2000\n",
      "453/453 [==============================] - 0s 296us/step - loss: 2.4334 - soft_acc: 0.3400 - val_loss: 2.2045 - val_soft_acc: 0.3070\n",
      "Epoch 7/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 1.9700 - soft_acc: 0.3400 - val_loss: 1.7884 - val_soft_acc: 0.3070\n",
      "Epoch 8/2000\n",
      "453/453 [==============================] - 0s 288us/step - loss: 1.6039 - soft_acc: 0.3400 - val_loss: 1.4727 - val_soft_acc: 0.3070\n",
      "Epoch 9/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 1.3370 - soft_acc: 0.3400 - val_loss: 1.2628 - val_soft_acc: 0.3070\n",
      "Epoch 10/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 1.1728 - soft_acc: 0.3400 - val_loss: 1.1613 - val_soft_acc: 0.3070\n",
      "Epoch 11/2000\n",
      "453/453 [==============================] - 0s 284us/step - loss: 1.0909 - soft_acc: 0.3400 - val_loss: 1.1044 - val_soft_acc: 0.3070\n",
      "Epoch 12/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 1.0346 - soft_acc: 0.3400 - val_loss: 1.0493 - val_soft_acc: 0.3070\n",
      "Epoch 13/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.9888 - soft_acc: 0.3400 - val_loss: 1.0066 - val_soft_acc: 0.3070\n",
      "Epoch 14/2000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.9490 - soft_acc: 0.3400 - val_loss: 0.9710 - val_soft_acc: 0.3070\n",
      "Epoch 15/2000\n",
      "453/453 [==============================] - 0s 289us/step - loss: 0.9164 - soft_acc: 0.3400 - val_loss: 0.9414 - val_soft_acc: 0.3070\n",
      "Epoch 16/2000\n",
      "453/453 [==============================] - 0s 293us/step - loss: 0.8885 - soft_acc: 0.3400 - val_loss: 0.9204 - val_soft_acc: 0.3070\n",
      "Epoch 17/2000\n",
      "453/453 [==============================] - 0s 291us/step - loss: 0.8681 - soft_acc: 0.3400 - val_loss: 0.9033 - val_soft_acc: 0.3070\n",
      "Epoch 18/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.8513 - soft_acc: 0.3400 - val_loss: 0.8836 - val_soft_acc: 0.3070\n",
      "Epoch 19/2000\n",
      "453/453 [==============================] - 0s 290us/step - loss: 0.8372 - soft_acc: 0.3400 - val_loss: 0.8765 - val_soft_acc: 0.3070\n",
      "Epoch 20/2000\n",
      "453/453 [==============================] - 0s 285us/step - loss: 0.8266 - soft_acc: 0.3400 - val_loss: 0.8733 - val_soft_acc: 0.3070\n",
      "Epoch 21/2000\n",
      "453/453 [==============================] - 0s 301us/step - loss: 0.8193 - soft_acc: 0.3400 - val_loss: 0.8620 - val_soft_acc: 0.3070\n",
      "Epoch 22/2000\n",
      "453/453 [==============================] - 0s 310us/step - loss: 0.8116 - soft_acc: 0.3400 - val_loss: 0.8622 - val_soft_acc: 0.3070\n",
      "Epoch 23/2000\n",
      "453/453 [==============================] - 0s 306us/step - loss: 0.8066 - soft_acc: 0.3400 - val_loss: 0.8481 - val_soft_acc: 0.3070\n",
      "Epoch 24/2000\n",
      "453/453 [==============================] - 0s 296us/step - loss: 0.8005 - soft_acc: 0.3400 - val_loss: 0.8416 - val_soft_acc: 0.3070\n",
      "Epoch 25/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.7959 - soft_acc: 0.3400 - val_loss: 0.8402 - val_soft_acc: 0.3070\n",
      "Epoch 26/2000\n",
      "453/453 [==============================] - 0s 293us/step - loss: 0.7910 - soft_acc: 0.3400 - val_loss: 0.8433 - val_soft_acc: 0.3070\n",
      "Epoch 27/2000\n",
      "453/453 [==============================] - 0s 314us/step - loss: 0.7891 - soft_acc: 0.3400 - val_loss: 0.8333 - val_soft_acc: 0.3070\n",
      "Epoch 28/2000\n",
      "453/453 [==============================] - 0s 291us/step - loss: 0.7850 - soft_acc: 0.3400 - val_loss: 0.8287 - val_soft_acc: 0.3070\n",
      "Epoch 29/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.7815 - soft_acc: 0.3400 - val_loss: 0.8337 - val_soft_acc: 0.3070\n",
      "Epoch 30/2000\n",
      "453/453 [==============================] - 0s 306us/step - loss: 0.7802 - soft_acc: 0.3400 - val_loss: 0.8261 - val_soft_acc: 0.3070\n",
      "Epoch 31/2000\n",
      "453/453 [==============================] - 0s 303us/step - loss: 0.7775 - soft_acc: 0.3400 - val_loss: 0.8249 - val_soft_acc: 0.3070\n",
      "Epoch 32/2000\n",
      "453/453 [==============================] - 0s 288us/step - loss: 0.7741 - soft_acc: 0.3400 - val_loss: 0.8169 - val_soft_acc: 0.3070\n",
      "Epoch 33/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.7716 - soft_acc: 0.3400 - val_loss: 0.8151 - val_soft_acc: 0.3070\n",
      "Epoch 34/2000\n",
      "453/453 [==============================] - 0s 292us/step - loss: 0.7686 - soft_acc: 0.3400 - val_loss: 0.8156 - val_soft_acc: 0.3070\n",
      "Epoch 35/2000\n",
      "453/453 [==============================] - 0s 287us/step - loss: 0.7675 - soft_acc: 0.3400 - val_loss: 0.8156 - val_soft_acc: 0.3070\n",
      "Epoch 36/2000\n",
      "453/453 [==============================] - 0s 291us/step - loss: 0.7648 - soft_acc: 0.3400 - val_loss: 0.8101 - val_soft_acc: 0.3070\n",
      "Epoch 37/2000\n",
      "453/453 [==============================] - 0s 288us/step - loss: 0.7644 - soft_acc: 0.3400 - val_loss: 0.8128 - val_soft_acc: 0.3070\n",
      "Epoch 38/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.7617 - soft_acc: 0.3400 - val_loss: 0.8120 - val_soft_acc: 0.3070\n",
      "Epoch 39/2000\n",
      "453/453 [==============================] - 0s 287us/step - loss: 0.7601 - soft_acc: 0.3400 - val_loss: 0.8061 - val_soft_acc: 0.3070\n",
      "Epoch 40/2000\n",
      "453/453 [==============================] - 0s 246us/step - loss: 0.7581 - soft_acc: 0.3400 - val_loss: 0.8043 - val_soft_acc: 0.3070\n",
      "Epoch 41/2000\n",
      "453/453 [==============================] - 0s 245us/step - loss: 0.7567 - soft_acc: 0.3400 - val_loss: 0.8115 - val_soft_acc: 0.3070\n",
      "Epoch 42/2000\n",
      "453/453 [==============================] - 0s 244us/step - loss: 0.7573 - soft_acc: 0.3400 - val_loss: 0.8051 - val_soft_acc: 0.3070\n",
      "Epoch 43/2000\n",
      "453/453 [==============================] - 0s 246us/step - loss: 0.7548 - soft_acc: 0.3400 - val_loss: 0.8087 - val_soft_acc: 0.3070\n",
      "Epoch 44/2000\n",
      "453/453 [==============================] - 0s 244us/step - loss: 0.7540 - soft_acc: 0.3400 - val_loss: 0.8082 - val_soft_acc: 0.3070\n",
      "Epoch 45/2000\n",
      "453/453 [==============================] - 0s 243us/step - loss: 0.7527 - soft_acc: 0.3400 - val_loss: 0.8020 - val_soft_acc: 0.3070\n",
      "Epoch 46/2000\n",
      "453/453 [==============================] - 0s 288us/step - loss: 0.7522 - soft_acc: 0.3400 - val_loss: 0.7994 - val_soft_acc: 0.3070\n",
      "Epoch 47/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.7509 - soft_acc: 0.3400 - val_loss: 0.7969 - val_soft_acc: 0.3070\n",
      "Epoch 48/2000\n",
      "453/453 [==============================] - 0s 256us/step - loss: 0.7508 - soft_acc: 0.3400 - val_loss: 0.8031 - val_soft_acc: 0.3070\n",
      "Epoch 49/2000\n",
      "453/453 [==============================] - 0s 289us/step - loss: 0.7492 - soft_acc: 0.3400 - val_loss: 0.8040 - val_soft_acc: 0.3070\n",
      "Epoch 50/2000\n",
      "453/453 [==============================] - 0s 295us/step - loss: 0.7494 - soft_acc: 0.3400 - val_loss: 0.8081 - val_soft_acc: 0.3070\n",
      "Epoch 51/2000\n",
      "453/453 [==============================] - 0s 284us/step - loss: 0.7491 - soft_acc: 0.3400 - val_loss: 0.8022 - val_soft_acc: 0.3070\n",
      "Epoch 52/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.7489 - soft_acc: 0.3400 - val_loss: 0.7986 - val_soft_acc: 0.3070\n",
      "Epoch 53/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.7473 - soft_acc: 0.3400 - val_loss: 0.8023 - val_soft_acc: 0.3070\n",
      "Epoch 54/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.7464 - soft_acc: 0.3400 - val_loss: 0.8033 - val_soft_acc: 0.3070\n",
      "Epoch 55/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.7460 - soft_acc: 0.3400 - val_loss: 0.8043 - val_soft_acc: 0.3070\n",
      "Epoch 56/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 273us/step - loss: 0.7461 - soft_acc: 0.3400 - val_loss: 0.8006 - val_soft_acc: 0.3070\n",
      "Epoch 57/2000\n",
      "453/453 [==============================] - 0s 258us/step - loss: 0.7452 - soft_acc: 0.3400 - val_loss: 0.7931 - val_soft_acc: 0.3070\n",
      "Epoch 58/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.7440 - soft_acc: 0.3400 - val_loss: 0.7918 - val_soft_acc: 0.3070\n",
      "Epoch 59/2000\n",
      "453/453 [==============================] - 0s 256us/step - loss: 0.7435 - soft_acc: 0.3400 - val_loss: 0.7915 - val_soft_acc: 0.3070\n",
      "Epoch 60/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.7421 - soft_acc: 0.3400 - val_loss: 0.7877 - val_soft_acc: 0.3070\n",
      "Epoch 61/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.7432 - soft_acc: 0.3400 - val_loss: 0.7876 - val_soft_acc: 0.3070\n",
      "Epoch 62/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.7406 - soft_acc: 0.3400 - val_loss: 0.7935 - val_soft_acc: 0.3070\n",
      "Epoch 63/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.7402 - soft_acc: 0.3400 - val_loss: 0.7892 - val_soft_acc: 0.3070\n",
      "Epoch 64/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.7408 - soft_acc: 0.3400 - val_loss: 0.7848 - val_soft_acc: 0.3070\n",
      "Epoch 65/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.7391 - soft_acc: 0.3400 - val_loss: 0.7851 - val_soft_acc: 0.3070\n",
      "Epoch 66/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.7375 - soft_acc: 0.3400 - val_loss: 0.7888 - val_soft_acc: 0.3070\n",
      "Epoch 67/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.7385 - soft_acc: 0.3400 - val_loss: 0.7930 - val_soft_acc: 0.3070\n",
      "Epoch 68/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.7384 - soft_acc: 0.3400 - val_loss: 0.7854 - val_soft_acc: 0.3070\n",
      "Epoch 69/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.7368 - soft_acc: 0.3400 - val_loss: 0.7828 - val_soft_acc: 0.3070\n",
      "Epoch 70/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.7375 - soft_acc: 0.3400 - val_loss: 0.7816 - val_soft_acc: 0.3070\n",
      "Epoch 71/2000\n",
      "453/453 [==============================] - 0s 264us/step - loss: 0.7359 - soft_acc: 0.3400 - val_loss: 0.7829 - val_soft_acc: 0.3070\n",
      "Epoch 72/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.7359 - soft_acc: 0.3400 - val_loss: 0.7800 - val_soft_acc: 0.3070\n",
      "Epoch 73/2000\n",
      "453/453 [==============================] - 0s 287us/step - loss: 0.7367 - soft_acc: 0.3400 - val_loss: 0.7788 - val_soft_acc: 0.3070\n",
      "Epoch 74/2000\n",
      "453/453 [==============================] - 0s 297us/step - loss: 0.7356 - soft_acc: 0.3400 - val_loss: 0.7789 - val_soft_acc: 0.3070\n",
      "Epoch 75/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.7358 - soft_acc: 0.3400 - val_loss: 0.7783 - val_soft_acc: 0.3070\n",
      "Epoch 76/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.7345 - soft_acc: 0.3400 - val_loss: 0.7819 - val_soft_acc: 0.3070\n",
      "Epoch 77/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.7344 - soft_acc: 0.3400 - val_loss: 0.7815 - val_soft_acc: 0.3070\n",
      "Epoch 78/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.7330 - soft_acc: 0.3400 - val_loss: 0.7836 - val_soft_acc: 0.3070\n",
      "Epoch 79/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.7333 - soft_acc: 0.3400 - val_loss: 0.7783 - val_soft_acc: 0.3070\n",
      "Epoch 80/2000\n",
      "453/453 [==============================] - 0s 290us/step - loss: 0.7319 - soft_acc: 0.3400 - val_loss: 0.7858 - val_soft_acc: 0.3070\n",
      "Epoch 81/2000\n",
      "453/453 [==============================] - 0s 300us/step - loss: 0.7348 - soft_acc: 0.3400 - val_loss: 0.7862 - val_soft_acc: 0.3070\n",
      "Epoch 82/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.7339 - soft_acc: 0.3400 - val_loss: 0.7867 - val_soft_acc: 0.3070\n",
      "Epoch 83/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.7338 - soft_acc: 0.3400 - val_loss: 0.7760 - val_soft_acc: 0.3070\n",
      "Epoch 84/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.7313 - soft_acc: 0.3400 - val_loss: 0.7732 - val_soft_acc: 0.3070\n",
      "Epoch 85/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.7319 - soft_acc: 0.3400 - val_loss: 0.7764 - val_soft_acc: 0.3070\n",
      "Epoch 86/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.7316 - soft_acc: 0.3400 - val_loss: 0.7755 - val_soft_acc: 0.3070\n",
      "Epoch 87/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.7334 - soft_acc: 0.3400 - val_loss: 0.7753 - val_soft_acc: 0.3070\n",
      "Epoch 88/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.7338 - soft_acc: 0.3400 - val_loss: 0.7704 - val_soft_acc: 0.3070\n",
      "Epoch 89/2000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.7310 - soft_acc: 0.3400 - val_loss: 0.7724 - val_soft_acc: 0.3070\n",
      "Epoch 90/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.7307 - soft_acc: 0.3400 - val_loss: 0.7731 - val_soft_acc: 0.3070\n",
      "Epoch 91/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.7296 - soft_acc: 0.3400 - val_loss: 0.7768 - val_soft_acc: 0.3070\n",
      "Epoch 92/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.7307 - soft_acc: 0.3400 - val_loss: 0.7736 - val_soft_acc: 0.3070\n",
      "Epoch 93/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.7293 - soft_acc: 0.3400 - val_loss: 0.7739 - val_soft_acc: 0.3070\n",
      "Epoch 94/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.7291 - soft_acc: 0.3400 - val_loss: 0.7700 - val_soft_acc: 0.3070\n",
      "Epoch 95/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.7279 - soft_acc: 0.3400 - val_loss: 0.7741 - val_soft_acc: 0.3070\n",
      "Epoch 96/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.7301 - soft_acc: 0.3400 - val_loss: 0.7717 - val_soft_acc: 0.3070\n",
      "Epoch 97/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.7269 - soft_acc: 0.3400 - val_loss: 0.7835 - val_soft_acc: 0.3070\n",
      "Epoch 98/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.7297 - soft_acc: 0.3400 - val_loss: 0.7763 - val_soft_acc: 0.3070\n",
      "Epoch 99/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.7285 - soft_acc: 0.3400 - val_loss: 0.7710 - val_soft_acc: 0.3070\n",
      "Epoch 100/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.7257 - soft_acc: 0.3400 - val_loss: 0.7734 - val_soft_acc: 0.3070\n",
      "Epoch 101/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.7279 - soft_acc: 0.3400 - val_loss: 0.7718 - val_soft_acc: 0.3070\n",
      "Epoch 102/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.7286 - soft_acc: 0.3400 - val_loss: 0.7759 - val_soft_acc: 0.3070\n",
      "Epoch 103/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.7276 - soft_acc: 0.3400 - val_loss: 0.7708 - val_soft_acc: 0.3070\n",
      "Epoch 104/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.7281 - soft_acc: 0.3400 - val_loss: 0.7716 - val_soft_acc: 0.3070\n",
      "Epoch 105/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.7269 - soft_acc: 0.3400 - val_loss: 0.7714 - val_soft_acc: 0.3070\n",
      "Epoch 106/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.7276 - soft_acc: 0.3400 - val_loss: 0.7756 - val_soft_acc: 0.3070\n",
      "Epoch 107/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.7268 - soft_acc: 0.3400 - val_loss: 0.7685 - val_soft_acc: 0.3070\n",
      "Epoch 108/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.7245 - soft_acc: 0.3400 - val_loss: 0.7718 - val_soft_acc: 0.3070\n",
      "Epoch 109/2000\n",
      "453/453 [==============================] - 0s 264us/step - loss: 0.7255 - soft_acc: 0.3400 - val_loss: 0.7728 - val_soft_acc: 0.3070\n",
      "Epoch 110/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.7284 - soft_acc: 0.3400 - val_loss: 0.7721 - val_soft_acc: 0.3070\n",
      "Epoch 111/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.7260 - soft_acc: 0.3400 - val_loss: 0.7676 - val_soft_acc: 0.3070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.7255 - soft_acc: 0.3400 - val_loss: 0.7698 - val_soft_acc: 0.3070\n",
      "Epoch 113/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.7248 - soft_acc: 0.3400 - val_loss: 0.7668 - val_soft_acc: 0.3070\n",
      "Epoch 114/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.7248 - soft_acc: 0.3400 - val_loss: 0.7694 - val_soft_acc: 0.3070\n",
      "Epoch 115/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.7263 - soft_acc: 0.3400 - val_loss: 0.7712 - val_soft_acc: 0.3070\n",
      "Epoch 116/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.7240 - soft_acc: 0.3400 - val_loss: 0.7696 - val_soft_acc: 0.3070\n",
      "Epoch 117/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.7240 - soft_acc: 0.3400 - val_loss: 0.7685 - val_soft_acc: 0.3070\n",
      "Epoch 118/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.7233 - soft_acc: 0.3400 - val_loss: 0.7706 - val_soft_acc: 0.3070\n",
      "Epoch 119/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.7259 - soft_acc: 0.3400 - val_loss: 0.7689 - val_soft_acc: 0.3070\n",
      "Epoch 120/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.7238 - soft_acc: 0.3400 - val_loss: 0.7672 - val_soft_acc: 0.3070\n",
      "Epoch 121/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.7240 - soft_acc: 0.3400 - val_loss: 0.7686 - val_soft_acc: 0.3070\n",
      "Epoch 122/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.7241 - soft_acc: 0.3400 - val_loss: 0.7707 - val_soft_acc: 0.3070\n",
      "Epoch 123/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.7246 - soft_acc: 0.3400 - val_loss: 0.7740 - val_soft_acc: 0.3070\n",
      "Epoch 124/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.7237 - soft_acc: 0.3400 - val_loss: 0.7777 - val_soft_acc: 0.3070\n",
      "Epoch 125/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.7252 - soft_acc: 0.3400 - val_loss: 0.7753 - val_soft_acc: 0.3070\n",
      "Epoch 126/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.7244 - soft_acc: 0.3400 - val_loss: 0.7672 - val_soft_acc: 0.3070\n",
      "Epoch 127/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.7233 - soft_acc: 0.3400 - val_loss: 0.7648 - val_soft_acc: 0.3070\n",
      "Epoch 128/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.7220 - soft_acc: 0.3400 - val_loss: 0.7634 - val_soft_acc: 0.3070\n",
      "Epoch 129/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.7221 - soft_acc: 0.3400 - val_loss: 0.7673 - val_soft_acc: 0.3070\n",
      "Epoch 130/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.7234 - soft_acc: 0.3400 - val_loss: 0.7663 - val_soft_acc: 0.3070\n",
      "Epoch 131/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.7227 - soft_acc: 0.3400 - val_loss: 0.7699 - val_soft_acc: 0.3070\n",
      "Epoch 132/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.7229 - soft_acc: 0.3400 - val_loss: 0.7687 - val_soft_acc: 0.3070\n",
      "Epoch 133/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.7216 - soft_acc: 0.3400 - val_loss: 0.7660 - val_soft_acc: 0.3070\n",
      "Epoch 134/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.7216 - soft_acc: 0.3400 - val_loss: 0.7642 - val_soft_acc: 0.3070\n",
      "Epoch 135/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.7204 - soft_acc: 0.3400 - val_loss: 0.7654 - val_soft_acc: 0.3070\n",
      "Epoch 136/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.7209 - soft_acc: 0.3400 - val_loss: 0.7646 - val_soft_acc: 0.3070\n",
      "Epoch 137/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.7201 - soft_acc: 0.3400 - val_loss: 0.7641 - val_soft_acc: 0.3070\n",
      "Epoch 138/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.7208 - soft_acc: 0.3400 - val_loss: 0.7639 - val_soft_acc: 0.3070\n",
      "Epoch 139/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.7211 - soft_acc: 0.3400 - val_loss: 0.7657 - val_soft_acc: 0.3070\n",
      "Epoch 140/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.7200 - soft_acc: 0.3400 - val_loss: 0.7641 - val_soft_acc: 0.3070\n",
      "Epoch 141/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.7183 - soft_acc: 0.3400 - val_loss: 0.7626 - val_soft_acc: 0.3070\n",
      "Epoch 142/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.7205 - soft_acc: 0.3400 - val_loss: 0.7659 - val_soft_acc: 0.3070\n",
      "Epoch 143/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.7203 - soft_acc: 0.3400 - val_loss: 0.7679 - val_soft_acc: 0.3070\n",
      "Epoch 144/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.7200 - soft_acc: 0.3400 - val_loss: 0.7668 - val_soft_acc: 0.3070\n",
      "Epoch 145/2000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.7200 - soft_acc: 0.3400 - val_loss: 0.7662 - val_soft_acc: 0.3070\n",
      "Epoch 146/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.7197 - soft_acc: 0.3400 - val_loss: 0.7623 - val_soft_acc: 0.3070\n",
      "Epoch 147/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.7184 - soft_acc: 0.3400 - val_loss: 0.7585 - val_soft_acc: 0.3070\n",
      "Epoch 148/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.7184 - soft_acc: 0.3400 - val_loss: 0.7644 - val_soft_acc: 0.3070\n",
      "Epoch 149/2000\n",
      "453/453 [==============================] - 0s 264us/step - loss: 0.7184 - soft_acc: 0.3400 - val_loss: 0.7580 - val_soft_acc: 0.3070\n",
      "Epoch 150/2000\n",
      "453/453 [==============================] - 0s 284us/step - loss: 0.7184 - soft_acc: 0.3400 - val_loss: 0.7635 - val_soft_acc: 0.3070\n",
      "Epoch 151/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.7180 - soft_acc: 0.3400 - val_loss: 0.7660 - val_soft_acc: 0.3070\n",
      "Epoch 152/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.7184 - soft_acc: 0.3400 - val_loss: 0.7619 - val_soft_acc: 0.3070\n",
      "Epoch 153/2000\n",
      "453/453 [==============================] - 0s 289us/step - loss: 0.7200 - soft_acc: 0.3400 - val_loss: 0.7590 - val_soft_acc: 0.3070\n",
      "Epoch 154/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.7167 - soft_acc: 0.3400 - val_loss: 0.7541 - val_soft_acc: 0.3070\n",
      "Epoch 155/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.7142 - soft_acc: 0.3400 - val_loss: 0.7565 - val_soft_acc: 0.3070\n",
      "Epoch 156/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.7178 - soft_acc: 0.3400 - val_loss: 0.7558 - val_soft_acc: 0.3070\n",
      "Epoch 157/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.7166 - soft_acc: 0.3400 - val_loss: 0.7525 - val_soft_acc: 0.3070\n",
      "Epoch 158/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.7146 - soft_acc: 0.3400 - val_loss: 0.7558 - val_soft_acc: 0.3070\n",
      "Epoch 159/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.7166 - soft_acc: 0.3400 - val_loss: 0.7565 - val_soft_acc: 0.3070\n",
      "Epoch 160/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.7163 - soft_acc: 0.3400 - val_loss: 0.7552 - val_soft_acc: 0.3070\n",
      "Epoch 161/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.7136 - soft_acc: 0.3400 - val_loss: 0.7547 - val_soft_acc: 0.3070\n",
      "Epoch 162/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.7150 - soft_acc: 0.3400 - val_loss: 0.7561 - val_soft_acc: 0.3070\n",
      "Epoch 163/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.7145 - soft_acc: 0.3400 - val_loss: 0.7548 - val_soft_acc: 0.3070\n",
      "Epoch 164/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.7135 - soft_acc: 0.3400 - val_loss: 0.7536 - val_soft_acc: 0.3070\n",
      "Epoch 165/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.7134 - soft_acc: 0.3400 - val_loss: 0.7528 - val_soft_acc: 0.3070\n",
      "Epoch 166/2000\n",
      "453/453 [==============================] - 0s 264us/step - loss: 0.7119 - soft_acc: 0.3400 - val_loss: 0.7519 - val_soft_acc: 0.3070\n",
      "Epoch 167/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 258us/step - loss: 0.7126 - soft_acc: 0.3400 - val_loss: 0.7548 - val_soft_acc: 0.3070\n",
      "Epoch 168/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.7130 - soft_acc: 0.3400 - val_loss: 0.7523 - val_soft_acc: 0.3070\n",
      "Epoch 169/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.7129 - soft_acc: 0.3400 - val_loss: 0.7542 - val_soft_acc: 0.3070\n",
      "Epoch 170/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.7124 - soft_acc: 0.3400 - val_loss: 0.7508 - val_soft_acc: 0.3070\n",
      "Epoch 171/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.7110 - soft_acc: 0.3400 - val_loss: 0.7499 - val_soft_acc: 0.3070\n",
      "Epoch 172/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.7105 - soft_acc: 0.3400 - val_loss: 0.7535 - val_soft_acc: 0.3070\n",
      "Epoch 173/2000\n",
      "453/453 [==============================] - 0s 302us/step - loss: 0.7113 - soft_acc: 0.3400 - val_loss: 0.7501 - val_soft_acc: 0.3070\n",
      "Epoch 174/2000\n",
      "453/453 [==============================] - 0s 306us/step - loss: 0.7092 - soft_acc: 0.3400 - val_loss: 0.7494 - val_soft_acc: 0.3070\n",
      "Epoch 175/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.7091 - soft_acc: 0.3400 - val_loss: 0.7518 - val_soft_acc: 0.3070\n",
      "Epoch 176/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.7103 - soft_acc: 0.3400 - val_loss: 0.7539 - val_soft_acc: 0.3070\n",
      "Epoch 177/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.7095 - soft_acc: 0.3400 - val_loss: 0.7499 - val_soft_acc: 0.3070\n",
      "Epoch 178/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.7079 - soft_acc: 0.3400 - val_loss: 0.7480 - val_soft_acc: 0.3070\n",
      "Epoch 179/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.7064 - soft_acc: 0.3400 - val_loss: 0.7512 - val_soft_acc: 0.3070\n",
      "Epoch 180/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.7063 - soft_acc: 0.3400 - val_loss: 0.7468 - val_soft_acc: 0.3070\n",
      "Epoch 181/2000\n",
      "453/453 [==============================] - 0s 295us/step - loss: 0.7061 - soft_acc: 0.3400 - val_loss: 0.7503 - val_soft_acc: 0.3070\n",
      "Epoch 182/2000\n",
      "453/453 [==============================] - 0s 288us/step - loss: 0.7057 - soft_acc: 0.3400 - val_loss: 0.7509 - val_soft_acc: 0.3070\n",
      "Epoch 183/2000\n",
      "453/453 [==============================] - 0s 293us/step - loss: 0.7059 - soft_acc: 0.3400 - val_loss: 0.7521 - val_soft_acc: 0.3070\n",
      "Epoch 184/2000\n",
      "453/453 [==============================] - 0s 290us/step - loss: 0.7064 - soft_acc: 0.3400 - val_loss: 0.7455 - val_soft_acc: 0.3070\n",
      "Epoch 185/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.7051 - soft_acc: 0.3400 - val_loss: 0.7416 - val_soft_acc: 0.3070\n",
      "Epoch 186/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.7032 - soft_acc: 0.3400 - val_loss: 0.7357 - val_soft_acc: 0.3070\n",
      "Epoch 187/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.7011 - soft_acc: 0.3400 - val_loss: 0.7382 - val_soft_acc: 0.3070\n",
      "Epoch 188/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.7012 - soft_acc: 0.3400 - val_loss: 0.7377 - val_soft_acc: 0.3070\n",
      "Epoch 189/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.7007 - soft_acc: 0.3400 - val_loss: 0.7338 - val_soft_acc: 0.3070\n",
      "Epoch 190/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.6988 - soft_acc: 0.3400 - val_loss: 0.7368 - val_soft_acc: 0.3070\n",
      "Epoch 191/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.6993 - soft_acc: 0.3400 - val_loss: 0.7329 - val_soft_acc: 0.3070\n",
      "Epoch 192/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.6971 - soft_acc: 0.3400 - val_loss: 0.7360 - val_soft_acc: 0.3070\n",
      "Epoch 193/2000\n",
      "453/453 [==============================] - 0s 284us/step - loss: 0.6978 - soft_acc: 0.3400 - val_loss: 0.7328 - val_soft_acc: 0.3070\n",
      "Epoch 194/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.6957 - soft_acc: 0.3400 - val_loss: 0.7260 - val_soft_acc: 0.3070\n",
      "Epoch 195/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.6936 - soft_acc: 0.3400 - val_loss: 0.7338 - val_soft_acc: 0.3070\n",
      "Epoch 196/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.6959 - soft_acc: 0.3400 - val_loss: 0.7275 - val_soft_acc: 0.3070\n",
      "Epoch 197/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.6922 - soft_acc: 0.3400 - val_loss: 0.7270 - val_soft_acc: 0.3070\n",
      "Epoch 198/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.6938 - soft_acc: 0.3400 - val_loss: 0.7233 - val_soft_acc: 0.3070\n",
      "Epoch 199/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.6920 - soft_acc: 0.3400 - val_loss: 0.7242 - val_soft_acc: 0.3070\n",
      "Epoch 200/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.6909 - soft_acc: 0.3400 - val_loss: 0.7196 - val_soft_acc: 0.3070\n",
      "Epoch 201/2000\n",
      "453/453 [==============================] - 0s 284us/step - loss: 0.6892 - soft_acc: 0.3400 - val_loss: 0.7216 - val_soft_acc: 0.3070\n",
      "Epoch 202/2000\n",
      "453/453 [==============================] - 0s 290us/step - loss: 0.6915 - soft_acc: 0.3400 - val_loss: 0.7150 - val_soft_acc: 0.3070\n",
      "Epoch 203/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.6879 - soft_acc: 0.3400 - val_loss: 0.7193 - val_soft_acc: 0.3070\n",
      "Epoch 204/2000\n",
      "453/453 [==============================] - 0s 289us/step - loss: 0.6893 - soft_acc: 0.3400 - val_loss: 0.7175 - val_soft_acc: 0.3070\n",
      "Epoch 205/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.6869 - soft_acc: 0.3400 - val_loss: 0.7137 - val_soft_acc: 0.3070\n",
      "Epoch 206/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.6857 - soft_acc: 0.3400 - val_loss: 0.7158 - val_soft_acc: 0.3070\n",
      "Epoch 207/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.6864 - soft_acc: 0.3400 - val_loss: 0.7136 - val_soft_acc: 0.3070\n",
      "Epoch 208/2000\n",
      "453/453 [==============================] - 0s 285us/step - loss: 0.6852 - soft_acc: 0.3400 - val_loss: 0.7151 - val_soft_acc: 0.3070\n",
      "Epoch 209/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.6847 - soft_acc: 0.3400 - val_loss: 0.7171 - val_soft_acc: 0.3070\n",
      "Epoch 210/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.6844 - soft_acc: 0.3400 - val_loss: 0.7170 - val_soft_acc: 0.3070\n",
      "Epoch 211/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.6834 - soft_acc: 0.3400 - val_loss: 0.7103 - val_soft_acc: 0.3070\n",
      "Epoch 212/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.6803 - soft_acc: 0.3400 - val_loss: 0.7150 - val_soft_acc: 0.3070\n",
      "Epoch 213/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.6820 - soft_acc: 0.3400 - val_loss: 0.7121 - val_soft_acc: 0.3070\n",
      "Epoch 214/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.6813 - soft_acc: 0.3400 - val_loss: 0.7041 - val_soft_acc: 0.3070\n",
      "Epoch 215/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.6777 - soft_acc: 0.3400 - val_loss: 0.7003 - val_soft_acc: 0.3070\n",
      "Epoch 216/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.6782 - soft_acc: 0.3400 - val_loss: 0.7027 - val_soft_acc: 0.3070\n",
      "Epoch 217/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.6768 - soft_acc: 0.3400 - val_loss: 0.7028 - val_soft_acc: 0.3070\n",
      "Epoch 218/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.6779 - soft_acc: 0.3400 - val_loss: 0.6980 - val_soft_acc: 0.3070\n",
      "Epoch 219/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.6748 - soft_acc: 0.3400 - val_loss: 0.6971 - val_soft_acc: 0.3070\n",
      "Epoch 220/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.6748 - soft_acc: 0.3400 - val_loss: 0.6936 - val_soft_acc: 0.3070\n",
      "Epoch 221/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.6741 - soft_acc: 0.3400 - val_loss: 0.6927 - val_soft_acc: 0.3070\n",
      "Epoch 222/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 270us/step - loss: 0.6731 - soft_acc: 0.3400 - val_loss: 0.6878 - val_soft_acc: 0.3070\n",
      "Epoch 223/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.6711 - soft_acc: 0.3400 - val_loss: 0.6966 - val_soft_acc: 0.3070\n",
      "Epoch 224/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.6732 - soft_acc: 0.3400 - val_loss: 0.6963 - val_soft_acc: 0.3070\n",
      "Epoch 225/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.6718 - soft_acc: 0.3400 - val_loss: 0.6899 - val_soft_acc: 0.3070\n",
      "Epoch 226/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.6707 - soft_acc: 0.3400 - val_loss: 0.6851 - val_soft_acc: 0.3070\n",
      "Epoch 227/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.6692 - soft_acc: 0.3400 - val_loss: 0.6904 - val_soft_acc: 0.3070\n",
      "Epoch 228/2000\n",
      "453/453 [==============================] - 0s 263us/step - loss: 0.6689 - soft_acc: 0.3400 - val_loss: 0.6862 - val_soft_acc: 0.3070\n",
      "Epoch 229/2000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.6681 - soft_acc: 0.3400 - val_loss: 0.6845 - val_soft_acc: 0.3070\n",
      "Epoch 230/2000\n",
      "453/453 [==============================] - 0s 264us/step - loss: 0.6678 - soft_acc: 0.3400 - val_loss: 0.6843 - val_soft_acc: 0.3070\n",
      "Epoch 231/2000\n",
      "453/453 [==============================] - 0s 262us/step - loss: 0.6677 - soft_acc: 0.3400 - val_loss: 0.6789 - val_soft_acc: 0.3070\n",
      "Epoch 232/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.6662 - soft_acc: 0.3400 - val_loss: 0.6787 - val_soft_acc: 0.3070\n",
      "Epoch 233/2000\n",
      "453/453 [==============================] - 0s 347us/step - loss: 0.6658 - soft_acc: 0.3400 - val_loss: 0.6797 - val_soft_acc: 0.3070\n",
      "Epoch 234/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.6672 - soft_acc: 0.3400 - val_loss: 0.6775 - val_soft_acc: 0.3070\n",
      "Epoch 235/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.6656 - soft_acc: 0.3400 - val_loss: 0.6826 - val_soft_acc: 0.3070\n",
      "Epoch 236/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.6654 - soft_acc: 0.3400 - val_loss: 0.6799 - val_soft_acc: 0.3070\n",
      "Epoch 237/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.6650 - soft_acc: 0.3400 - val_loss: 0.6771 - val_soft_acc: 0.3070\n",
      "Epoch 238/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.6652 - soft_acc: 0.3400 - val_loss: 0.6757 - val_soft_acc: 0.3070\n",
      "Epoch 239/2000\n",
      "453/453 [==============================] - 0s 293us/step - loss: 0.6618 - soft_acc: 0.3400 - val_loss: 0.6766 - val_soft_acc: 0.3070\n",
      "Epoch 240/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.6623 - soft_acc: 0.3400 - val_loss: 0.6793 - val_soft_acc: 0.3070\n",
      "Epoch 241/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.6622 - soft_acc: 0.3400 - val_loss: 0.6752 - val_soft_acc: 0.3070\n",
      "Epoch 242/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.6610 - soft_acc: 0.3400 - val_loss: 0.6709 - val_soft_acc: 0.3070\n",
      "Epoch 243/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.6593 - soft_acc: 0.3400 - val_loss: 0.6715 - val_soft_acc: 0.3070\n",
      "Epoch 244/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.6601 - soft_acc: 0.3400 - val_loss: 0.6743 - val_soft_acc: 0.3070\n",
      "Epoch 245/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.6598 - soft_acc: 0.3400 - val_loss: 0.6676 - val_soft_acc: 0.3070\n",
      "Epoch 246/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.6568 - soft_acc: 0.3400 - val_loss: 0.6776 - val_soft_acc: 0.3070\n",
      "Epoch 247/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.6584 - soft_acc: 0.3400 - val_loss: 0.6763 - val_soft_acc: 0.3070\n",
      "Epoch 248/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.6576 - soft_acc: 0.3400 - val_loss: 0.6703 - val_soft_acc: 0.3070\n",
      "Epoch 249/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.6562 - soft_acc: 0.3400 - val_loss: 0.6737 - val_soft_acc: 0.3070\n",
      "Epoch 250/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.6553 - soft_acc: 0.3400 - val_loss: 0.6739 - val_soft_acc: 0.3070\n",
      "Epoch 251/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.6557 - soft_acc: 0.3400 - val_loss: 0.6752 - val_soft_acc: 0.3070\n",
      "Epoch 252/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.6553 - soft_acc: 0.3400 - val_loss: 0.6717 - val_soft_acc: 0.3070\n",
      "Epoch 253/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.6532 - soft_acc: 0.3400 - val_loss: 0.6773 - val_soft_acc: 0.3070\n",
      "Epoch 254/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.6538 - soft_acc: 0.3400 - val_loss: 0.6755 - val_soft_acc: 0.3070\n",
      "Epoch 255/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.6537 - soft_acc: 0.3400 - val_loss: 0.6781 - val_soft_acc: 0.3070\n",
      "Epoch 256/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.6527 - soft_acc: 0.3400 - val_loss: 0.6774 - val_soft_acc: 0.3070\n",
      "Epoch 257/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.6529 - soft_acc: 0.3400 - val_loss: 0.6772 - val_soft_acc: 0.3070\n",
      "Epoch 258/2000\n",
      "453/453 [==============================] - 0s 285us/step - loss: 0.6519 - soft_acc: 0.3400 - val_loss: 0.6714 - val_soft_acc: 0.3070\n",
      "Epoch 259/2000\n",
      "453/453 [==============================] - 0s 298us/step - loss: 0.6512 - soft_acc: 0.3400 - val_loss: 0.6706 - val_soft_acc: 0.3070\n",
      "Epoch 260/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.6512 - soft_acc: 0.3400 - val_loss: 0.6695 - val_soft_acc: 0.3070\n",
      "Epoch 261/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.6509 - soft_acc: 0.3400 - val_loss: 0.6677 - val_soft_acc: 0.3070\n",
      "Epoch 262/2000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.6503 - soft_acc: 0.3400 - val_loss: 0.6656 - val_soft_acc: 0.3070\n",
      "Epoch 263/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.6486 - soft_acc: 0.3400 - val_loss: 0.6691 - val_soft_acc: 0.3070\n",
      "Epoch 264/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.6476 - soft_acc: 0.3400 - val_loss: 0.6692 - val_soft_acc: 0.3070\n",
      "Epoch 265/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.6483 - soft_acc: 0.3400 - val_loss: 0.6665 - val_soft_acc: 0.3070\n",
      "Epoch 266/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.6475 - soft_acc: 0.3400 - val_loss: 0.6640 - val_soft_acc: 0.3070\n",
      "Epoch 267/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.6465 - soft_acc: 0.3400 - val_loss: 0.6691 - val_soft_acc: 0.3070\n",
      "Epoch 268/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.6465 - soft_acc: 0.3400 - val_loss: 0.6658 - val_soft_acc: 0.3070\n",
      "Epoch 269/2000\n",
      "453/453 [==============================] - 0s 284us/step - loss: 0.6452 - soft_acc: 0.3400 - val_loss: 0.6687 - val_soft_acc: 0.3070\n",
      "Epoch 270/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.6461 - soft_acc: 0.3400 - val_loss: 0.6736 - val_soft_acc: 0.3070\n",
      "Epoch 271/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.6461 - soft_acc: 0.3400 - val_loss: 0.6681 - val_soft_acc: 0.3070\n",
      "Epoch 272/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.6454 - soft_acc: 0.3400 - val_loss: 0.6651 - val_soft_acc: 0.3070\n",
      "Epoch 273/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.6429 - soft_acc: 0.3400 - val_loss: 0.6693 - val_soft_acc: 0.3070\n",
      "Epoch 274/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.6419 - soft_acc: 0.3400 - val_loss: 0.6658 - val_soft_acc: 0.3070\n",
      "Epoch 275/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.6427 - soft_acc: 0.3400 - val_loss: 0.6622 - val_soft_acc: 0.3070\n",
      "Epoch 276/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.6413 - soft_acc: 0.3400 - val_loss: 0.6647 - val_soft_acc: 0.3070\n",
      "Epoch 277/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 274us/step - loss: 0.6413 - soft_acc: 0.3400 - val_loss: 0.6675 - val_soft_acc: 0.3070\n",
      "Epoch 278/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.6399 - soft_acc: 0.3400 - val_loss: 0.6712 - val_soft_acc: 0.3070\n",
      "Epoch 279/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.6419 - soft_acc: 0.3400 - val_loss: 0.6732 - val_soft_acc: 0.3070\n",
      "Epoch 280/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.6422 - soft_acc: 0.3400 - val_loss: 0.6646 - val_soft_acc: 0.3070\n",
      "Epoch 281/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.6382 - soft_acc: 0.3400 - val_loss: 0.6668 - val_soft_acc: 0.3070\n",
      "Epoch 282/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.6381 - soft_acc: 0.3400 - val_loss: 0.6664 - val_soft_acc: 0.3070\n",
      "Epoch 283/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.6383 - soft_acc: 0.3400 - val_loss: 0.6626 - val_soft_acc: 0.3070\n",
      "Epoch 284/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.6366 - soft_acc: 0.3400 - val_loss: 0.6705 - val_soft_acc: 0.3070\n",
      "Epoch 285/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.6381 - soft_acc: 0.3400 - val_loss: 0.6609 - val_soft_acc: 0.3070\n",
      "Epoch 286/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.6350 - soft_acc: 0.3400 - val_loss: 0.6600 - val_soft_acc: 0.3070\n",
      "Epoch 287/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.6349 - soft_acc: 0.3400 - val_loss: 0.6603 - val_soft_acc: 0.3070\n",
      "Epoch 288/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.6362 - soft_acc: 0.3400 - val_loss: 0.6574 - val_soft_acc: 0.3070\n",
      "Epoch 289/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.6325 - soft_acc: 0.3400 - val_loss: 0.6605 - val_soft_acc: 0.3070\n",
      "Epoch 290/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.6355 - soft_acc: 0.3400 - val_loss: 0.6605 - val_soft_acc: 0.3070\n",
      "Epoch 291/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.6353 - soft_acc: 0.3400 - val_loss: 0.6576 - val_soft_acc: 0.3070\n",
      "Epoch 292/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.6328 - soft_acc: 0.3400 - val_loss: 0.6549 - val_soft_acc: 0.3070\n",
      "Epoch 293/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.6313 - soft_acc: 0.3400 - val_loss: 0.6619 - val_soft_acc: 0.3070\n",
      "Epoch 294/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.6327 - soft_acc: 0.3400 - val_loss: 0.6610 - val_soft_acc: 0.3070\n",
      "Epoch 295/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.6313 - soft_acc: 0.3400 - val_loss: 0.6621 - val_soft_acc: 0.3070\n",
      "Epoch 296/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.6294 - soft_acc: 0.3400 - val_loss: 0.6592 - val_soft_acc: 0.3070\n",
      "Epoch 297/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.6275 - soft_acc: 0.3400 - val_loss: 0.6572 - val_soft_acc: 0.3070\n",
      "Epoch 298/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.6290 - soft_acc: 0.3400 - val_loss: 0.6543 - val_soft_acc: 0.3070\n",
      "Epoch 299/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.6286 - soft_acc: 0.3400 - val_loss: 0.6548 - val_soft_acc: 0.3070\n",
      "Epoch 300/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.6275 - soft_acc: 0.3400 - val_loss: 0.6527 - val_soft_acc: 0.3070\n",
      "Epoch 301/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.6254 - soft_acc: 0.3400 - val_loss: 0.6507 - val_soft_acc: 0.3070\n",
      "Epoch 302/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.6256 - soft_acc: 0.3400 - val_loss: 0.6572 - val_soft_acc: 0.3070\n",
      "Epoch 303/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.6284 - soft_acc: 0.3400 - val_loss: 0.6534 - val_soft_acc: 0.3070\n",
      "Epoch 304/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.6244 - soft_acc: 0.3400 - val_loss: 0.6579 - val_soft_acc: 0.3070\n",
      "Epoch 305/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.6244 - soft_acc: 0.3400 - val_loss: 0.6549 - val_soft_acc: 0.3070\n",
      "Epoch 306/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.6233 - soft_acc: 0.3400 - val_loss: 0.6537 - val_soft_acc: 0.3070\n",
      "Epoch 307/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.6225 - soft_acc: 0.3400 - val_loss: 0.6523 - val_soft_acc: 0.3070\n",
      "Epoch 308/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.6216 - soft_acc: 0.3400 - val_loss: 0.6497 - val_soft_acc: 0.3070\n",
      "Epoch 309/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.6206 - soft_acc: 0.3400 - val_loss: 0.6509 - val_soft_acc: 0.3070\n",
      "Epoch 310/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.6215 - soft_acc: 0.3400 - val_loss: 0.6555 - val_soft_acc: 0.3070\n",
      "Epoch 311/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.6206 - soft_acc: 0.3400 - val_loss: 0.6505 - val_soft_acc: 0.3070\n",
      "Epoch 312/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.6185 - soft_acc: 0.3400 - val_loss: 0.6587 - val_soft_acc: 0.3070\n",
      "Epoch 313/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.6208 - soft_acc: 0.3400 - val_loss: 0.6556 - val_soft_acc: 0.3070\n",
      "Epoch 314/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.6187 - soft_acc: 0.3400 - val_loss: 0.6557 - val_soft_acc: 0.3070\n",
      "Epoch 315/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.6188 - soft_acc: 0.3400 - val_loss: 0.6510 - val_soft_acc: 0.3070\n",
      "Epoch 316/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.6161 - soft_acc: 0.3400 - val_loss: 0.6489 - val_soft_acc: 0.3070\n",
      "Epoch 317/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.6149 - soft_acc: 0.3400 - val_loss: 0.6483 - val_soft_acc: 0.3070\n",
      "Epoch 318/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.6156 - soft_acc: 0.3400 - val_loss: 0.6548 - val_soft_acc: 0.3070\n",
      "Epoch 319/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.6159 - soft_acc: 0.3400 - val_loss: 0.6463 - val_soft_acc: 0.3070\n",
      "Epoch 320/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.6139 - soft_acc: 0.3400 - val_loss: 0.6481 - val_soft_acc: 0.2982\n",
      "Epoch 321/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.6140 - soft_acc: 0.3510 - val_loss: 0.6484 - val_soft_acc: 0.3070\n",
      "Epoch 322/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.6140 - soft_acc: 0.3400 - val_loss: 0.6483 - val_soft_acc: 0.3070\n",
      "Epoch 323/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.6109 - soft_acc: 0.3400 - val_loss: 0.6458 - val_soft_acc: 0.3070\n",
      "Epoch 324/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.6110 - soft_acc: 0.3400 - val_loss: 0.6456 - val_soft_acc: 0.3070\n",
      "Epoch 325/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.6101 - soft_acc: 0.3422 - val_loss: 0.6469 - val_soft_acc: 0.3070\n",
      "Epoch 326/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.6084 - soft_acc: 0.3400 - val_loss: 0.6479 - val_soft_acc: 0.3070\n",
      "Epoch 327/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.6106 - soft_acc: 0.3466 - val_loss: 0.6421 - val_soft_acc: 0.3070\n",
      "Epoch 328/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.6081 - soft_acc: 0.3598 - val_loss: 0.6459 - val_soft_acc: 0.3070\n",
      "Epoch 329/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.6072 - soft_acc: 0.3400 - val_loss: 0.6380 - val_soft_acc: 0.3158\n",
      "Epoch 330/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.6057 - soft_acc: 0.3576 - val_loss: 0.6445 - val_soft_acc: 0.3158\n",
      "Epoch 331/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.6052 - soft_acc: 0.3444 - val_loss: 0.6451 - val_soft_acc: 0.3158\n",
      "Epoch 332/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 275us/step - loss: 0.6051 - soft_acc: 0.3510 - val_loss: 0.6423 - val_soft_acc: 0.3070\n",
      "Epoch 333/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.6047 - soft_acc: 0.3554 - val_loss: 0.6424 - val_soft_acc: 0.3158\n",
      "Epoch 334/2000\n",
      "453/453 [==============================] - 0s 304us/step - loss: 0.6046 - soft_acc: 0.3687 - val_loss: 0.6434 - val_soft_acc: 0.3246\n",
      "Epoch 335/2000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.6058 - soft_acc: 0.3664 - val_loss: 0.6420 - val_soft_acc: 0.3158\n",
      "Epoch 336/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.6045 - soft_acc: 0.3664 - val_loss: 0.6366 - val_soft_acc: 0.3070\n",
      "Epoch 337/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.5991 - soft_acc: 0.3664 - val_loss: 0.6437 - val_soft_acc: 0.3070\n",
      "Epoch 338/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.6026 - soft_acc: 0.3554 - val_loss: 0.6383 - val_soft_acc: 0.3158\n",
      "Epoch 339/2000\n",
      "453/453 [==============================] - 0s 284us/step - loss: 0.6005 - soft_acc: 0.3687 - val_loss: 0.6389 - val_soft_acc: 0.3070\n",
      "Epoch 340/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.5994 - soft_acc: 0.3709 - val_loss: 0.6386 - val_soft_acc: 0.3070\n",
      "Epoch 341/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.5989 - soft_acc: 0.3664 - val_loss: 0.6404 - val_soft_acc: 0.2982\n",
      "Epoch 342/2000\n",
      "453/453 [==============================] - 0s 308us/step - loss: 0.5986 - soft_acc: 0.3731 - val_loss: 0.6430 - val_soft_acc: 0.3246\n",
      "Epoch 343/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.5979 - soft_acc: 0.3709 - val_loss: 0.6421 - val_soft_acc: 0.3246\n",
      "Epoch 344/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.5966 - soft_acc: 0.3642 - val_loss: 0.6351 - val_soft_acc: 0.3158\n",
      "Epoch 345/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.5945 - soft_acc: 0.3863 - val_loss: 0.6378 - val_soft_acc: 0.3158\n",
      "Epoch 346/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.5949 - soft_acc: 0.3797 - val_loss: 0.6355 - val_soft_acc: 0.3246\n",
      "Epoch 347/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.5936 - soft_acc: 0.3907 - val_loss: 0.6349 - val_soft_acc: 0.3246\n",
      "Epoch 348/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.5924 - soft_acc: 0.3797 - val_loss: 0.6352 - val_soft_acc: 0.3246\n",
      "Epoch 349/2000\n",
      "453/453 [==============================] - 0s 302us/step - loss: 0.5939 - soft_acc: 0.3841 - val_loss: 0.6339 - val_soft_acc: 0.3421\n",
      "Epoch 350/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.5904 - soft_acc: 0.3907 - val_loss: 0.6278 - val_soft_acc: 0.3333\n",
      "Epoch 351/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.5895 - soft_acc: 0.3797 - val_loss: 0.6311 - val_soft_acc: 0.3333\n",
      "Epoch 352/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.5897 - soft_acc: 0.3797 - val_loss: 0.6327 - val_soft_acc: 0.3246\n",
      "Epoch 353/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.5899 - soft_acc: 0.3841 - val_loss: 0.6361 - val_soft_acc: 0.3246\n",
      "Epoch 354/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.5882 - soft_acc: 0.3974 - val_loss: 0.6302 - val_soft_acc: 0.3333\n",
      "Epoch 355/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.5872 - soft_acc: 0.3907 - val_loss: 0.6284 - val_soft_acc: 0.3421\n",
      "Epoch 356/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.5866 - soft_acc: 0.3907 - val_loss: 0.6298 - val_soft_acc: 0.3421\n",
      "Epoch 357/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.5861 - soft_acc: 0.3929 - val_loss: 0.6302 - val_soft_acc: 0.3333\n",
      "Epoch 358/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.5834 - soft_acc: 0.3974 - val_loss: 0.6327 - val_soft_acc: 0.3333\n",
      "Epoch 359/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.5843 - soft_acc: 0.3951 - val_loss: 0.6356 - val_soft_acc: 0.3246\n",
      "Epoch 360/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.5834 - soft_acc: 0.3951 - val_loss: 0.6293 - val_soft_acc: 0.3333\n",
      "Epoch 361/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.5807 - soft_acc: 0.3974 - val_loss: 0.6307 - val_soft_acc: 0.3421\n",
      "Epoch 362/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.5833 - soft_acc: 0.3974 - val_loss: 0.6292 - val_soft_acc: 0.3421\n",
      "Epoch 363/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.5805 - soft_acc: 0.3996 - val_loss: 0.6238 - val_soft_acc: 0.3421\n",
      "Epoch 364/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.5798 - soft_acc: 0.3929 - val_loss: 0.6236 - val_soft_acc: 0.3421\n",
      "Epoch 365/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.5797 - soft_acc: 0.3951 - val_loss: 0.6203 - val_soft_acc: 0.3421\n",
      "Epoch 366/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.5763 - soft_acc: 0.3996 - val_loss: 0.6226 - val_soft_acc: 0.3421\n",
      "Epoch 367/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.5784 - soft_acc: 0.3996 - val_loss: 0.6258 - val_soft_acc: 0.3421\n",
      "Epoch 368/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.5781 - soft_acc: 0.4018 - val_loss: 0.6232 - val_soft_acc: 0.3421\n",
      "Epoch 369/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.5768 - soft_acc: 0.4018 - val_loss: 0.6250 - val_soft_acc: 0.3421\n",
      "Epoch 370/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.5747 - soft_acc: 0.3996 - val_loss: 0.6204 - val_soft_acc: 0.3421\n",
      "Epoch 371/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.5739 - soft_acc: 0.4018 - val_loss: 0.6251 - val_soft_acc: 0.3421\n",
      "Epoch 372/2000\n",
      "453/453 [==============================] - 0s 309us/step - loss: 0.5751 - soft_acc: 0.3996 - val_loss: 0.6217 - val_soft_acc: 0.3509\n",
      "Epoch 373/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.5723 - soft_acc: 0.4062 - val_loss: 0.6313 - val_soft_acc: 0.3421\n",
      "Epoch 374/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.5754 - soft_acc: 0.3996 - val_loss: 0.6212 - val_soft_acc: 0.3421\n",
      "Epoch 375/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.5718 - soft_acc: 0.3996 - val_loss: 0.6187 - val_soft_acc: 0.3421\n",
      "Epoch 376/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.5706 - soft_acc: 0.3996 - val_loss: 0.6193 - val_soft_acc: 0.3421\n",
      "Epoch 377/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.5714 - soft_acc: 0.4018 - val_loss: 0.6262 - val_soft_acc: 0.3421\n",
      "Epoch 378/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.5708 - soft_acc: 0.3996 - val_loss: 0.6176 - val_soft_acc: 0.3421\n",
      "Epoch 379/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.5686 - soft_acc: 0.4018 - val_loss: 0.6227 - val_soft_acc: 0.3421\n",
      "Epoch 380/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.5676 - soft_acc: 0.4018 - val_loss: 0.6191 - val_soft_acc: 0.3509\n",
      "Epoch 381/2000\n",
      "453/453 [==============================] - 0s 289us/step - loss: 0.5669 - soft_acc: 0.4062 - val_loss: 0.6186 - val_soft_acc: 0.3421\n",
      "Epoch 382/2000\n",
      "453/453 [==============================] - 0s 287us/step - loss: 0.5663 - soft_acc: 0.4040 - val_loss: 0.6223 - val_soft_acc: 0.3421\n",
      "Epoch 383/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.5660 - soft_acc: 0.4018 - val_loss: 0.6255 - val_soft_acc: 0.3509\n",
      "Epoch 384/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.5664 - soft_acc: 0.4062 - val_loss: 0.6147 - val_soft_acc: 0.3421\n",
      "Epoch 385/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.5625 - soft_acc: 0.4018 - val_loss: 0.6161 - val_soft_acc: 0.3509\n",
      "Epoch 386/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.5637 - soft_acc: 0.4040 - val_loss: 0.6202 - val_soft_acc: 0.3509\n",
      "Epoch 387/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 284us/step - loss: 0.5651 - soft_acc: 0.4106 - val_loss: 0.6202 - val_soft_acc: 0.3509\n",
      "Epoch 388/2000\n",
      "453/453 [==============================] - 0s 288us/step - loss: 0.5626 - soft_acc: 0.4106 - val_loss: 0.6180 - val_soft_acc: 0.3509\n",
      "Epoch 389/2000\n",
      "453/453 [==============================] - 0s 287us/step - loss: 0.5632 - soft_acc: 0.4062 - val_loss: 0.6165 - val_soft_acc: 0.3421\n",
      "Epoch 390/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.5623 - soft_acc: 0.4062 - val_loss: 0.6181 - val_soft_acc: 0.3509\n",
      "Epoch 391/2000\n",
      "453/453 [==============================] - 0s 285us/step - loss: 0.5605 - soft_acc: 0.4172 - val_loss: 0.6116 - val_soft_acc: 0.3421\n",
      "Epoch 392/2000\n",
      "453/453 [==============================] - 0s 311us/step - loss: 0.5615 - soft_acc: 0.4150 - val_loss: 0.6158 - val_soft_acc: 0.3684\n",
      "Epoch 393/2000\n",
      "453/453 [==============================] - 0s 297us/step - loss: 0.5584 - soft_acc: 0.4172 - val_loss: 0.6140 - val_soft_acc: 0.3684\n",
      "Epoch 394/2000\n",
      "453/453 [==============================] - 0s 284us/step - loss: 0.5587 - soft_acc: 0.4194 - val_loss: 0.6108 - val_soft_acc: 0.3684\n",
      "Epoch 395/2000\n",
      "453/453 [==============================] - 0s 291us/step - loss: 0.5591 - soft_acc: 0.4150 - val_loss: 0.6126 - val_soft_acc: 0.3684\n",
      "Epoch 396/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.5566 - soft_acc: 0.4128 - val_loss: 0.6107 - val_soft_acc: 0.3596\n",
      "Epoch 397/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.5594 - soft_acc: 0.4172 - val_loss: 0.6169 - val_soft_acc: 0.3684\n",
      "Epoch 398/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.5587 - soft_acc: 0.4194 - val_loss: 0.6100 - val_soft_acc: 0.3596\n",
      "Epoch 399/2000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.5574 - soft_acc: 0.4216 - val_loss: 0.6139 - val_soft_acc: 0.3684\n",
      "Epoch 400/2000\n",
      "453/453 [==============================] - 0s 311us/step - loss: 0.5557 - soft_acc: 0.4216 - val_loss: 0.6096 - val_soft_acc: 0.3596\n",
      "Epoch 401/2000\n",
      "453/453 [==============================] - 0s 323us/step - loss: 0.5564 - soft_acc: 0.4194 - val_loss: 0.6156 - val_soft_acc: 0.3772\n",
      "Epoch 402/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.5555 - soft_acc: 0.4194 - val_loss: 0.6064 - val_soft_acc: 0.3684\n",
      "Epoch 403/2000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.5542 - soft_acc: 0.4216 - val_loss: 0.6067 - val_soft_acc: 0.3684\n",
      "Epoch 404/2000\n",
      "453/453 [==============================] - 0s 287us/step - loss: 0.5553 - soft_acc: 0.4327 - val_loss: 0.6008 - val_soft_acc: 0.3772\n",
      "Epoch 405/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.5519 - soft_acc: 0.4260 - val_loss: 0.6021 - val_soft_acc: 0.3684\n",
      "Epoch 406/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.5515 - soft_acc: 0.4305 - val_loss: 0.6110 - val_soft_acc: 0.3684\n",
      "Epoch 407/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.5525 - soft_acc: 0.4238 - val_loss: 0.6064 - val_soft_acc: 0.3684\n",
      "Epoch 408/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.5514 - soft_acc: 0.4371 - val_loss: 0.6073 - val_soft_acc: 0.3684\n",
      "Epoch 409/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.5529 - soft_acc: 0.4437 - val_loss: 0.6106 - val_soft_acc: 0.3684\n",
      "Epoch 410/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.5499 - soft_acc: 0.4393 - val_loss: 0.6053 - val_soft_acc: 0.3596\n",
      "Epoch 411/2000\n",
      "453/453 [==============================] - 0s 311us/step - loss: 0.5494 - soft_acc: 0.4481 - val_loss: 0.6034 - val_soft_acc: 0.3860\n",
      "Epoch 412/2000\n",
      "453/453 [==============================] - 0s 306us/step - loss: 0.5478 - soft_acc: 0.4393 - val_loss: 0.6049 - val_soft_acc: 0.3860\n",
      "Epoch 413/2000\n",
      "453/453 [==============================] - 0s 285us/step - loss: 0.5504 - soft_acc: 0.4349 - val_loss: 0.6042 - val_soft_acc: 0.3772\n",
      "Epoch 414/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.5468 - soft_acc: 0.4481 - val_loss: 0.6017 - val_soft_acc: 0.3772\n",
      "Epoch 415/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.5477 - soft_acc: 0.4459 - val_loss: 0.6069 - val_soft_acc: 0.3860\n",
      "Epoch 416/2000\n",
      "453/453 [==============================] - 0s 305us/step - loss: 0.5486 - soft_acc: 0.4393 - val_loss: 0.6115 - val_soft_acc: 0.4035\n",
      "Epoch 417/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.5473 - soft_acc: 0.4547 - val_loss: 0.6073 - val_soft_acc: 0.3772\n",
      "Epoch 418/2000\n",
      "453/453 [==============================] - 0s 318us/step - loss: 0.5478 - soft_acc: 0.4481 - val_loss: 0.6143 - val_soft_acc: 0.4123\n",
      "Epoch 419/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.5490 - soft_acc: 0.4614 - val_loss: 0.6106 - val_soft_acc: 0.3947\n",
      "Epoch 420/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.5443 - soft_acc: 0.4503 - val_loss: 0.6025 - val_soft_acc: 0.3772\n",
      "Epoch 421/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.5444 - soft_acc: 0.4481 - val_loss: 0.6077 - val_soft_acc: 0.3947\n",
      "Epoch 422/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.5431 - soft_acc: 0.4592 - val_loss: 0.6056 - val_soft_acc: 0.3772\n",
      "Epoch 423/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.5477 - soft_acc: 0.4459 - val_loss: 0.6072 - val_soft_acc: 0.3947\n",
      "Epoch 424/2000\n",
      "453/453 [==============================] - 0s 284us/step - loss: 0.5437 - soft_acc: 0.4592 - val_loss: 0.6006 - val_soft_acc: 0.3860\n",
      "Epoch 425/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.5429 - soft_acc: 0.4547 - val_loss: 0.5989 - val_soft_acc: 0.3860\n",
      "Epoch 426/2000\n",
      "453/453 [==============================] - 0s 285us/step - loss: 0.5419 - soft_acc: 0.4570 - val_loss: 0.6093 - val_soft_acc: 0.3947\n",
      "Epoch 427/2000\n",
      "453/453 [==============================] - 0s 307us/step - loss: 0.5428 - soft_acc: 0.4525 - val_loss: 0.6005 - val_soft_acc: 0.4123\n",
      "Epoch 428/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.5404 - soft_acc: 0.4636 - val_loss: 0.5968 - val_soft_acc: 0.3772\n",
      "Epoch 429/2000\n",
      "453/453 [==============================] - 0s 285us/step - loss: 0.5396 - soft_acc: 0.4614 - val_loss: 0.5977 - val_soft_acc: 0.3947\n",
      "Epoch 430/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.5428 - soft_acc: 0.4636 - val_loss: 0.6007 - val_soft_acc: 0.3947\n",
      "Epoch 431/2000\n",
      "453/453 [==============================] - 0s 285us/step - loss: 0.5415 - soft_acc: 0.4658 - val_loss: 0.5988 - val_soft_acc: 0.3947\n",
      "Epoch 432/2000\n",
      "453/453 [==============================] - 0s 289us/step - loss: 0.5409 - soft_acc: 0.4702 - val_loss: 0.5947 - val_soft_acc: 0.3947\n",
      "Epoch 433/2000\n",
      "453/453 [==============================] - 0s 305us/step - loss: 0.5387 - soft_acc: 0.4525 - val_loss: 0.5976 - val_soft_acc: 0.4298\n",
      "Epoch 434/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.5376 - soft_acc: 0.4614 - val_loss: 0.5996 - val_soft_acc: 0.3947\n",
      "Epoch 435/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.5395 - soft_acc: 0.4570 - val_loss: 0.5986 - val_soft_acc: 0.4035\n",
      "Epoch 436/2000\n",
      "453/453 [==============================] - 0s 285us/step - loss: 0.5383 - soft_acc: 0.4592 - val_loss: 0.6014 - val_soft_acc: 0.4035\n",
      "Epoch 437/2000\n",
      "453/453 [==============================] - 0s 299us/step - loss: 0.5389 - soft_acc: 0.4768 - val_loss: 0.5998 - val_soft_acc: 0.4035\n",
      "Epoch 438/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.5364 - soft_acc: 0.4680 - val_loss: 0.6036 - val_soft_acc: 0.4123\n",
      "Epoch 439/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.5357 - soft_acc: 0.4945 - val_loss: 0.5995 - val_soft_acc: 0.4123\n",
      "Epoch 440/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.5355 - soft_acc: 0.4702 - val_loss: 0.6027 - val_soft_acc: 0.4211\n",
      "Epoch 441/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.5368 - soft_acc: 0.4790 - val_loss: 0.6044 - val_soft_acc: 0.4211\n",
      "Epoch 442/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 274us/step - loss: 0.5376 - soft_acc: 0.4812 - val_loss: 0.5975 - val_soft_acc: 0.4123\n",
      "Epoch 443/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.5323 - soft_acc: 0.4834 - val_loss: 0.6004 - val_soft_acc: 0.4035\n",
      "Epoch 444/2000\n",
      "453/453 [==============================] - 0s 290us/step - loss: 0.5337 - soft_acc: 0.4746 - val_loss: 0.5964 - val_soft_acc: 0.4298\n",
      "Epoch 445/2000\n",
      "453/453 [==============================] - 0s 291us/step - loss: 0.5318 - soft_acc: 0.4702 - val_loss: 0.5989 - val_soft_acc: 0.4298\n",
      "Epoch 446/2000\n",
      "453/453 [==============================] - 0s 289us/step - loss: 0.5311 - soft_acc: 0.4790 - val_loss: 0.5950 - val_soft_acc: 0.4211\n",
      "Epoch 447/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.5334 - soft_acc: 0.4680 - val_loss: 0.5930 - val_soft_acc: 0.4298\n",
      "Epoch 448/2000\n",
      "453/453 [==============================] - 0s 284us/step - loss: 0.5309 - soft_acc: 0.4879 - val_loss: 0.5995 - val_soft_acc: 0.4298\n",
      "Epoch 449/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.5333 - soft_acc: 0.5121 - val_loss: 0.6040 - val_soft_acc: 0.3947\n",
      "Epoch 450/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.5316 - soft_acc: 0.5099 - val_loss: 0.5963 - val_soft_acc: 0.4298\n",
      "Epoch 451/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.5289 - soft_acc: 0.4879 - val_loss: 0.5925 - val_soft_acc: 0.4298\n",
      "Epoch 452/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.5298 - soft_acc: 0.4790 - val_loss: 0.6037 - val_soft_acc: 0.4211\n",
      "Epoch 453/2000\n",
      "453/453 [==============================] - 0s 285us/step - loss: 0.5305 - soft_acc: 0.4989 - val_loss: 0.5972 - val_soft_acc: 0.4211\n",
      "Epoch 454/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.5300 - soft_acc: 0.4923 - val_loss: 0.5962 - val_soft_acc: 0.4298\n",
      "Epoch 455/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.5280 - soft_acc: 0.4857 - val_loss: 0.5916 - val_soft_acc: 0.4211\n",
      "Epoch 456/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.5265 - soft_acc: 0.4989 - val_loss: 0.5919 - val_soft_acc: 0.4298\n",
      "Epoch 457/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.5281 - soft_acc: 0.5011 - val_loss: 0.5929 - val_soft_acc: 0.4035\n",
      "Epoch 458/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.5276 - soft_acc: 0.4967 - val_loss: 0.5939 - val_soft_acc: 0.4298\n",
      "Epoch 459/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.5267 - soft_acc: 0.4945 - val_loss: 0.6112 - val_soft_acc: 0.4035\n",
      "Epoch 460/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.5292 - soft_acc: 0.5254 - val_loss: 0.6051 - val_soft_acc: 0.4211\n",
      "Epoch 461/2000\n",
      "453/453 [==============================] - 0s 328us/step - loss: 0.5275 - soft_acc: 0.5232 - val_loss: 0.5926 - val_soft_acc: 0.4386\n",
      "Epoch 462/2000\n",
      "453/453 [==============================] - 0s 292us/step - loss: 0.5265 - soft_acc: 0.5033 - val_loss: 0.5953 - val_soft_acc: 0.4386\n",
      "Epoch 463/2000\n",
      "453/453 [==============================] - 0s 303us/step - loss: 0.5237 - soft_acc: 0.5166 - val_loss: 0.5959 - val_soft_acc: 0.4474\n",
      "Epoch 464/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.5260 - soft_acc: 0.5320 - val_loss: 0.5903 - val_soft_acc: 0.4035\n",
      "Epoch 465/2000\n",
      "453/453 [==============================] - 0s 287us/step - loss: 0.5254 - soft_acc: 0.4901 - val_loss: 0.5907 - val_soft_acc: 0.4298\n",
      "Epoch 466/2000\n",
      "453/453 [==============================] - 0s 316us/step - loss: 0.5236 - soft_acc: 0.5143 - val_loss: 0.5931 - val_soft_acc: 0.4474\n",
      "Epoch 467/2000\n",
      "453/453 [==============================] - 0s 284us/step - loss: 0.5249 - soft_acc: 0.5055 - val_loss: 0.5884 - val_soft_acc: 0.4386\n",
      "Epoch 468/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.5230 - soft_acc: 0.5077 - val_loss: 0.5869 - val_soft_acc: 0.4298\n",
      "Epoch 469/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.5238 - soft_acc: 0.4790 - val_loss: 0.5918 - val_soft_acc: 0.4386\n",
      "Epoch 470/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.5265 - soft_acc: 0.5011 - val_loss: 0.5906 - val_soft_acc: 0.4211\n",
      "Epoch 471/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.5219 - soft_acc: 0.5099 - val_loss: 0.5870 - val_soft_acc: 0.4211\n",
      "Epoch 472/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.5231 - soft_acc: 0.5077 - val_loss: 0.5860 - val_soft_acc: 0.4211\n",
      "Epoch 473/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.5198 - soft_acc: 0.4989 - val_loss: 0.5926 - val_soft_acc: 0.4298\n",
      "Epoch 474/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.5232 - soft_acc: 0.5166 - val_loss: 0.5861 - val_soft_acc: 0.4211\n",
      "Epoch 475/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.5199 - soft_acc: 0.5077 - val_loss: 0.5987 - val_soft_acc: 0.4211\n",
      "Epoch 476/2000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.5228 - soft_acc: 0.5408 - val_loss: 0.5870 - val_soft_acc: 0.4298\n",
      "Epoch 477/2000\n",
      "453/453 [==============================] - 0s 320us/step - loss: 0.5165 - soft_acc: 0.5166 - val_loss: 0.5869 - val_soft_acc: 0.4298\n",
      "Epoch 478/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.5203 - soft_acc: 0.5121 - val_loss: 0.5919 - val_soft_acc: 0.4298\n",
      "Epoch 479/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.5184 - soft_acc: 0.5254 - val_loss: 0.6032 - val_soft_acc: 0.4123\n",
      "Epoch 480/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.5235 - soft_acc: 0.5298 - val_loss: 0.5936 - val_soft_acc: 0.4386\n",
      "Epoch 481/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.5207 - soft_acc: 0.5210 - val_loss: 0.5914 - val_soft_acc: 0.4298\n",
      "Epoch 482/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.5172 - soft_acc: 0.5210 - val_loss: 0.5897 - val_soft_acc: 0.4298\n",
      "Epoch 483/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.5183 - soft_acc: 0.5364 - val_loss: 0.5859 - val_soft_acc: 0.4386\n",
      "Epoch 484/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.5171 - soft_acc: 0.5254 - val_loss: 0.5944 - val_soft_acc: 0.4298\n",
      "Epoch 485/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.5166 - soft_acc: 0.5320 - val_loss: 0.5859 - val_soft_acc: 0.4386\n",
      "Epoch 486/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.5186 - soft_acc: 0.5254 - val_loss: 0.5889 - val_soft_acc: 0.4298\n",
      "Epoch 487/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.5152 - soft_acc: 0.5298 - val_loss: 0.5868 - val_soft_acc: 0.4474\n",
      "Epoch 488/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.5164 - soft_acc: 0.5210 - val_loss: 0.5913 - val_soft_acc: 0.4386\n",
      "Epoch 489/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.5159 - soft_acc: 0.5430 - val_loss: 0.5867 - val_soft_acc: 0.4386\n",
      "Epoch 490/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.5176 - soft_acc: 0.5430 - val_loss: 0.5909 - val_soft_acc: 0.4386\n",
      "Epoch 491/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.5136 - soft_acc: 0.5342 - val_loss: 0.5832 - val_soft_acc: 0.4386\n",
      "Epoch 492/2000\n",
      "453/453 [==============================] - 0s 314us/step - loss: 0.5155 - soft_acc: 0.5386 - val_loss: 0.5812 - val_soft_acc: 0.4561\n",
      "Epoch 493/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.5137 - soft_acc: 0.5453 - val_loss: 0.5789 - val_soft_acc: 0.4474\n",
      "Epoch 494/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.5128 - soft_acc: 0.5232 - val_loss: 0.5863 - val_soft_acc: 0.4474\n",
      "Epoch 495/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.5148 - soft_acc: 0.5386 - val_loss: 0.5802 - val_soft_acc: 0.4474\n",
      "Epoch 496/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.5143 - soft_acc: 0.5386 - val_loss: 0.5791 - val_soft_acc: 0.4561\n",
      "Epoch 497/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 273us/step - loss: 0.5123 - soft_acc: 0.5453 - val_loss: 0.5785 - val_soft_acc: 0.4474\n",
      "Epoch 498/2000\n",
      "453/453 [==============================] - 0s 288us/step - loss: 0.5133 - soft_acc: 0.5298 - val_loss: 0.5828 - val_soft_acc: 0.4474\n",
      "Epoch 499/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.5124 - soft_acc: 0.5430 - val_loss: 0.5904 - val_soft_acc: 0.4386\n",
      "Epoch 500/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.5124 - soft_acc: 0.5386 - val_loss: 0.5791 - val_soft_acc: 0.4298\n",
      "Epoch 501/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.5120 - soft_acc: 0.5386 - val_loss: 0.5859 - val_soft_acc: 0.4386\n",
      "Epoch 502/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.5121 - soft_acc: 0.5408 - val_loss: 0.5943 - val_soft_acc: 0.4386\n",
      "Epoch 503/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.5138 - soft_acc: 0.5453 - val_loss: 0.5956 - val_soft_acc: 0.4386\n",
      "Epoch 504/2000\n",
      "453/453 [==============================] - 0s 314us/step - loss: 0.5115 - soft_acc: 0.5519 - val_loss: 0.5837 - val_soft_acc: 0.4649\n",
      "Epoch 505/2000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.5121 - soft_acc: 0.5475 - val_loss: 0.5816 - val_soft_acc: 0.4298\n",
      "Epoch 506/2000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.5104 - soft_acc: 0.5497 - val_loss: 0.5848 - val_soft_acc: 0.4474\n",
      "Epoch 507/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.5082 - soft_acc: 0.5364 - val_loss: 0.5977 - val_soft_acc: 0.4386\n",
      "Epoch 508/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.5109 - soft_acc: 0.5342 - val_loss: 0.5815 - val_soft_acc: 0.4386\n",
      "Epoch 509/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.5084 - soft_acc: 0.5430 - val_loss: 0.5873 - val_soft_acc: 0.4561\n",
      "Epoch 510/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.5138 - soft_acc: 0.5276 - val_loss: 0.5796 - val_soft_acc: 0.4474\n",
      "Epoch 511/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.5099 - soft_acc: 0.5607 - val_loss: 0.5820 - val_soft_acc: 0.4561\n",
      "Epoch 512/2000\n",
      "453/453 [==============================] - 0s 308us/step - loss: 0.5130 - soft_acc: 0.5386 - val_loss: 0.5751 - val_soft_acc: 0.4737\n",
      "Epoch 513/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.5091 - soft_acc: 0.5541 - val_loss: 0.5743 - val_soft_acc: 0.4737\n",
      "Epoch 514/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.5077 - soft_acc: 0.5519 - val_loss: 0.5813 - val_soft_acc: 0.4386\n",
      "Epoch 515/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.5060 - soft_acc: 0.5453 - val_loss: 0.5849 - val_soft_acc: 0.4298\n",
      "Epoch 516/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.5077 - soft_acc: 0.5585 - val_loss: 0.5783 - val_soft_acc: 0.4298\n",
      "Epoch 517/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.5070 - soft_acc: 0.5497 - val_loss: 0.5747 - val_soft_acc: 0.4386\n",
      "Epoch 518/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.5035 - soft_acc: 0.5541 - val_loss: 0.5735 - val_soft_acc: 0.4561\n",
      "Epoch 519/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.5064 - soft_acc: 0.5497 - val_loss: 0.5725 - val_soft_acc: 0.4649\n",
      "Epoch 520/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.5051 - soft_acc: 0.5563 - val_loss: 0.5811 - val_soft_acc: 0.4386\n",
      "Epoch 521/2000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.5083 - soft_acc: 0.5475 - val_loss: 0.5829 - val_soft_acc: 0.4386\n",
      "Epoch 522/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.5069 - soft_acc: 0.5497 - val_loss: 0.5813 - val_soft_acc: 0.4474\n",
      "Epoch 523/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.5056 - soft_acc: 0.5497 - val_loss: 0.5815 - val_soft_acc: 0.4386\n",
      "Epoch 524/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.5036 - soft_acc: 0.5519 - val_loss: 0.5749 - val_soft_acc: 0.4737\n",
      "Epoch 525/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.5029 - soft_acc: 0.5607 - val_loss: 0.5844 - val_soft_acc: 0.4474\n",
      "Epoch 526/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.5053 - soft_acc: 0.5519 - val_loss: 0.5865 - val_soft_acc: 0.4386\n",
      "Epoch 527/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.5046 - soft_acc: 0.5475 - val_loss: 0.5821 - val_soft_acc: 0.4386\n",
      "Epoch 528/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.5038 - soft_acc: 0.5607 - val_loss: 0.5791 - val_soft_acc: 0.4649\n",
      "Epoch 529/2000\n",
      "453/453 [==============================] - 0s 263us/step - loss: 0.5044 - soft_acc: 0.5519 - val_loss: 0.5830 - val_soft_acc: 0.4474\n",
      "Epoch 530/2000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.5024 - soft_acc: 0.5607 - val_loss: 0.5924 - val_soft_acc: 0.4386\n",
      "Epoch 531/2000\n",
      "453/453 [==============================] - 0s 290us/step - loss: 0.5041 - soft_acc: 0.5651 - val_loss: 0.5864 - val_soft_acc: 0.4386\n",
      "Epoch 532/2000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.5025 - soft_acc: 0.5563 - val_loss: 0.5878 - val_soft_acc: 0.4386\n",
      "Epoch 533/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.5007 - soft_acc: 0.5607 - val_loss: 0.5779 - val_soft_acc: 0.4386\n",
      "Epoch 534/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.5026 - soft_acc: 0.5541 - val_loss: 0.6001 - val_soft_acc: 0.4474\n",
      "Epoch 535/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.5053 - soft_acc: 0.5541 - val_loss: 0.5817 - val_soft_acc: 0.4386\n",
      "Epoch 536/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.5008 - soft_acc: 0.5695 - val_loss: 0.5793 - val_soft_acc: 0.4474\n",
      "Epoch 537/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4994 - soft_acc: 0.5607 - val_loss: 0.5755 - val_soft_acc: 0.4649\n",
      "Epoch 538/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.5028 - soft_acc: 0.5585 - val_loss: 0.5762 - val_soft_acc: 0.4561\n",
      "Epoch 539/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.5003 - soft_acc: 0.5651 - val_loss: 0.5831 - val_soft_acc: 0.4386\n",
      "Epoch 540/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.5009 - soft_acc: 0.5607 - val_loss: 0.5843 - val_soft_acc: 0.4386\n",
      "Epoch 541/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4990 - soft_acc: 0.5629 - val_loss: 0.5935 - val_soft_acc: 0.4386\n",
      "Epoch 542/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4999 - soft_acc: 0.5762 - val_loss: 0.5737 - val_soft_acc: 0.4386\n",
      "Epoch 543/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.4969 - soft_acc: 0.5740 - val_loss: 0.5757 - val_soft_acc: 0.4386\n",
      "Epoch 544/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4983 - soft_acc: 0.5607 - val_loss: 0.5767 - val_soft_acc: 0.4386\n",
      "Epoch 545/2000\n",
      "453/453 [==============================] - 0s 300us/step - loss: 0.4959 - soft_acc: 0.5717 - val_loss: 0.5960 - val_soft_acc: 0.4825\n",
      "Epoch 546/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.5011 - soft_acc: 0.5762 - val_loss: 0.5919 - val_soft_acc: 0.4474\n",
      "Epoch 547/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4974 - soft_acc: 0.5762 - val_loss: 0.5790 - val_soft_acc: 0.4474\n",
      "Epoch 548/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4982 - soft_acc: 0.5673 - val_loss: 0.5806 - val_soft_acc: 0.4474\n",
      "Epoch 549/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.4961 - soft_acc: 0.5762 - val_loss: 0.5774 - val_soft_acc: 0.4561\n",
      "Epoch 550/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4972 - soft_acc: 0.5629 - val_loss: 0.5806 - val_soft_acc: 0.4386\n",
      "Epoch 551/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4952 - soft_acc: 0.5762 - val_loss: 0.5791 - val_soft_acc: 0.4386\n",
      "Epoch 552/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 275us/step - loss: 0.4933 - soft_acc: 0.5695 - val_loss: 0.5841 - val_soft_acc: 0.4474\n",
      "Epoch 553/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4951 - soft_acc: 0.5740 - val_loss: 0.5856 - val_soft_acc: 0.4737\n",
      "Epoch 554/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4941 - soft_acc: 0.5850 - val_loss: 0.5787 - val_soft_acc: 0.4474\n",
      "Epoch 555/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.4968 - soft_acc: 0.5717 - val_loss: 0.5779 - val_soft_acc: 0.4474\n",
      "Epoch 556/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4940 - soft_acc: 0.5762 - val_loss: 0.5726 - val_soft_acc: 0.4737\n",
      "Epoch 557/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4955 - soft_acc: 0.5717 - val_loss: 0.5773 - val_soft_acc: 0.4737\n",
      "Epoch 558/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.4931 - soft_acc: 0.5629 - val_loss: 0.5782 - val_soft_acc: 0.4649\n",
      "Epoch 559/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4944 - soft_acc: 0.5673 - val_loss: 0.5764 - val_soft_acc: 0.4649\n",
      "Epoch 560/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4933 - soft_acc: 0.5673 - val_loss: 0.5746 - val_soft_acc: 0.4649\n",
      "Epoch 561/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4952 - soft_acc: 0.5960 - val_loss: 0.5744 - val_soft_acc: 0.4561\n",
      "Epoch 562/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4921 - soft_acc: 0.5740 - val_loss: 0.5762 - val_soft_acc: 0.4474\n",
      "Epoch 563/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4927 - soft_acc: 0.5717 - val_loss: 0.5798 - val_soft_acc: 0.4561\n",
      "Epoch 564/2000\n",
      "453/453 [==============================] - 0s 284us/step - loss: 0.4916 - soft_acc: 0.5872 - val_loss: 0.5755 - val_soft_acc: 0.4649\n",
      "Epoch 565/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4924 - soft_acc: 0.5740 - val_loss: 0.5738 - val_soft_acc: 0.4386\n",
      "Epoch 566/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4919 - soft_acc: 0.5740 - val_loss: 0.5858 - val_soft_acc: 0.4737\n",
      "Epoch 567/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4928 - soft_acc: 0.5762 - val_loss: 0.5751 - val_soft_acc: 0.4649\n",
      "Epoch 568/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4911 - soft_acc: 0.5717 - val_loss: 0.5757 - val_soft_acc: 0.4649\n",
      "Epoch 569/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4914 - soft_acc: 0.5784 - val_loss: 0.5721 - val_soft_acc: 0.4825\n",
      "Epoch 570/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.4891 - soft_acc: 0.5784 - val_loss: 0.5678 - val_soft_acc: 0.4649\n",
      "Epoch 571/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4886 - soft_acc: 0.5717 - val_loss: 0.5661 - val_soft_acc: 0.4825\n",
      "Epoch 572/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4904 - soft_acc: 0.5894 - val_loss: 0.5775 - val_soft_acc: 0.4561\n",
      "Epoch 573/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4898 - soft_acc: 0.5850 - val_loss: 0.5687 - val_soft_acc: 0.4649\n",
      "Epoch 574/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4894 - soft_acc: 0.5850 - val_loss: 0.5724 - val_soft_acc: 0.4561\n",
      "Epoch 575/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4890 - soft_acc: 0.5850 - val_loss: 0.5702 - val_soft_acc: 0.4825\n",
      "Epoch 576/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4880 - soft_acc: 0.5982 - val_loss: 0.5738 - val_soft_acc: 0.4649\n",
      "Epoch 577/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4895 - soft_acc: 0.5938 - val_loss: 0.5741 - val_soft_acc: 0.4649\n",
      "Epoch 578/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4865 - soft_acc: 0.5872 - val_loss: 0.5708 - val_soft_acc: 0.4561\n",
      "Epoch 579/2000\n",
      "453/453 [==============================] - 0s 264us/step - loss: 0.4896 - soft_acc: 0.5850 - val_loss: 0.5704 - val_soft_acc: 0.4737\n",
      "Epoch 580/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.4911 - soft_acc: 0.5938 - val_loss: 0.5708 - val_soft_acc: 0.4561\n",
      "Epoch 581/2000\n",
      "453/453 [==============================] - 0s 303us/step - loss: 0.4868 - soft_acc: 0.5938 - val_loss: 0.5776 - val_soft_acc: 0.4912\n",
      "Epoch 582/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.4874 - soft_acc: 0.6004 - val_loss: 0.5674 - val_soft_acc: 0.4737\n",
      "Epoch 583/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4869 - soft_acc: 0.5762 - val_loss: 0.5725 - val_soft_acc: 0.4912\n",
      "Epoch 584/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4873 - soft_acc: 0.5982 - val_loss: 0.5686 - val_soft_acc: 0.4737\n",
      "Epoch 585/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4844 - soft_acc: 0.5916 - val_loss: 0.5656 - val_soft_acc: 0.4649\n",
      "Epoch 586/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.4863 - soft_acc: 0.5960 - val_loss: 0.5743 - val_soft_acc: 0.4649\n",
      "Epoch 587/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4877 - soft_acc: 0.5894 - val_loss: 0.5687 - val_soft_acc: 0.4912\n",
      "Epoch 588/2000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.4829 - soft_acc: 0.6049 - val_loss: 0.5731 - val_soft_acc: 0.4737\n",
      "Epoch 589/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4849 - soft_acc: 0.5982 - val_loss: 0.5690 - val_soft_acc: 0.4737\n",
      "Epoch 590/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4856 - soft_acc: 0.5872 - val_loss: 0.5729 - val_soft_acc: 0.4737\n",
      "Epoch 591/2000\n",
      "453/453 [==============================] - 0s 307us/step - loss: 0.4848 - soft_acc: 0.5916 - val_loss: 0.5942 - val_soft_acc: 0.5000\n",
      "Epoch 592/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.4880 - soft_acc: 0.5894 - val_loss: 0.5807 - val_soft_acc: 0.5000\n",
      "Epoch 593/2000\n",
      "453/453 [==============================] - 0s 304us/step - loss: 0.4844 - soft_acc: 0.5960 - val_loss: 0.5919 - val_soft_acc: 0.5088\n",
      "Epoch 594/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4861 - soft_acc: 0.5938 - val_loss: 0.5681 - val_soft_acc: 0.4474\n",
      "Epoch 595/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4850 - soft_acc: 0.5916 - val_loss: 0.5679 - val_soft_acc: 0.4649\n",
      "Epoch 596/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4829 - soft_acc: 0.5894 - val_loss: 0.5705 - val_soft_acc: 0.4825\n",
      "Epoch 597/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4842 - soft_acc: 0.6004 - val_loss: 0.5701 - val_soft_acc: 0.4825\n",
      "Epoch 598/2000\n",
      "453/453 [==============================] - 0s 309us/step - loss: 0.4827 - soft_acc: 0.6093 - val_loss: 0.5884 - val_soft_acc: 0.5175\n",
      "Epoch 599/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4847 - soft_acc: 0.5982 - val_loss: 0.5654 - val_soft_acc: 0.4649\n",
      "Epoch 600/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4814 - soft_acc: 0.5938 - val_loss: 0.5727 - val_soft_acc: 0.5000\n",
      "Epoch 601/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4851 - soft_acc: 0.6071 - val_loss: 0.5747 - val_soft_acc: 0.5088\n",
      "Epoch 602/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.4818 - soft_acc: 0.5982 - val_loss: 0.5673 - val_soft_acc: 0.4737\n",
      "Epoch 603/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.4823 - soft_acc: 0.5960 - val_loss: 0.5754 - val_soft_acc: 0.5000\n",
      "Epoch 604/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.4817 - soft_acc: 0.5960 - val_loss: 0.5844 - val_soft_acc: 0.5000\n",
      "Epoch 605/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.4815 - soft_acc: 0.6026 - val_loss: 0.5694 - val_soft_acc: 0.4649\n",
      "Epoch 606/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4842 - soft_acc: 0.5960 - val_loss: 0.5715 - val_soft_acc: 0.4737\n",
      "Epoch 607/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 268us/step - loss: 0.4790 - soft_acc: 0.6004 - val_loss: 0.5732 - val_soft_acc: 0.4912\n",
      "Epoch 608/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4770 - soft_acc: 0.6026 - val_loss: 0.5702 - val_soft_acc: 0.4649\n",
      "Epoch 609/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4803 - soft_acc: 0.5938 - val_loss: 0.5650 - val_soft_acc: 0.4561\n",
      "Epoch 610/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4797 - soft_acc: 0.6026 - val_loss: 0.5713 - val_soft_acc: 0.5000\n",
      "Epoch 611/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4789 - soft_acc: 0.6026 - val_loss: 0.5673 - val_soft_acc: 0.4737\n",
      "Epoch 612/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4782 - soft_acc: 0.6004 - val_loss: 0.5762 - val_soft_acc: 0.4912\n",
      "Epoch 613/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4803 - soft_acc: 0.5960 - val_loss: 0.5872 - val_soft_acc: 0.4912\n",
      "Epoch 614/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.4800 - soft_acc: 0.6026 - val_loss: 0.5713 - val_soft_acc: 0.4737\n",
      "Epoch 615/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4802 - soft_acc: 0.5982 - val_loss: 0.5910 - val_soft_acc: 0.5088\n",
      "Epoch 616/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.4774 - soft_acc: 0.6049 - val_loss: 0.5733 - val_soft_acc: 0.4825\n",
      "Epoch 617/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4760 - soft_acc: 0.5916 - val_loss: 0.5678 - val_soft_acc: 0.4561\n",
      "Epoch 618/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4793 - soft_acc: 0.5960 - val_loss: 0.5856 - val_soft_acc: 0.5088\n",
      "Epoch 619/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4787 - soft_acc: 0.5960 - val_loss: 0.5779 - val_soft_acc: 0.5088\n",
      "Epoch 620/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4769 - soft_acc: 0.6159 - val_loss: 0.5851 - val_soft_acc: 0.5088\n",
      "Epoch 621/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4798 - soft_acc: 0.5960 - val_loss: 0.5710 - val_soft_acc: 0.4912\n",
      "Epoch 622/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4762 - soft_acc: 0.5982 - val_loss: 0.5845 - val_soft_acc: 0.5088\n",
      "Epoch 623/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.4770 - soft_acc: 0.5938 - val_loss: 0.5687 - val_soft_acc: 0.5000\n",
      "Epoch 624/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4778 - soft_acc: 0.6071 - val_loss: 0.5834 - val_soft_acc: 0.5088\n",
      "Epoch 625/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4773 - soft_acc: 0.6093 - val_loss: 0.5703 - val_soft_acc: 0.4561\n",
      "Epoch 626/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.4761 - soft_acc: 0.6071 - val_loss: 0.5731 - val_soft_acc: 0.4649\n",
      "Epoch 627/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4766 - soft_acc: 0.5872 - val_loss: 0.5717 - val_soft_acc: 0.5088\n",
      "Epoch 628/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4772 - soft_acc: 0.5982 - val_loss: 0.5720 - val_soft_acc: 0.5000\n",
      "Epoch 629/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4755 - soft_acc: 0.6004 - val_loss: 0.5720 - val_soft_acc: 0.4561\n",
      "Epoch 630/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4753 - soft_acc: 0.5960 - val_loss: 0.5742 - val_soft_acc: 0.5000\n",
      "Epoch 631/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4773 - soft_acc: 0.6071 - val_loss: 0.5788 - val_soft_acc: 0.4825\n",
      "Epoch 632/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4773 - soft_acc: 0.5960 - val_loss: 0.5677 - val_soft_acc: 0.4912\n",
      "Epoch 633/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.4736 - soft_acc: 0.6093 - val_loss: 0.5787 - val_soft_acc: 0.4737\n",
      "Epoch 634/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4807 - soft_acc: 0.6159 - val_loss: 0.5653 - val_soft_acc: 0.4561\n",
      "Epoch 635/2000\n",
      "453/453 [==============================] - 0s 292us/step - loss: 0.4735 - soft_acc: 0.6004 - val_loss: 0.5713 - val_soft_acc: 0.5351\n",
      "Epoch 636/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4738 - soft_acc: 0.6071 - val_loss: 0.5848 - val_soft_acc: 0.5000\n",
      "Epoch 637/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.4748 - soft_acc: 0.6004 - val_loss: 0.5662 - val_soft_acc: 0.5000\n",
      "Epoch 638/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4728 - soft_acc: 0.6093 - val_loss: 0.5742 - val_soft_acc: 0.5175\n",
      "Epoch 639/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4722 - soft_acc: 0.6115 - val_loss: 0.5651 - val_soft_acc: 0.4737\n",
      "Epoch 640/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4716 - soft_acc: 0.6049 - val_loss: 0.5662 - val_soft_acc: 0.4825\n",
      "Epoch 641/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4751 - soft_acc: 0.5960 - val_loss: 0.5710 - val_soft_acc: 0.5000\n",
      "Epoch 642/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4713 - soft_acc: 0.6026 - val_loss: 0.5981 - val_soft_acc: 0.4912\n",
      "Epoch 643/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.4755 - soft_acc: 0.6159 - val_loss: 0.5756 - val_soft_acc: 0.5000\n",
      "Epoch 644/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.4740 - soft_acc: 0.6137 - val_loss: 0.5963 - val_soft_acc: 0.4825\n",
      "Epoch 645/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4775 - soft_acc: 0.6026 - val_loss: 0.5851 - val_soft_acc: 0.5000\n",
      "Epoch 646/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4742 - soft_acc: 0.6093 - val_loss: 0.5916 - val_soft_acc: 0.5263\n",
      "Epoch 647/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.4750 - soft_acc: 0.6049 - val_loss: 0.5658 - val_soft_acc: 0.4912\n",
      "Epoch 648/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4693 - soft_acc: 0.6049 - val_loss: 0.5765 - val_soft_acc: 0.5175\n",
      "Epoch 649/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4707 - soft_acc: 0.6093 - val_loss: 0.5761 - val_soft_acc: 0.5263\n",
      "Epoch 650/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.4745 - soft_acc: 0.6026 - val_loss: 0.5702 - val_soft_acc: 0.5000\n",
      "Epoch 651/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4686 - soft_acc: 0.5982 - val_loss: 0.5677 - val_soft_acc: 0.5263\n",
      "Epoch 652/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4701 - soft_acc: 0.6026 - val_loss: 0.5821 - val_soft_acc: 0.5000\n",
      "Epoch 653/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4729 - soft_acc: 0.6115 - val_loss: 0.5691 - val_soft_acc: 0.4825\n",
      "Epoch 654/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4693 - soft_acc: 0.6049 - val_loss: 0.5731 - val_soft_acc: 0.5263\n",
      "Epoch 655/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4681 - soft_acc: 0.6181 - val_loss: 0.5675 - val_soft_acc: 0.4912\n",
      "Epoch 656/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4703 - soft_acc: 0.6049 - val_loss: 0.5626 - val_soft_acc: 0.4737\n",
      "Epoch 657/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.4678 - soft_acc: 0.6026 - val_loss: 0.5914 - val_soft_acc: 0.5000\n",
      "Epoch 658/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.4705 - soft_acc: 0.6049 - val_loss: 0.5752 - val_soft_acc: 0.4474\n",
      "Epoch 659/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4740 - soft_acc: 0.6049 - val_loss: 0.5690 - val_soft_acc: 0.4912\n",
      "Epoch 660/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.4711 - soft_acc: 0.5916 - val_loss: 0.5650 - val_soft_acc: 0.4737\n",
      "Epoch 661/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4673 - soft_acc: 0.6137 - val_loss: 0.5694 - val_soft_acc: 0.5263\n",
      "Epoch 662/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 279us/step - loss: 0.4676 - soft_acc: 0.6093 - val_loss: 0.5628 - val_soft_acc: 0.4912\n",
      "Epoch 663/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4670 - soft_acc: 0.6115 - val_loss: 0.5675 - val_soft_acc: 0.4649\n",
      "Epoch 664/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.4721 - soft_acc: 0.6004 - val_loss: 0.5639 - val_soft_acc: 0.5000\n",
      "Epoch 665/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4664 - soft_acc: 0.6159 - val_loss: 0.5798 - val_soft_acc: 0.5175\n",
      "Epoch 666/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.4684 - soft_acc: 0.6159 - val_loss: 0.5688 - val_soft_acc: 0.5000\n",
      "Epoch 667/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4690 - soft_acc: 0.6159 - val_loss: 0.5763 - val_soft_acc: 0.5351\n",
      "Epoch 668/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.4712 - soft_acc: 0.6026 - val_loss: 0.5661 - val_soft_acc: 0.4825\n",
      "Epoch 669/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4665 - soft_acc: 0.6115 - val_loss: 0.5692 - val_soft_acc: 0.5088\n",
      "Epoch 670/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4667 - soft_acc: 0.6071 - val_loss: 0.5711 - val_soft_acc: 0.5088\n",
      "Epoch 671/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4651 - soft_acc: 0.6137 - val_loss: 0.5624 - val_soft_acc: 0.5000\n",
      "Epoch 672/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4611 - soft_acc: 0.6026 - val_loss: 0.6099 - val_soft_acc: 0.5088\n",
      "Epoch 673/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4722 - soft_acc: 0.6181 - val_loss: 0.5872 - val_soft_acc: 0.5351\n",
      "Epoch 674/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4664 - soft_acc: 0.6071 - val_loss: 0.5727 - val_soft_acc: 0.4737\n",
      "Epoch 675/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4659 - soft_acc: 0.6093 - val_loss: 0.5772 - val_soft_acc: 0.4912\n",
      "Epoch 676/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4644 - soft_acc: 0.6115 - val_loss: 0.5695 - val_soft_acc: 0.4912\n",
      "Epoch 677/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4646 - soft_acc: 0.6004 - val_loss: 0.5706 - val_soft_acc: 0.5000\n",
      "Epoch 678/2000\n",
      "453/453 [==============================] - 0s 304us/step - loss: 0.4645 - soft_acc: 0.6203 - val_loss: 0.5780 - val_soft_acc: 0.5351\n",
      "Epoch 679/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4639 - soft_acc: 0.6137 - val_loss: 0.5777 - val_soft_acc: 0.5351\n",
      "Epoch 680/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.4636 - soft_acc: 0.6159 - val_loss: 0.5692 - val_soft_acc: 0.4825\n",
      "Epoch 681/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4655 - soft_acc: 0.6071 - val_loss: 0.5649 - val_soft_acc: 0.5000\n",
      "Epoch 682/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.4629 - soft_acc: 0.6159 - val_loss: 0.5678 - val_soft_acc: 0.5000\n",
      "Epoch 683/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4618 - soft_acc: 0.6203 - val_loss: 0.5667 - val_soft_acc: 0.4825\n",
      "Epoch 684/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4659 - soft_acc: 0.6049 - val_loss: 0.5640 - val_soft_acc: 0.5000\n",
      "Epoch 685/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.4651 - soft_acc: 0.6115 - val_loss: 0.5676 - val_soft_acc: 0.4825\n",
      "Epoch 686/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4653 - soft_acc: 0.6247 - val_loss: 0.5701 - val_soft_acc: 0.4561\n",
      "Epoch 687/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4659 - soft_acc: 0.6115 - val_loss: 0.5714 - val_soft_acc: 0.4474\n",
      "Epoch 688/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4650 - soft_acc: 0.6115 - val_loss: 0.5828 - val_soft_acc: 0.5175\n",
      "Epoch 689/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.4644 - soft_acc: 0.6203 - val_loss: 0.5711 - val_soft_acc: 0.5175\n",
      "Epoch 690/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4628 - soft_acc: 0.6269 - val_loss: 0.5832 - val_soft_acc: 0.5175\n",
      "Epoch 691/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4640 - soft_acc: 0.6203 - val_loss: 0.5716 - val_soft_acc: 0.5088\n",
      "Epoch 692/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.4619 - soft_acc: 0.6225 - val_loss: 0.5844 - val_soft_acc: 0.5351\n",
      "Epoch 693/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.4632 - soft_acc: 0.6203 - val_loss: 0.5628 - val_soft_acc: 0.5088\n",
      "Epoch 694/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4620 - soft_acc: 0.6203 - val_loss: 0.5684 - val_soft_acc: 0.5088\n",
      "Epoch 695/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4612 - soft_acc: 0.6071 - val_loss: 0.5637 - val_soft_acc: 0.5175\n",
      "Epoch 696/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4629 - soft_acc: 0.6247 - val_loss: 0.5639 - val_soft_acc: 0.4912\n",
      "Epoch 697/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4605 - soft_acc: 0.6137 - val_loss: 0.5636 - val_soft_acc: 0.5000\n",
      "Epoch 698/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.4622 - soft_acc: 0.6159 - val_loss: 0.5761 - val_soft_acc: 0.5175\n",
      "Epoch 699/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4611 - soft_acc: 0.6247 - val_loss: 0.5606 - val_soft_acc: 0.5175\n",
      "Epoch 700/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4564 - soft_acc: 0.6181 - val_loss: 0.5607 - val_soft_acc: 0.5175\n",
      "Epoch 701/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.4588 - soft_acc: 0.6247 - val_loss: 0.5652 - val_soft_acc: 0.4649\n",
      "Epoch 702/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4610 - soft_acc: 0.6313 - val_loss: 0.5631 - val_soft_acc: 0.5000\n",
      "Epoch 703/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.4618 - soft_acc: 0.6137 - val_loss: 0.5663 - val_soft_acc: 0.5000\n",
      "Epoch 704/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4581 - soft_acc: 0.6247 - val_loss: 0.5673 - val_soft_acc: 0.5000\n",
      "Epoch 705/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4621 - soft_acc: 0.6181 - val_loss: 0.5667 - val_soft_acc: 0.4825\n",
      "Epoch 706/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4593 - soft_acc: 0.6203 - val_loss: 0.5679 - val_soft_acc: 0.5175\n",
      "Epoch 707/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4569 - soft_acc: 0.6093 - val_loss: 0.5653 - val_soft_acc: 0.4649\n",
      "Epoch 708/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4631 - soft_acc: 0.6159 - val_loss: 0.5822 - val_soft_acc: 0.5263\n",
      "Epoch 709/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4601 - soft_acc: 0.6115 - val_loss: 0.5753 - val_soft_acc: 0.5175\n",
      "Epoch 710/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4581 - soft_acc: 0.6159 - val_loss: 0.5750 - val_soft_acc: 0.5088\n",
      "Epoch 711/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4594 - soft_acc: 0.6181 - val_loss: 0.5616 - val_soft_acc: 0.4825\n",
      "Epoch 712/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.4610 - soft_acc: 0.6181 - val_loss: 0.5735 - val_soft_acc: 0.5263\n",
      "Epoch 713/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4587 - soft_acc: 0.6203 - val_loss: 0.5758 - val_soft_acc: 0.5263\n",
      "Epoch 714/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4569 - soft_acc: 0.6336 - val_loss: 0.5614 - val_soft_acc: 0.5088\n",
      "Epoch 715/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4574 - soft_acc: 0.6225 - val_loss: 0.5595 - val_soft_acc: 0.5000\n",
      "Epoch 716/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4574 - soft_acc: 0.6203 - val_loss: 0.5668 - val_soft_acc: 0.5000\n",
      "Epoch 717/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 267us/step - loss: 0.4583 - soft_acc: 0.6137 - val_loss: 0.5713 - val_soft_acc: 0.4912\n",
      "Epoch 718/2000\n",
      "453/453 [==============================] - 0s 305us/step - loss: 0.4569 - soft_acc: 0.6203 - val_loss: 0.5822 - val_soft_acc: 0.5439\n",
      "Epoch 719/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4577 - soft_acc: 0.6225 - val_loss: 0.5618 - val_soft_acc: 0.5175\n",
      "Epoch 720/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.4567 - soft_acc: 0.6225 - val_loss: 0.5652 - val_soft_acc: 0.5000\n",
      "Epoch 721/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.4582 - soft_acc: 0.6336 - val_loss: 0.5807 - val_soft_acc: 0.5439\n",
      "Epoch 722/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4570 - soft_acc: 0.6313 - val_loss: 0.5635 - val_soft_acc: 0.5000\n",
      "Epoch 723/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4541 - soft_acc: 0.6225 - val_loss: 0.5818 - val_soft_acc: 0.5351\n",
      "Epoch 724/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4562 - soft_acc: 0.6291 - val_loss: 0.5655 - val_soft_acc: 0.4912\n",
      "Epoch 725/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.4555 - soft_acc: 0.6269 - val_loss: 0.5690 - val_soft_acc: 0.4649\n",
      "Epoch 726/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.4556 - soft_acc: 0.6203 - val_loss: 0.5713 - val_soft_acc: 0.5175\n",
      "Epoch 727/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.4533 - soft_acc: 0.6291 - val_loss: 0.6028 - val_soft_acc: 0.5351\n",
      "Epoch 728/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4620 - soft_acc: 0.6225 - val_loss: 0.5960 - val_soft_acc: 0.5351\n",
      "Epoch 729/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.4559 - soft_acc: 0.6402 - val_loss: 0.5662 - val_soft_acc: 0.5000\n",
      "Epoch 730/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4548 - soft_acc: 0.6269 - val_loss: 0.5743 - val_soft_acc: 0.5088\n",
      "Epoch 731/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4555 - soft_acc: 0.6313 - val_loss: 0.5760 - val_soft_acc: 0.5088\n",
      "Epoch 732/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4535 - soft_acc: 0.6313 - val_loss: 0.5752 - val_soft_acc: 0.4912\n",
      "Epoch 733/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4538 - soft_acc: 0.6269 - val_loss: 0.5769 - val_soft_acc: 0.5351\n",
      "Epoch 734/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4548 - soft_acc: 0.6424 - val_loss: 0.5693 - val_soft_acc: 0.5088\n",
      "Epoch 735/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4530 - soft_acc: 0.6313 - val_loss: 0.5806 - val_soft_acc: 0.5351\n",
      "Epoch 736/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4542 - soft_acc: 0.6336 - val_loss: 0.5699 - val_soft_acc: 0.5000\n",
      "Epoch 737/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4584 - soft_acc: 0.6380 - val_loss: 0.5709 - val_soft_acc: 0.4737\n",
      "Epoch 738/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4512 - soft_acc: 0.6336 - val_loss: 0.5723 - val_soft_acc: 0.5175\n",
      "Epoch 739/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.4518 - soft_acc: 0.6336 - val_loss: 0.5738 - val_soft_acc: 0.5088\n",
      "Epoch 740/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4507 - soft_acc: 0.6336 - val_loss: 0.5661 - val_soft_acc: 0.5088\n",
      "Epoch 741/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.4525 - soft_acc: 0.6159 - val_loss: 0.5682 - val_soft_acc: 0.5000\n",
      "Epoch 742/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4516 - soft_acc: 0.6225 - val_loss: 0.5673 - val_soft_acc: 0.5000\n",
      "Epoch 743/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4531 - soft_acc: 0.6336 - val_loss: 0.5755 - val_soft_acc: 0.5263\n",
      "Epoch 744/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.4502 - soft_acc: 0.6402 - val_loss: 0.5723 - val_soft_acc: 0.5088\n",
      "Epoch 745/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.4507 - soft_acc: 0.6291 - val_loss: 0.5657 - val_soft_acc: 0.5000\n",
      "Epoch 746/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.4490 - soft_acc: 0.6402 - val_loss: 0.5696 - val_soft_acc: 0.4825\n",
      "Epoch 747/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4505 - soft_acc: 0.6446 - val_loss: 0.5701 - val_soft_acc: 0.4912\n",
      "Epoch 748/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4560 - soft_acc: 0.6269 - val_loss: 0.5617 - val_soft_acc: 0.5175\n",
      "Epoch 749/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4502 - soft_acc: 0.6358 - val_loss: 0.5634 - val_soft_acc: 0.5000\n",
      "Epoch 750/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4483 - soft_acc: 0.6358 - val_loss: 0.5757 - val_soft_acc: 0.5000\n",
      "Epoch 751/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4476 - soft_acc: 0.6424 - val_loss: 0.5669 - val_soft_acc: 0.4912\n",
      "Epoch 752/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4518 - soft_acc: 0.6468 - val_loss: 0.5672 - val_soft_acc: 0.4912\n",
      "Epoch 753/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4486 - soft_acc: 0.6446 - val_loss: 0.5848 - val_soft_acc: 0.4649\n",
      "Epoch 754/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.4581 - soft_acc: 0.6402 - val_loss: 0.5696 - val_soft_acc: 0.4825\n",
      "Epoch 755/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4498 - soft_acc: 0.6468 - val_loss: 0.5640 - val_soft_acc: 0.5351\n",
      "Epoch 756/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4484 - soft_acc: 0.6424 - val_loss: 0.5794 - val_soft_acc: 0.5263\n",
      "Epoch 757/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4486 - soft_acc: 0.6358 - val_loss: 0.5729 - val_soft_acc: 0.5000\n",
      "Epoch 758/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.4508 - soft_acc: 0.6291 - val_loss: 0.5691 - val_soft_acc: 0.5088\n",
      "Epoch 759/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.4504 - soft_acc: 0.6269 - val_loss: 0.5716 - val_soft_acc: 0.5088\n",
      "Epoch 760/2000\n",
      "453/453 [==============================] - 0s 310us/step - loss: 0.4494 - soft_acc: 0.6313 - val_loss: 0.5811 - val_soft_acc: 0.5526\n",
      "Epoch 761/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4498 - soft_acc: 0.6336 - val_loss: 0.5640 - val_soft_acc: 0.5000\n",
      "Epoch 762/2000\n",
      "453/453 [==============================] - 0s 300us/step - loss: 0.4492 - soft_acc: 0.6402 - val_loss: 0.5791 - val_soft_acc: 0.5614\n",
      "Epoch 763/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.4505 - soft_acc: 0.6313 - val_loss: 0.5796 - val_soft_acc: 0.5526\n",
      "Epoch 764/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4467 - soft_acc: 0.6468 - val_loss: 0.5945 - val_soft_acc: 0.5439\n",
      "Epoch 765/2000\n",
      "453/453 [==============================] - 0s 284us/step - loss: 0.4528 - soft_acc: 0.6358 - val_loss: 0.5795 - val_soft_acc: 0.5351\n",
      "Epoch 766/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4465 - soft_acc: 0.6446 - val_loss: 0.5651 - val_soft_acc: 0.5088\n",
      "Epoch 767/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4455 - soft_acc: 0.6313 - val_loss: 0.5744 - val_soft_acc: 0.4825\n",
      "Epoch 768/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4540 - soft_acc: 0.6512 - val_loss: 0.5848 - val_soft_acc: 0.5175\n",
      "Epoch 769/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4498 - soft_acc: 0.6446 - val_loss: 0.5720 - val_soft_acc: 0.4649\n",
      "Epoch 770/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4477 - soft_acc: 0.6336 - val_loss: 0.5743 - val_soft_acc: 0.5175\n",
      "Epoch 771/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4468 - soft_acc: 0.6358 - val_loss: 0.5721 - val_soft_acc: 0.5175\n",
      "Epoch 772/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 277us/step - loss: 0.4470 - soft_acc: 0.6313 - val_loss: 0.5602 - val_soft_acc: 0.5263\n",
      "Epoch 773/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.4447 - soft_acc: 0.6358 - val_loss: 0.5769 - val_soft_acc: 0.5175\n",
      "Epoch 774/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4469 - soft_acc: 0.6402 - val_loss: 0.5824 - val_soft_acc: 0.5175\n",
      "Epoch 775/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4484 - soft_acc: 0.6512 - val_loss: 0.5649 - val_soft_acc: 0.5175\n",
      "Epoch 776/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.4448 - soft_acc: 0.6512 - val_loss: 0.5625 - val_soft_acc: 0.5263\n",
      "Epoch 777/2000\n",
      "453/453 [==============================] - 0s 289us/step - loss: 0.4452 - soft_acc: 0.6380 - val_loss: 0.5624 - val_soft_acc: 0.5000\n",
      "Epoch 778/2000\n",
      "453/453 [==============================] - 0s 289us/step - loss: 0.4467 - soft_acc: 0.6380 - val_loss: 0.5630 - val_soft_acc: 0.5000\n",
      "Epoch 779/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.4485 - soft_acc: 0.6424 - val_loss: 0.5588 - val_soft_acc: 0.5088\n",
      "Epoch 780/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4454 - soft_acc: 0.6512 - val_loss: 0.5721 - val_soft_acc: 0.5263\n",
      "Epoch 781/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4459 - soft_acc: 0.6424 - val_loss: 0.5626 - val_soft_acc: 0.4912\n",
      "Epoch 782/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4458 - soft_acc: 0.6490 - val_loss: 0.5695 - val_soft_acc: 0.5088\n",
      "Epoch 783/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4463 - soft_acc: 0.6380 - val_loss: 0.5737 - val_soft_acc: 0.5263\n",
      "Epoch 784/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4499 - soft_acc: 0.6424 - val_loss: 0.5672 - val_soft_acc: 0.5351\n",
      "Epoch 785/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4431 - soft_acc: 0.6358 - val_loss: 0.5585 - val_soft_acc: 0.5088\n",
      "Epoch 786/2000\n",
      "453/453 [==============================] - 0s 285us/step - loss: 0.4424 - soft_acc: 0.6402 - val_loss: 0.5634 - val_soft_acc: 0.5000\n",
      "Epoch 787/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4446 - soft_acc: 0.6291 - val_loss: 0.5621 - val_soft_acc: 0.5263\n",
      "Epoch 788/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4416 - soft_acc: 0.6512 - val_loss: 0.5635 - val_soft_acc: 0.5000\n",
      "Epoch 789/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.4418 - soft_acc: 0.6512 - val_loss: 0.5677 - val_soft_acc: 0.5000\n",
      "Epoch 790/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4452 - soft_acc: 0.6468 - val_loss: 0.5625 - val_soft_acc: 0.5263\n",
      "Epoch 791/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4422 - soft_acc: 0.6512 - val_loss: 0.5672 - val_soft_acc: 0.5088\n",
      "Epoch 792/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4431 - soft_acc: 0.6600 - val_loss: 0.6026 - val_soft_acc: 0.5439\n",
      "Epoch 793/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4484 - soft_acc: 0.6468 - val_loss: 0.5783 - val_soft_acc: 0.5351\n",
      "Epoch 794/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.4445 - soft_acc: 0.6446 - val_loss: 0.5653 - val_soft_acc: 0.5263\n",
      "Epoch 795/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4451 - soft_acc: 0.6512 - val_loss: 0.5671 - val_soft_acc: 0.5088\n",
      "Epoch 796/2000\n",
      "453/453 [==============================] - 0s 318us/step - loss: 0.4446 - soft_acc: 0.6556 - val_loss: 0.5927 - val_soft_acc: 0.5702\n",
      "Epoch 797/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4468 - soft_acc: 0.6512 - val_loss: 0.5783 - val_soft_acc: 0.5175\n",
      "Epoch 798/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4417 - soft_acc: 0.6490 - val_loss: 0.5684 - val_soft_acc: 0.5088\n",
      "Epoch 799/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4398 - soft_acc: 0.6600 - val_loss: 0.5673 - val_soft_acc: 0.4912\n",
      "Epoch 800/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4413 - soft_acc: 0.6534 - val_loss: 0.5825 - val_soft_acc: 0.5263\n",
      "Epoch 801/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4411 - soft_acc: 0.6490 - val_loss: 0.5692 - val_soft_acc: 0.4912\n",
      "Epoch 802/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4407 - soft_acc: 0.6446 - val_loss: 0.5607 - val_soft_acc: 0.5000\n",
      "Epoch 803/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4417 - soft_acc: 0.6468 - val_loss: 0.5718 - val_soft_acc: 0.5439\n",
      "Epoch 804/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.4433 - soft_acc: 0.6424 - val_loss: 0.5779 - val_soft_acc: 0.5439\n",
      "Epoch 805/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4420 - soft_acc: 0.6468 - val_loss: 0.5861 - val_soft_acc: 0.5439\n",
      "Epoch 806/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4439 - soft_acc: 0.6534 - val_loss: 0.5782 - val_soft_acc: 0.5175\n",
      "Epoch 807/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4442 - soft_acc: 0.6490 - val_loss: 0.5913 - val_soft_acc: 0.5263\n",
      "Epoch 808/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4426 - soft_acc: 0.6512 - val_loss: 0.5815 - val_soft_acc: 0.5702\n",
      "Epoch 809/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4408 - soft_acc: 0.6446 - val_loss: 0.5661 - val_soft_acc: 0.5088\n",
      "Epoch 810/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4398 - soft_acc: 0.6556 - val_loss: 0.5628 - val_soft_acc: 0.5000\n",
      "Epoch 811/2000\n",
      "453/453 [==============================] - 0s 288us/step - loss: 0.4409 - soft_acc: 0.6623 - val_loss: 0.5926 - val_soft_acc: 0.5439\n",
      "Epoch 812/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4417 - soft_acc: 0.6534 - val_loss: 0.5912 - val_soft_acc: 0.5439\n",
      "Epoch 813/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4398 - soft_acc: 0.6424 - val_loss: 0.5814 - val_soft_acc: 0.5351\n",
      "Epoch 814/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4407 - soft_acc: 0.6446 - val_loss: 0.5698 - val_soft_acc: 0.4825\n",
      "Epoch 815/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4420 - soft_acc: 0.6468 - val_loss: 0.5849 - val_soft_acc: 0.5263\n",
      "Epoch 816/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4378 - soft_acc: 0.6556 - val_loss: 0.5761 - val_soft_acc: 0.5088\n",
      "Epoch 817/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4385 - soft_acc: 0.6689 - val_loss: 0.5714 - val_soft_acc: 0.5351\n",
      "Epoch 818/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.4410 - soft_acc: 0.6490 - val_loss: 0.5866 - val_soft_acc: 0.5175\n",
      "Epoch 819/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4409 - soft_acc: 0.6490 - val_loss: 0.5683 - val_soft_acc: 0.5088\n",
      "Epoch 820/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4387 - soft_acc: 0.6534 - val_loss: 0.5998 - val_soft_acc: 0.5439\n",
      "Epoch 821/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4398 - soft_acc: 0.6512 - val_loss: 0.5680 - val_soft_acc: 0.4825\n",
      "Epoch 822/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4360 - soft_acc: 0.6578 - val_loss: 0.5810 - val_soft_acc: 0.5175\n",
      "Epoch 823/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4438 - soft_acc: 0.6490 - val_loss: 0.6137 - val_soft_acc: 0.5263\n",
      "Epoch 824/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.4445 - soft_acc: 0.6490 - val_loss: 0.5608 - val_soft_acc: 0.4912\n",
      "Epoch 825/2000\n",
      "453/453 [==============================] - 0s 305us/step - loss: 0.4383 - soft_acc: 0.6490 - val_loss: 0.5624 - val_soft_acc: 0.5000\n",
      "Epoch 826/2000\n",
      "453/453 [==============================] - 0s 329us/step - loss: 0.4414 - soft_acc: 0.6380 - val_loss: 0.5615 - val_soft_acc: 0.5175\n",
      "Epoch 827/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 325us/step - loss: 0.4420 - soft_acc: 0.6424 - val_loss: 0.5567 - val_soft_acc: 0.5088\n",
      "Epoch 828/2000\n",
      "453/453 [==============================] - 0s 293us/step - loss: 0.4337 - soft_acc: 0.6556 - val_loss: 0.5557 - val_soft_acc: 0.5000\n",
      "Epoch 829/2000\n",
      "453/453 [==============================] - 0s 284us/step - loss: 0.4388 - soft_acc: 0.6534 - val_loss: 0.5694 - val_soft_acc: 0.5088\n",
      "Epoch 830/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.4382 - soft_acc: 0.6556 - val_loss: 0.5623 - val_soft_acc: 0.5088\n",
      "Epoch 831/2000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.4375 - soft_acc: 0.6446 - val_loss: 0.5713 - val_soft_acc: 0.5088\n",
      "Epoch 832/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.4382 - soft_acc: 0.6468 - val_loss: 0.5727 - val_soft_acc: 0.5088\n",
      "Epoch 833/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4371 - soft_acc: 0.6446 - val_loss: 0.5850 - val_soft_acc: 0.5526\n",
      "Epoch 834/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4394 - soft_acc: 0.6490 - val_loss: 0.5620 - val_soft_acc: 0.5088\n",
      "Epoch 835/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4347 - soft_acc: 0.6534 - val_loss: 0.5637 - val_soft_acc: 0.5263\n",
      "Epoch 836/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4361 - soft_acc: 0.6667 - val_loss: 0.5630 - val_soft_acc: 0.4825\n",
      "Epoch 837/2000\n",
      "453/453 [==============================] - 0s 314us/step - loss: 0.4352 - soft_acc: 0.6534 - val_loss: 0.5688 - val_soft_acc: 0.5000\n",
      "Epoch 838/2000\n",
      "453/453 [==============================] - 0s 322us/step - loss: 0.4393 - soft_acc: 0.6645 - val_loss: 0.5664 - val_soft_acc: 0.5263\n",
      "Epoch 839/2000\n",
      "453/453 [==============================] - 0s 325us/step - loss: 0.4337 - soft_acc: 0.6490 - val_loss: 0.6060 - val_soft_acc: 0.5351\n",
      "Epoch 840/2000\n",
      "453/453 [==============================] - 0s 303us/step - loss: 0.4398 - soft_acc: 0.6600 - val_loss: 0.5661 - val_soft_acc: 0.4912\n",
      "Epoch 841/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4355 - soft_acc: 0.6534 - val_loss: 0.5733 - val_soft_acc: 0.4912\n",
      "Epoch 842/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.4376 - soft_acc: 0.6424 - val_loss: 0.5721 - val_soft_acc: 0.5088\n",
      "Epoch 843/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.4342 - soft_acc: 0.6600 - val_loss: 0.5997 - val_soft_acc: 0.5439\n",
      "Epoch 844/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4376 - soft_acc: 0.6667 - val_loss: 0.5661 - val_soft_acc: 0.5263\n",
      "Epoch 845/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4348 - soft_acc: 0.6534 - val_loss: 0.5627 - val_soft_acc: 0.5175\n",
      "Epoch 846/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.4328 - soft_acc: 0.6578 - val_loss: 0.5681 - val_soft_acc: 0.4912\n",
      "Epoch 847/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.4335 - soft_acc: 0.6600 - val_loss: 0.5764 - val_soft_acc: 0.5175\n",
      "Epoch 848/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4335 - soft_acc: 0.6512 - val_loss: 0.5672 - val_soft_acc: 0.4737\n",
      "Epoch 849/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4324 - soft_acc: 0.6600 - val_loss: 0.5669 - val_soft_acc: 0.5175\n",
      "Epoch 850/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.4341 - soft_acc: 0.6534 - val_loss: 0.5714 - val_soft_acc: 0.4825\n",
      "Epoch 851/2000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.4349 - soft_acc: 0.6667 - val_loss: 0.5629 - val_soft_acc: 0.5088\n",
      "Epoch 852/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4350 - soft_acc: 0.6512 - val_loss: 0.5626 - val_soft_acc: 0.5000\n",
      "Epoch 853/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4319 - soft_acc: 0.6490 - val_loss: 0.6008 - val_soft_acc: 0.5526\n",
      "Epoch 854/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4363 - soft_acc: 0.6600 - val_loss: 0.5677 - val_soft_acc: 0.4825\n",
      "Epoch 855/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4371 - soft_acc: 0.6578 - val_loss: 0.5602 - val_soft_acc: 0.5175\n",
      "Epoch 856/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.4326 - soft_acc: 0.6578 - val_loss: 0.5580 - val_soft_acc: 0.5263\n",
      "Epoch 857/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.4342 - soft_acc: 0.6490 - val_loss: 0.5679 - val_soft_acc: 0.4649\n",
      "Epoch 858/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4367 - soft_acc: 0.6446 - val_loss: 0.5640 - val_soft_acc: 0.5526\n",
      "Epoch 859/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.4313 - soft_acc: 0.6556 - val_loss: 0.5658 - val_soft_acc: 0.5263\n",
      "Epoch 860/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4320 - soft_acc: 0.6600 - val_loss: 0.5734 - val_soft_acc: 0.5175\n",
      "Epoch 861/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4322 - soft_acc: 0.6490 - val_loss: 0.5892 - val_soft_acc: 0.5439\n",
      "Epoch 862/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4370 - soft_acc: 0.6578 - val_loss: 0.5615 - val_soft_acc: 0.5263\n",
      "Epoch 863/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4312 - soft_acc: 0.6556 - val_loss: 0.5614 - val_soft_acc: 0.5526\n",
      "Epoch 864/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.4336 - soft_acc: 0.6446 - val_loss: 0.5743 - val_soft_acc: 0.5351\n",
      "Epoch 865/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4317 - soft_acc: 0.6578 - val_loss: 0.5671 - val_soft_acc: 0.5000\n",
      "Epoch 866/2000\n",
      "453/453 [==============================] - 0s 288us/step - loss: 0.4331 - soft_acc: 0.6490 - val_loss: 0.5675 - val_soft_acc: 0.5175\n",
      "Epoch 867/2000\n",
      "453/453 [==============================] - 0s 302us/step - loss: 0.4303 - soft_acc: 0.6667 - val_loss: 0.5660 - val_soft_acc: 0.5088\n",
      "Epoch 868/2000\n",
      "453/453 [==============================] - 0s 300us/step - loss: 0.4322 - soft_acc: 0.6556 - val_loss: 0.5899 - val_soft_acc: 0.5263\n",
      "Epoch 869/2000\n",
      "453/453 [==============================] - 0s 291us/step - loss: 0.4355 - soft_acc: 0.6446 - val_loss: 0.5801 - val_soft_acc: 0.5351\n",
      "Epoch 870/2000\n",
      "453/453 [==============================] - 0s 302us/step - loss: 0.4308 - soft_acc: 0.6490 - val_loss: 0.5798 - val_soft_acc: 0.5175\n",
      "Epoch 871/2000\n",
      "453/453 [==============================] - 0s 294us/step - loss: 0.4305 - soft_acc: 0.6667 - val_loss: 0.5566 - val_soft_acc: 0.5175\n",
      "Epoch 872/2000\n",
      "453/453 [==============================] - 0s 297us/step - loss: 0.4282 - soft_acc: 0.6689 - val_loss: 0.5676 - val_soft_acc: 0.4825\n",
      "Epoch 873/2000\n",
      "453/453 [==============================] - 0s 289us/step - loss: 0.4367 - soft_acc: 0.6556 - val_loss: 0.5688 - val_soft_acc: 0.5439\n",
      "Epoch 874/2000\n",
      "453/453 [==============================] - 0s 298us/step - loss: 0.4291 - soft_acc: 0.6534 - val_loss: 0.5717 - val_soft_acc: 0.5439\n",
      "Epoch 875/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4272 - soft_acc: 0.6534 - val_loss: 0.5709 - val_soft_acc: 0.4825\n",
      "Epoch 876/2000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.4321 - soft_acc: 0.6689 - val_loss: 0.5587 - val_soft_acc: 0.5526\n",
      "Epoch 877/2000\n",
      "453/453 [==============================] - 0s 287us/step - loss: 0.4311 - soft_acc: 0.6645 - val_loss: 0.5688 - val_soft_acc: 0.5351\n",
      "Epoch 878/2000\n",
      "453/453 [==============================] - 0s 293us/step - loss: 0.4296 - soft_acc: 0.6667 - val_loss: 0.5593 - val_soft_acc: 0.5439\n",
      "Epoch 879/2000\n",
      "453/453 [==============================] - 0s 285us/step - loss: 0.4298 - soft_acc: 0.6512 - val_loss: 0.5631 - val_soft_acc: 0.5175\n",
      "Epoch 880/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4285 - soft_acc: 0.6623 - val_loss: 0.5952 - val_soft_acc: 0.5351\n",
      "Epoch 881/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4370 - soft_acc: 0.6645 - val_loss: 0.5705 - val_soft_acc: 0.5351\n",
      "Epoch 882/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 278us/step - loss: 0.4277 - soft_acc: 0.6799 - val_loss: 0.5532 - val_soft_acc: 0.5351\n",
      "Epoch 883/2000\n",
      "453/453 [==============================] - 0s 290us/step - loss: 0.4278 - soft_acc: 0.6645 - val_loss: 0.5679 - val_soft_acc: 0.5263\n",
      "Epoch 884/2000\n",
      "453/453 [==============================] - 0s 287us/step - loss: 0.4271 - soft_acc: 0.6578 - val_loss: 0.5664 - val_soft_acc: 0.4737\n",
      "Epoch 885/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.4354 - soft_acc: 0.6468 - val_loss: 0.5623 - val_soft_acc: 0.4825\n",
      "Epoch 886/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.4293 - soft_acc: 0.6645 - val_loss: 0.5785 - val_soft_acc: 0.5351\n",
      "Epoch 887/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.4299 - soft_acc: 0.6468 - val_loss: 0.5624 - val_soft_acc: 0.5175\n",
      "Epoch 888/2000\n",
      "453/453 [==============================] - 0s 285us/step - loss: 0.4275 - soft_acc: 0.6733 - val_loss: 0.5624 - val_soft_acc: 0.4912\n",
      "Epoch 889/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4292 - soft_acc: 0.6667 - val_loss: 0.5755 - val_soft_acc: 0.5263\n",
      "Epoch 890/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4254 - soft_acc: 0.6689 - val_loss: 0.5635 - val_soft_acc: 0.5175\n",
      "Epoch 891/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.4264 - soft_acc: 0.6733 - val_loss: 0.5583 - val_soft_acc: 0.5263\n",
      "Epoch 892/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4272 - soft_acc: 0.6777 - val_loss: 0.5628 - val_soft_acc: 0.5439\n",
      "Epoch 893/2000\n",
      "453/453 [==============================] - 0s 284us/step - loss: 0.4247 - soft_acc: 0.6755 - val_loss: 0.5757 - val_soft_acc: 0.5263\n",
      "Epoch 894/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4255 - soft_acc: 0.6667 - val_loss: 0.5675 - val_soft_acc: 0.5263\n",
      "Epoch 895/2000\n",
      "453/453 [==============================] - 0s 288us/step - loss: 0.4272 - soft_acc: 0.6645 - val_loss: 0.5635 - val_soft_acc: 0.5263\n",
      "Epoch 896/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.4301 - soft_acc: 0.6578 - val_loss: 0.5607 - val_soft_acc: 0.5263\n",
      "Epoch 897/2000\n",
      "453/453 [==============================] - 0s 293us/step - loss: 0.4303 - soft_acc: 0.6512 - val_loss: 0.5627 - val_soft_acc: 0.5351\n",
      "Epoch 898/2000\n",
      "453/453 [==============================] - 0s 298us/step - loss: 0.4265 - soft_acc: 0.6777 - val_loss: 0.5926 - val_soft_acc: 0.5439\n",
      "Epoch 899/2000\n",
      "453/453 [==============================] - 0s 284us/step - loss: 0.4296 - soft_acc: 0.6711 - val_loss: 0.5616 - val_soft_acc: 0.5351\n",
      "Epoch 900/2000\n",
      "453/453 [==============================] - 0s 292us/step - loss: 0.4267 - soft_acc: 0.6777 - val_loss: 0.5629 - val_soft_acc: 0.5526\n",
      "Epoch 901/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4254 - soft_acc: 0.6733 - val_loss: 0.5737 - val_soft_acc: 0.5263\n",
      "Epoch 902/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4275 - soft_acc: 0.6689 - val_loss: 0.5712 - val_soft_acc: 0.5351\n",
      "Epoch 903/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4277 - soft_acc: 0.6623 - val_loss: 0.5763 - val_soft_acc: 0.5263\n",
      "Epoch 904/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.4257 - soft_acc: 0.6556 - val_loss: 0.5662 - val_soft_acc: 0.5175\n",
      "Epoch 905/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4271 - soft_acc: 0.6468 - val_loss: 0.5642 - val_soft_acc: 0.5526\n",
      "Epoch 906/2000\n",
      "453/453 [==============================] - 0s 289us/step - loss: 0.4244 - soft_acc: 0.6755 - val_loss: 0.5597 - val_soft_acc: 0.5526\n",
      "Epoch 907/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.4255 - soft_acc: 0.6711 - val_loss: 0.5592 - val_soft_acc: 0.5351\n",
      "Epoch 908/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.4295 - soft_acc: 0.6556 - val_loss: 0.5629 - val_soft_acc: 0.5526\n",
      "Epoch 909/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.4248 - soft_acc: 0.6578 - val_loss: 0.5786 - val_soft_acc: 0.5439\n",
      "Epoch 910/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4260 - soft_acc: 0.6777 - val_loss: 0.5567 - val_soft_acc: 0.5351\n",
      "Epoch 911/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4271 - soft_acc: 0.6755 - val_loss: 0.5863 - val_soft_acc: 0.5351\n",
      "Epoch 912/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.4258 - soft_acc: 0.6689 - val_loss: 0.5674 - val_soft_acc: 0.5351\n",
      "Epoch 913/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4238 - soft_acc: 0.6733 - val_loss: 0.5655 - val_soft_acc: 0.5439\n",
      "Epoch 914/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4264 - soft_acc: 0.6667 - val_loss: 0.5779 - val_soft_acc: 0.5088\n",
      "Epoch 915/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4284 - soft_acc: 0.6821 - val_loss: 0.5704 - val_soft_acc: 0.5088\n",
      "Epoch 916/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4225 - soft_acc: 0.6711 - val_loss: 0.5612 - val_soft_acc: 0.5263\n",
      "Epoch 917/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.4244 - soft_acc: 0.6777 - val_loss: 0.5749 - val_soft_acc: 0.5351\n",
      "Epoch 918/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.4290 - soft_acc: 0.6711 - val_loss: 0.5622 - val_soft_acc: 0.4912\n",
      "Epoch 919/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4221 - soft_acc: 0.6799 - val_loss: 0.5768 - val_soft_acc: 0.5263\n",
      "Epoch 920/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4247 - soft_acc: 0.6711 - val_loss: 0.5921 - val_soft_acc: 0.5526\n",
      "Epoch 921/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4284 - soft_acc: 0.6755 - val_loss: 0.5597 - val_soft_acc: 0.4825\n",
      "Epoch 922/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.4243 - soft_acc: 0.6887 - val_loss: 0.5602 - val_soft_acc: 0.5351\n",
      "Epoch 923/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.4260 - soft_acc: 0.6623 - val_loss: 0.5651 - val_soft_acc: 0.5263\n",
      "Epoch 924/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4212 - soft_acc: 0.6821 - val_loss: 0.5603 - val_soft_acc: 0.5351\n",
      "Epoch 925/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.4252 - soft_acc: 0.6645 - val_loss: 0.5707 - val_soft_acc: 0.5526\n",
      "Epoch 926/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4245 - soft_acc: 0.6689 - val_loss: 0.5572 - val_soft_acc: 0.5175\n",
      "Epoch 927/2000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.4249 - soft_acc: 0.6600 - val_loss: 0.5577 - val_soft_acc: 0.4912\n",
      "Epoch 928/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4252 - soft_acc: 0.6755 - val_loss: 0.5513 - val_soft_acc: 0.5439\n",
      "Epoch 929/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.4187 - soft_acc: 0.6821 - val_loss: 0.5589 - val_soft_acc: 0.5439\n",
      "Epoch 930/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4232 - soft_acc: 0.6689 - val_loss: 0.6001 - val_soft_acc: 0.5351\n",
      "Epoch 931/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4282 - soft_acc: 0.6623 - val_loss: 0.5975 - val_soft_acc: 0.5702\n",
      "Epoch 932/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.4247 - soft_acc: 0.6755 - val_loss: 0.5703 - val_soft_acc: 0.5088\n",
      "Epoch 933/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4210 - soft_acc: 0.6755 - val_loss: 0.5815 - val_soft_acc: 0.5263\n",
      "Epoch 934/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4217 - soft_acc: 0.6777 - val_loss: 0.5653 - val_soft_acc: 0.5351\n",
      "Epoch 935/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4204 - soft_acc: 0.6799 - val_loss: 0.5661 - val_soft_acc: 0.5263\n",
      "Epoch 936/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.4218 - soft_acc: 0.6733 - val_loss: 0.5737 - val_soft_acc: 0.5351\n",
      "Epoch 937/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 275us/step - loss: 0.4226 - soft_acc: 0.6755 - val_loss: 0.5662 - val_soft_acc: 0.5526\n",
      "Epoch 938/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.4230 - soft_acc: 0.6711 - val_loss: 0.5682 - val_soft_acc: 0.4825\n",
      "Epoch 939/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4243 - soft_acc: 0.6733 - val_loss: 0.5925 - val_soft_acc: 0.5175\n",
      "Epoch 940/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4194 - soft_acc: 0.6733 - val_loss: 0.5701 - val_soft_acc: 0.5175\n",
      "Epoch 941/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4188 - soft_acc: 0.6777 - val_loss: 0.5657 - val_soft_acc: 0.5000\n",
      "Epoch 942/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4255 - soft_acc: 0.6799 - val_loss: 0.5747 - val_soft_acc: 0.4912\n",
      "Epoch 943/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4278 - soft_acc: 0.6689 - val_loss: 0.5667 - val_soft_acc: 0.5439\n",
      "Epoch 944/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.4202 - soft_acc: 0.6711 - val_loss: 0.5934 - val_soft_acc: 0.5614\n",
      "Epoch 945/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.4210 - soft_acc: 0.6711 - val_loss: 0.5623 - val_soft_acc: 0.5000\n",
      "Epoch 946/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.4219 - soft_acc: 0.6777 - val_loss: 0.5560 - val_soft_acc: 0.5351\n",
      "Epoch 947/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4216 - soft_acc: 0.6667 - val_loss: 0.5597 - val_soft_acc: 0.5175\n",
      "Epoch 948/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4204 - soft_acc: 0.6755 - val_loss: 0.5588 - val_soft_acc: 0.4912\n",
      "Epoch 949/2000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.4232 - soft_acc: 0.6777 - val_loss: 0.5595 - val_soft_acc: 0.5088\n",
      "Epoch 950/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4187 - soft_acc: 0.6733 - val_loss: 0.5547 - val_soft_acc: 0.5263\n",
      "Epoch 951/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.4200 - soft_acc: 0.6711 - val_loss: 0.5649 - val_soft_acc: 0.5175\n",
      "Epoch 952/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4216 - soft_acc: 0.6600 - val_loss: 0.5599 - val_soft_acc: 0.5351\n",
      "Epoch 953/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4206 - soft_acc: 0.6777 - val_loss: 0.5663 - val_soft_acc: 0.5351\n",
      "Epoch 954/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4209 - soft_acc: 0.6667 - val_loss: 0.5599 - val_soft_acc: 0.5263\n",
      "Epoch 955/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4193 - soft_acc: 0.6777 - val_loss: 0.5707 - val_soft_acc: 0.5263\n",
      "Epoch 956/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4208 - soft_acc: 0.6667 - val_loss: 0.5612 - val_soft_acc: 0.5175\n",
      "Epoch 957/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4227 - soft_acc: 0.6777 - val_loss: 0.5688 - val_soft_acc: 0.4912\n",
      "Epoch 958/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.4239 - soft_acc: 0.6821 - val_loss: 0.5637 - val_soft_acc: 0.5000\n",
      "Epoch 959/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4207 - soft_acc: 0.6843 - val_loss: 0.5559 - val_soft_acc: 0.5175\n",
      "Epoch 960/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.4186 - soft_acc: 0.6733 - val_loss: 0.5640 - val_soft_acc: 0.5175\n",
      "Epoch 961/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4215 - soft_acc: 0.6711 - val_loss: 0.5611 - val_soft_acc: 0.5263\n",
      "Epoch 962/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.4207 - soft_acc: 0.6667 - val_loss: 0.5603 - val_soft_acc: 0.5175\n",
      "Epoch 963/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.4191 - soft_acc: 0.6821 - val_loss: 0.5601 - val_soft_acc: 0.5000\n",
      "Epoch 964/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4180 - soft_acc: 0.6755 - val_loss: 0.5625 - val_soft_acc: 0.5088\n",
      "Epoch 965/2000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.4203 - soft_acc: 0.6755 - val_loss: 0.5562 - val_soft_acc: 0.5263\n",
      "Epoch 966/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4185 - soft_acc: 0.6821 - val_loss: 0.5825 - val_soft_acc: 0.5526\n",
      "Epoch 967/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4211 - soft_acc: 0.6777 - val_loss: 0.5635 - val_soft_acc: 0.5175\n",
      "Epoch 968/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4194 - soft_acc: 0.6821 - val_loss: 0.5585 - val_soft_acc: 0.5175\n",
      "Epoch 969/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4207 - soft_acc: 0.6821 - val_loss: 0.5556 - val_soft_acc: 0.5175\n",
      "Epoch 970/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4168 - soft_acc: 0.6821 - val_loss: 0.5810 - val_soft_acc: 0.5439\n",
      "Epoch 971/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4210 - soft_acc: 0.6821 - val_loss: 0.5745 - val_soft_acc: 0.5614\n",
      "Epoch 972/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4154 - soft_acc: 0.6909 - val_loss: 0.5552 - val_soft_acc: 0.5175\n",
      "Epoch 973/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.4181 - soft_acc: 0.6667 - val_loss: 0.6005 - val_soft_acc: 0.5351\n",
      "Epoch 974/2000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.4223 - soft_acc: 0.6821 - val_loss: 0.5582 - val_soft_acc: 0.5000\n",
      "Epoch 975/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.4189 - soft_acc: 0.6755 - val_loss: 0.5522 - val_soft_acc: 0.5439\n",
      "Epoch 976/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4216 - soft_acc: 0.6600 - val_loss: 0.5842 - val_soft_acc: 0.5614\n",
      "Epoch 977/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4173 - soft_acc: 0.6689 - val_loss: 0.5654 - val_soft_acc: 0.5351\n",
      "Epoch 978/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4154 - soft_acc: 0.6998 - val_loss: 0.5569 - val_soft_acc: 0.5000\n",
      "Epoch 979/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4181 - soft_acc: 0.6821 - val_loss: 0.5611 - val_soft_acc: 0.4912\n",
      "Epoch 980/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4189 - soft_acc: 0.6799 - val_loss: 0.5519 - val_soft_acc: 0.5263\n",
      "Epoch 981/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4148 - soft_acc: 0.6865 - val_loss: 0.5570 - val_soft_acc: 0.5088\n",
      "Epoch 982/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4161 - soft_acc: 0.6755 - val_loss: 0.5588 - val_soft_acc: 0.5263\n",
      "Epoch 983/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4159 - soft_acc: 0.6733 - val_loss: 0.5589 - val_soft_acc: 0.5526\n",
      "Epoch 984/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4148 - soft_acc: 0.6843 - val_loss: 0.5756 - val_soft_acc: 0.5526\n",
      "Epoch 985/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4188 - soft_acc: 0.6777 - val_loss: 0.5602 - val_soft_acc: 0.5088\n",
      "Epoch 986/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4188 - soft_acc: 0.6909 - val_loss: 0.5828 - val_soft_acc: 0.5526\n",
      "Epoch 987/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.4180 - soft_acc: 0.6909 - val_loss: 0.5575 - val_soft_acc: 0.5175\n",
      "Epoch 988/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4164 - soft_acc: 0.6932 - val_loss: 0.5845 - val_soft_acc: 0.5526\n",
      "Epoch 989/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4165 - soft_acc: 0.6932 - val_loss: 0.5708 - val_soft_acc: 0.5439\n",
      "Epoch 990/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4153 - soft_acc: 0.6998 - val_loss: 0.6184 - val_soft_acc: 0.5351\n",
      "Epoch 991/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4210 - soft_acc: 0.6843 - val_loss: 0.5873 - val_soft_acc: 0.5614\n",
      "Epoch 992/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 266us/step - loss: 0.4165 - soft_acc: 0.6799 - val_loss: 0.5594 - val_soft_acc: 0.5263\n",
      "Epoch 993/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4117 - soft_acc: 0.6932 - val_loss: 0.5553 - val_soft_acc: 0.5000\n",
      "Epoch 994/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4119 - soft_acc: 0.7064 - val_loss: 0.6005 - val_soft_acc: 0.5526\n",
      "Epoch 995/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4174 - soft_acc: 0.6865 - val_loss: 0.5582 - val_soft_acc: 0.5439\n",
      "Epoch 996/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4135 - soft_acc: 0.6998 - val_loss: 0.5992 - val_soft_acc: 0.5526\n",
      "Epoch 997/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.4160 - soft_acc: 0.6865 - val_loss: 0.5614 - val_soft_acc: 0.5614\n",
      "Epoch 998/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.4126 - soft_acc: 0.6865 - val_loss: 0.5587 - val_soft_acc: 0.5263\n",
      "Epoch 999/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4163 - soft_acc: 0.6932 - val_loss: 0.5631 - val_soft_acc: 0.5702\n",
      "Epoch 1000/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4131 - soft_acc: 0.6887 - val_loss: 0.5611 - val_soft_acc: 0.5439\n",
      "Epoch 1001/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4110 - soft_acc: 0.6887 - val_loss: 0.5605 - val_soft_acc: 0.5263\n",
      "Epoch 1002/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4161 - soft_acc: 0.6998 - val_loss: 0.5538 - val_soft_acc: 0.5526\n",
      "Epoch 1003/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4116 - soft_acc: 0.6976 - val_loss: 0.5480 - val_soft_acc: 0.5439\n",
      "Epoch 1004/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4080 - soft_acc: 0.6976 - val_loss: 0.5830 - val_soft_acc: 0.5614\n",
      "Epoch 1005/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4110 - soft_acc: 0.6932 - val_loss: 0.5543 - val_soft_acc: 0.5175\n",
      "Epoch 1006/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4106 - soft_acc: 0.6998 - val_loss: 0.5519 - val_soft_acc: 0.5088\n",
      "Epoch 1007/2000\n",
      "453/453 [==============================] - 0s 264us/step - loss: 0.4149 - soft_acc: 0.7064 - val_loss: 0.5574 - val_soft_acc: 0.5263\n",
      "Epoch 1008/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.4142 - soft_acc: 0.6998 - val_loss: 0.5711 - val_soft_acc: 0.5526\n",
      "Epoch 1009/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.4141 - soft_acc: 0.7064 - val_loss: 0.5618 - val_soft_acc: 0.5000\n",
      "Epoch 1010/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4133 - soft_acc: 0.6998 - val_loss: 0.5594 - val_soft_acc: 0.5614\n",
      "Epoch 1011/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4121 - soft_acc: 0.6932 - val_loss: 0.5994 - val_soft_acc: 0.5702\n",
      "Epoch 1012/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.4122 - soft_acc: 0.7042 - val_loss: 0.5704 - val_soft_acc: 0.5526\n",
      "Epoch 1013/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4092 - soft_acc: 0.7196 - val_loss: 0.5871 - val_soft_acc: 0.5614\n",
      "Epoch 1014/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4112 - soft_acc: 0.7174 - val_loss: 0.6221 - val_soft_acc: 0.5439\n",
      "Epoch 1015/2000\n",
      "453/453 [==============================] - 0s 300us/step - loss: 0.4174 - soft_acc: 0.7020 - val_loss: 0.5995 - val_soft_acc: 0.5789\n",
      "Epoch 1016/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4149 - soft_acc: 0.6998 - val_loss: 0.5569 - val_soft_acc: 0.5526\n",
      "Epoch 1017/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.4092 - soft_acc: 0.7130 - val_loss: 0.5755 - val_soft_acc: 0.5526\n",
      "Epoch 1018/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4099 - soft_acc: 0.7086 - val_loss: 0.5885 - val_soft_acc: 0.5614\n",
      "Epoch 1019/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4127 - soft_acc: 0.7219 - val_loss: 0.5788 - val_soft_acc: 0.5175\n",
      "Epoch 1020/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4106 - soft_acc: 0.6976 - val_loss: 0.5522 - val_soft_acc: 0.5614\n",
      "Epoch 1021/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4112 - soft_acc: 0.6998 - val_loss: 0.5504 - val_soft_acc: 0.5263\n",
      "Epoch 1022/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4128 - soft_acc: 0.7108 - val_loss: 0.5878 - val_soft_acc: 0.5263\n",
      "Epoch 1023/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4128 - soft_acc: 0.6954 - val_loss: 0.6037 - val_soft_acc: 0.5702\n",
      "Epoch 1024/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4124 - soft_acc: 0.7042 - val_loss: 0.5679 - val_soft_acc: 0.5000\n",
      "Epoch 1025/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4107 - soft_acc: 0.6998 - val_loss: 0.5674 - val_soft_acc: 0.5088\n",
      "Epoch 1026/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4106 - soft_acc: 0.7064 - val_loss: 0.5584 - val_soft_acc: 0.5526\n",
      "Epoch 1027/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4093 - soft_acc: 0.7086 - val_loss: 0.5666 - val_soft_acc: 0.5526\n",
      "Epoch 1028/2000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.4102 - soft_acc: 0.7020 - val_loss: 0.5643 - val_soft_acc: 0.4737\n",
      "Epoch 1029/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4123 - soft_acc: 0.6976 - val_loss: 0.5694 - val_soft_acc: 0.5263\n",
      "Epoch 1030/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4072 - soft_acc: 0.6932 - val_loss: 0.5578 - val_soft_acc: 0.5351\n",
      "Epoch 1031/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4076 - soft_acc: 0.7042 - val_loss: 0.5551 - val_soft_acc: 0.5088\n",
      "Epoch 1032/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4091 - soft_acc: 0.6998 - val_loss: 0.5568 - val_soft_acc: 0.5614\n",
      "Epoch 1033/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4064 - soft_acc: 0.6887 - val_loss: 0.5506 - val_soft_acc: 0.5263\n",
      "Epoch 1034/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4067 - soft_acc: 0.7086 - val_loss: 0.5513 - val_soft_acc: 0.5351\n",
      "Epoch 1035/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4092 - soft_acc: 0.7130 - val_loss: 0.5940 - val_soft_acc: 0.5702\n",
      "Epoch 1036/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4097 - soft_acc: 0.7042 - val_loss: 0.5968 - val_soft_acc: 0.5614\n",
      "Epoch 1037/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4103 - soft_acc: 0.6998 - val_loss: 0.5595 - val_soft_acc: 0.5263\n",
      "Epoch 1038/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.4055 - soft_acc: 0.6998 - val_loss: 0.5555 - val_soft_acc: 0.5088\n",
      "Epoch 1039/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4107 - soft_acc: 0.6998 - val_loss: 0.5653 - val_soft_acc: 0.4825\n",
      "Epoch 1040/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4151 - soft_acc: 0.6976 - val_loss: 0.5602 - val_soft_acc: 0.5439\n",
      "Epoch 1041/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.4066 - soft_acc: 0.7042 - val_loss: 0.5478 - val_soft_acc: 0.5351\n",
      "Epoch 1042/2000\n",
      "453/453 [==============================] - 0s 284us/step - loss: 0.4064 - soft_acc: 0.6976 - val_loss: 0.5518 - val_soft_acc: 0.5263\n",
      "Epoch 1043/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4093 - soft_acc: 0.6998 - val_loss: 0.5501 - val_soft_acc: 0.5088\n",
      "Epoch 1044/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4088 - soft_acc: 0.7241 - val_loss: 0.5515 - val_soft_acc: 0.5175\n",
      "Epoch 1045/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4066 - soft_acc: 0.7086 - val_loss: 0.5483 - val_soft_acc: 0.5526\n",
      "Epoch 1046/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4091 - soft_acc: 0.7020 - val_loss: 0.5488 - val_soft_acc: 0.5088\n",
      "Epoch 1047/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 264us/step - loss: 0.4038 - soft_acc: 0.7042 - val_loss: 0.6070 - val_soft_acc: 0.4561\n",
      "Epoch 1048/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4217 - soft_acc: 0.6954 - val_loss: 0.5756 - val_soft_acc: 0.5351\n",
      "Epoch 1049/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.4049 - soft_acc: 0.6932 - val_loss: 0.5898 - val_soft_acc: 0.5351\n",
      "Epoch 1050/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4094 - soft_acc: 0.7086 - val_loss: 0.5767 - val_soft_acc: 0.5351\n",
      "Epoch 1051/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.4070 - soft_acc: 0.7042 - val_loss: 0.5712 - val_soft_acc: 0.5263\n",
      "Epoch 1052/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4060 - soft_acc: 0.7196 - val_loss: 0.5488 - val_soft_acc: 0.5263\n",
      "Epoch 1053/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4050 - soft_acc: 0.6954 - val_loss: 0.5697 - val_soft_acc: 0.5351\n",
      "Epoch 1054/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.4054 - soft_acc: 0.7219 - val_loss: 0.5765 - val_soft_acc: 0.5439\n",
      "Epoch 1055/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4066 - soft_acc: 0.7020 - val_loss: 0.5600 - val_soft_acc: 0.5000\n",
      "Epoch 1056/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.4123 - soft_acc: 0.7152 - val_loss: 0.5480 - val_soft_acc: 0.5439\n",
      "Epoch 1057/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4073 - soft_acc: 0.7042 - val_loss: 0.5497 - val_soft_acc: 0.5351\n",
      "Epoch 1058/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4014 - soft_acc: 0.7064 - val_loss: 0.5585 - val_soft_acc: 0.4825\n",
      "Epoch 1059/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4070 - soft_acc: 0.7020 - val_loss: 0.5532 - val_soft_acc: 0.5263\n",
      "Epoch 1060/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4041 - soft_acc: 0.6954 - val_loss: 0.5496 - val_soft_acc: 0.5702\n",
      "Epoch 1061/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4051 - soft_acc: 0.7064 - val_loss: 0.5653 - val_soft_acc: 0.5439\n",
      "Epoch 1062/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4047 - soft_acc: 0.7130 - val_loss: 0.5468 - val_soft_acc: 0.5439\n",
      "Epoch 1063/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4059 - soft_acc: 0.7130 - val_loss: 0.5523 - val_soft_acc: 0.5526\n",
      "Epoch 1064/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4079 - soft_acc: 0.7108 - val_loss: 0.5510 - val_soft_acc: 0.5263\n",
      "Epoch 1065/2000\n",
      "453/453 [==============================] - 0s 302us/step - loss: 0.4070 - soft_acc: 0.7108 - val_loss: 0.5886 - val_soft_acc: 0.5789\n",
      "Epoch 1066/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4086 - soft_acc: 0.6998 - val_loss: 0.5677 - val_soft_acc: 0.5526\n",
      "Epoch 1067/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4062 - soft_acc: 0.7042 - val_loss: 0.5547 - val_soft_acc: 0.5263\n",
      "Epoch 1068/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.4052 - soft_acc: 0.7042 - val_loss: 0.5497 - val_soft_acc: 0.5351\n",
      "Epoch 1069/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.4033 - soft_acc: 0.7174 - val_loss: 0.5543 - val_soft_acc: 0.5702\n",
      "Epoch 1070/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.4036 - soft_acc: 0.7064 - val_loss: 0.5620 - val_soft_acc: 0.5351\n",
      "Epoch 1071/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4039 - soft_acc: 0.7042 - val_loss: 0.5702 - val_soft_acc: 0.5614\n",
      "Epoch 1072/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4006 - soft_acc: 0.7219 - val_loss: 0.5583 - val_soft_acc: 0.5175\n",
      "Epoch 1073/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4109 - soft_acc: 0.7042 - val_loss: 0.5496 - val_soft_acc: 0.5614\n",
      "Epoch 1074/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4034 - soft_acc: 0.6932 - val_loss: 0.5544 - val_soft_acc: 0.5526\n",
      "Epoch 1075/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4050 - soft_acc: 0.6954 - val_loss: 0.5626 - val_soft_acc: 0.5088\n",
      "Epoch 1076/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4012 - soft_acc: 0.7196 - val_loss: 0.5499 - val_soft_acc: 0.5439\n",
      "Epoch 1077/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4063 - soft_acc: 0.7152 - val_loss: 0.5820 - val_soft_acc: 0.5526\n",
      "Epoch 1078/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4042 - soft_acc: 0.7108 - val_loss: 0.5502 - val_soft_acc: 0.5439\n",
      "Epoch 1079/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.4014 - soft_acc: 0.7152 - val_loss: 0.5592 - val_soft_acc: 0.5351\n",
      "Epoch 1080/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4018 - soft_acc: 0.7130 - val_loss: 0.5505 - val_soft_acc: 0.5439\n",
      "Epoch 1081/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4043 - soft_acc: 0.7064 - val_loss: 0.5453 - val_soft_acc: 0.5351\n",
      "Epoch 1082/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4041 - soft_acc: 0.7241 - val_loss: 0.5845 - val_soft_acc: 0.5526\n",
      "Epoch 1083/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4036 - soft_acc: 0.7086 - val_loss: 0.5503 - val_soft_acc: 0.5789\n",
      "Epoch 1084/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4023 - soft_acc: 0.6998 - val_loss: 0.5467 - val_soft_acc: 0.5263\n",
      "Epoch 1085/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.4042 - soft_acc: 0.7064 - val_loss: 0.5674 - val_soft_acc: 0.5526\n",
      "Epoch 1086/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4035 - soft_acc: 0.7285 - val_loss: 0.5817 - val_soft_acc: 0.5702\n",
      "Epoch 1087/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4032 - soft_acc: 0.7064 - val_loss: 0.5864 - val_soft_acc: 0.5526\n",
      "Epoch 1088/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.3996 - soft_acc: 0.7064 - val_loss: 0.5613 - val_soft_acc: 0.5263\n",
      "Epoch 1089/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4018 - soft_acc: 0.7086 - val_loss: 0.5582 - val_soft_acc: 0.5439\n",
      "Epoch 1090/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.4047 - soft_acc: 0.7064 - val_loss: 0.5768 - val_soft_acc: 0.5439\n",
      "Epoch 1091/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4018 - soft_acc: 0.7196 - val_loss: 0.5720 - val_soft_acc: 0.5526\n",
      "Epoch 1092/2000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.4020 - soft_acc: 0.7042 - val_loss: 0.5533 - val_soft_acc: 0.5175\n",
      "Epoch 1093/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4053 - soft_acc: 0.7064 - val_loss: 0.5528 - val_soft_acc: 0.5351\n",
      "Epoch 1094/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.4014 - soft_acc: 0.7042 - val_loss: 0.5702 - val_soft_acc: 0.5351\n",
      "Epoch 1095/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4054 - soft_acc: 0.7020 - val_loss: 0.5835 - val_soft_acc: 0.5000\n",
      "Epoch 1096/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.4105 - soft_acc: 0.6932 - val_loss: 0.5638 - val_soft_acc: 0.4912\n",
      "Epoch 1097/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4045 - soft_acc: 0.7130 - val_loss: 0.5525 - val_soft_acc: 0.5175\n",
      "Epoch 1098/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4010 - soft_acc: 0.7174 - val_loss: 0.6123 - val_soft_acc: 0.5702\n",
      "Epoch 1099/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4042 - soft_acc: 0.7086 - val_loss: 0.5561 - val_soft_acc: 0.5175\n",
      "Epoch 1100/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4018 - soft_acc: 0.7020 - val_loss: 0.5728 - val_soft_acc: 0.5526\n",
      "Epoch 1101/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4011 - soft_acc: 0.7130 - val_loss: 0.5654 - val_soft_acc: 0.5088\n",
      "Epoch 1102/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 271us/step - loss: 0.4001 - soft_acc: 0.7042 - val_loss: 0.5568 - val_soft_acc: 0.5175\n",
      "Epoch 1103/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.4017 - soft_acc: 0.7108 - val_loss: 0.5427 - val_soft_acc: 0.5263\n",
      "Epoch 1104/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.4034 - soft_acc: 0.7042 - val_loss: 0.5433 - val_soft_acc: 0.5439\n",
      "Epoch 1105/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4001 - soft_acc: 0.7086 - val_loss: 0.5727 - val_soft_acc: 0.5526\n",
      "Epoch 1106/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4021 - soft_acc: 0.7108 - val_loss: 0.5734 - val_soft_acc: 0.5439\n",
      "Epoch 1107/2000\n",
      "453/453 [==============================] - 0s 264us/step - loss: 0.3995 - soft_acc: 0.7152 - val_loss: 0.5615 - val_soft_acc: 0.5351\n",
      "Epoch 1108/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.3982 - soft_acc: 0.7108 - val_loss: 0.5447 - val_soft_acc: 0.5351\n",
      "Epoch 1109/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.3989 - soft_acc: 0.7174 - val_loss: 0.5526 - val_soft_acc: 0.5088\n",
      "Epoch 1110/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4021 - soft_acc: 0.7196 - val_loss: 0.5713 - val_soft_acc: 0.5526\n",
      "Epoch 1111/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.3999 - soft_acc: 0.7108 - val_loss: 0.6320 - val_soft_acc: 0.5702\n",
      "Epoch 1112/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.4072 - soft_acc: 0.7108 - val_loss: 0.5530 - val_soft_acc: 0.5000\n",
      "Epoch 1113/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.4019 - soft_acc: 0.7086 - val_loss: 0.5674 - val_soft_acc: 0.5000\n",
      "Epoch 1114/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.4048 - soft_acc: 0.7042 - val_loss: 0.5708 - val_soft_acc: 0.5000\n",
      "Epoch 1115/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4077 - soft_acc: 0.7108 - val_loss: 0.5490 - val_soft_acc: 0.5351\n",
      "Epoch 1116/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4042 - soft_acc: 0.7152 - val_loss: 0.5688 - val_soft_acc: 0.5439\n",
      "Epoch 1117/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4011 - soft_acc: 0.7196 - val_loss: 0.5626 - val_soft_acc: 0.5614\n",
      "Epoch 1118/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.4009 - soft_acc: 0.7152 - val_loss: 0.5583 - val_soft_acc: 0.4912\n",
      "Epoch 1119/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4069 - soft_acc: 0.7020 - val_loss: 0.5422 - val_soft_acc: 0.5175\n",
      "Epoch 1120/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.3960 - soft_acc: 0.7174 - val_loss: 0.5449 - val_soft_acc: 0.5175\n",
      "Epoch 1121/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.4012 - soft_acc: 0.7174 - val_loss: 0.5500 - val_soft_acc: 0.5088\n",
      "Epoch 1122/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.4001 - soft_acc: 0.7152 - val_loss: 0.5701 - val_soft_acc: 0.5439\n",
      "Epoch 1123/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.3999 - soft_acc: 0.7108 - val_loss: 0.5602 - val_soft_acc: 0.5526\n",
      "Epoch 1124/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.3994 - soft_acc: 0.7086 - val_loss: 0.5611 - val_soft_acc: 0.5351\n",
      "Epoch 1125/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.3981 - soft_acc: 0.6976 - val_loss: 0.5586 - val_soft_acc: 0.5351\n",
      "Epoch 1126/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3969 - soft_acc: 0.7108 - val_loss: 0.5423 - val_soft_acc: 0.5351\n",
      "Epoch 1127/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3980 - soft_acc: 0.7130 - val_loss: 0.5433 - val_soft_acc: 0.5351\n",
      "Epoch 1128/2000\n",
      "453/453 [==============================] - 0s 264us/step - loss: 0.3989 - soft_acc: 0.7108 - val_loss: 0.5475 - val_soft_acc: 0.5263\n",
      "Epoch 1129/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.3988 - soft_acc: 0.7219 - val_loss: 0.5435 - val_soft_acc: 0.5614\n",
      "Epoch 1130/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3975 - soft_acc: 0.7020 - val_loss: 0.5372 - val_soft_acc: 0.5351\n",
      "Epoch 1131/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4005 - soft_acc: 0.7064 - val_loss: 0.5423 - val_soft_acc: 0.5263\n",
      "Epoch 1132/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.3970 - soft_acc: 0.7064 - val_loss: 0.5510 - val_soft_acc: 0.5175\n",
      "Epoch 1133/2000\n",
      "453/453 [==============================] - 0s 293us/step - loss: 0.3970 - soft_acc: 0.7020 - val_loss: 0.5929 - val_soft_acc: 0.5877\n",
      "Epoch 1134/2000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.4000 - soft_acc: 0.7108 - val_loss: 0.5519 - val_soft_acc: 0.5175\n",
      "Epoch 1135/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.4024 - soft_acc: 0.7020 - val_loss: 0.5715 - val_soft_acc: 0.5526\n",
      "Epoch 1136/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3979 - soft_acc: 0.7086 - val_loss: 0.5467 - val_soft_acc: 0.5175\n",
      "Epoch 1137/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.3990 - soft_acc: 0.7020 - val_loss: 0.5730 - val_soft_acc: 0.5526\n",
      "Epoch 1138/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.4011 - soft_acc: 0.7042 - val_loss: 0.5432 - val_soft_acc: 0.5351\n",
      "Epoch 1139/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.3997 - soft_acc: 0.7086 - val_loss: 0.5621 - val_soft_acc: 0.5439\n",
      "Epoch 1140/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.3959 - soft_acc: 0.7086 - val_loss: 0.5437 - val_soft_acc: 0.5439\n",
      "Epoch 1141/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3953 - soft_acc: 0.7042 - val_loss: 0.6203 - val_soft_acc: 0.5702\n",
      "Epoch 1142/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4083 - soft_acc: 0.6998 - val_loss: 0.5447 - val_soft_acc: 0.5263\n",
      "Epoch 1143/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.3963 - soft_acc: 0.7196 - val_loss: 0.5414 - val_soft_acc: 0.5263\n",
      "Epoch 1144/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.3953 - soft_acc: 0.7241 - val_loss: 0.5532 - val_soft_acc: 0.5175\n",
      "Epoch 1145/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.3946 - soft_acc: 0.7196 - val_loss: 0.5976 - val_soft_acc: 0.5614\n",
      "Epoch 1146/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.4004 - soft_acc: 0.6976 - val_loss: 0.5447 - val_soft_acc: 0.5439\n",
      "Epoch 1147/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.3965 - soft_acc: 0.7130 - val_loss: 0.5841 - val_soft_acc: 0.5526\n",
      "Epoch 1148/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.4008 - soft_acc: 0.7086 - val_loss: 0.5630 - val_soft_acc: 0.4649\n",
      "Epoch 1149/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.4055 - soft_acc: 0.6976 - val_loss: 0.5524 - val_soft_acc: 0.5439\n",
      "Epoch 1150/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.3955 - soft_acc: 0.7152 - val_loss: 0.5456 - val_soft_acc: 0.5439\n",
      "Epoch 1151/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.3940 - soft_acc: 0.7329 - val_loss: 0.5627 - val_soft_acc: 0.5351\n",
      "Epoch 1152/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.3983 - soft_acc: 0.7307 - val_loss: 0.5442 - val_soft_acc: 0.5351\n",
      "Epoch 1153/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.3925 - soft_acc: 0.7130 - val_loss: 0.5703 - val_soft_acc: 0.5351\n",
      "Epoch 1154/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.3948 - soft_acc: 0.7086 - val_loss: 0.6040 - val_soft_acc: 0.5789\n",
      "Epoch 1155/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.3957 - soft_acc: 0.7130 - val_loss: 0.5895 - val_soft_acc: 0.5702\n",
      "Epoch 1156/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3968 - soft_acc: 0.7174 - val_loss: 0.5562 - val_soft_acc: 0.4912\n",
      "Epoch 1157/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 270us/step - loss: 0.4002 - soft_acc: 0.7174 - val_loss: 0.5398 - val_soft_acc: 0.5351\n",
      "Epoch 1158/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.3947 - soft_acc: 0.7174 - val_loss: 0.5404 - val_soft_acc: 0.5351\n",
      "Epoch 1159/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.3945 - soft_acc: 0.7108 - val_loss: 0.5418 - val_soft_acc: 0.5351\n",
      "Epoch 1160/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.3929 - soft_acc: 0.7130 - val_loss: 0.5496 - val_soft_acc: 0.5263\n",
      "Epoch 1161/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.3933 - soft_acc: 0.7130 - val_loss: 0.5779 - val_soft_acc: 0.5614\n",
      "Epoch 1162/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.3957 - soft_acc: 0.7020 - val_loss: 0.5460 - val_soft_acc: 0.5351\n",
      "Epoch 1163/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.3933 - soft_acc: 0.7108 - val_loss: 0.5846 - val_soft_acc: 0.5351\n",
      "Epoch 1164/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.3972 - soft_acc: 0.7152 - val_loss: 0.5450 - val_soft_acc: 0.5088\n",
      "Epoch 1165/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.3948 - soft_acc: 0.7086 - val_loss: 0.5428 - val_soft_acc: 0.5175\n",
      "Epoch 1166/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.3968 - soft_acc: 0.7351 - val_loss: 0.5396 - val_soft_acc: 0.5175\n",
      "Epoch 1167/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.3989 - soft_acc: 0.6998 - val_loss: 0.5620 - val_soft_acc: 0.5263\n",
      "Epoch 1168/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.3954 - soft_acc: 0.7241 - val_loss: 0.5620 - val_soft_acc: 0.5439\n",
      "Epoch 1169/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.3927 - soft_acc: 0.7174 - val_loss: 0.5419 - val_soft_acc: 0.5526\n",
      "Epoch 1170/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4001 - soft_acc: 0.7108 - val_loss: 0.5426 - val_soft_acc: 0.5263\n",
      "Epoch 1171/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.3964 - soft_acc: 0.7152 - val_loss: 0.5614 - val_soft_acc: 0.5614\n",
      "Epoch 1172/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.3938 - soft_acc: 0.7263 - val_loss: 0.6050 - val_soft_acc: 0.5702\n",
      "Epoch 1173/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.3984 - soft_acc: 0.7196 - val_loss: 0.5570 - val_soft_acc: 0.5000\n",
      "Epoch 1174/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3986 - soft_acc: 0.6954 - val_loss: 0.5371 - val_soft_acc: 0.5351\n",
      "Epoch 1175/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.3936 - soft_acc: 0.7241 - val_loss: 0.5346 - val_soft_acc: 0.5263\n",
      "Epoch 1176/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.3942 - soft_acc: 0.7174 - val_loss: 0.5351 - val_soft_acc: 0.5439\n",
      "Epoch 1177/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.3918 - soft_acc: 0.6998 - val_loss: 0.5480 - val_soft_acc: 0.5614\n",
      "Epoch 1178/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4022 - soft_acc: 0.7042 - val_loss: 0.5581 - val_soft_acc: 0.5263\n",
      "Epoch 1179/2000\n",
      "453/453 [==============================] - 0s 301us/step - loss: 0.3961 - soft_acc: 0.7042 - val_loss: 0.5400 - val_soft_acc: 0.5439\n",
      "Epoch 1180/2000\n",
      "453/453 [==============================] - 0s 336us/step - loss: 0.3894 - soft_acc: 0.7196 - val_loss: 0.5493 - val_soft_acc: 0.5088\n",
      "Epoch 1181/2000\n",
      "453/453 [==============================] - 0s 297us/step - loss: 0.3941 - soft_acc: 0.7108 - val_loss: 0.5457 - val_soft_acc: 0.5263\n",
      "Epoch 1182/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.3959 - soft_acc: 0.7196 - val_loss: 0.5438 - val_soft_acc: 0.5263\n",
      "Epoch 1183/2000\n",
      "453/453 [==============================] - 0s 288us/step - loss: 0.3934 - soft_acc: 0.7241 - val_loss: 0.5424 - val_soft_acc: 0.5263\n",
      "Epoch 1184/2000\n",
      "453/453 [==============================] - 0s 306us/step - loss: 0.3918 - soft_acc: 0.7152 - val_loss: 0.5476 - val_soft_acc: 0.5351\n",
      "Epoch 1185/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.3908 - soft_acc: 0.7108 - val_loss: 0.5713 - val_soft_acc: 0.5789\n",
      "Epoch 1186/2000\n",
      "453/453 [==============================] - 0s 293us/step - loss: 0.3973 - soft_acc: 0.7086 - val_loss: 0.5457 - val_soft_acc: 0.5175\n",
      "Epoch 1187/2000\n",
      "453/453 [==============================] - 0s 301us/step - loss: 0.3915 - soft_acc: 0.7174 - val_loss: 0.5507 - val_soft_acc: 0.5175\n",
      "Epoch 1188/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.3956 - soft_acc: 0.7152 - val_loss: 0.5563 - val_soft_acc: 0.5351\n",
      "Epoch 1189/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3923 - soft_acc: 0.7152 - val_loss: 0.5415 - val_soft_acc: 0.5351\n",
      "Epoch 1190/2000\n",
      "453/453 [==============================] - 0s 284us/step - loss: 0.3884 - soft_acc: 0.7219 - val_loss: 0.5566 - val_soft_acc: 0.5175\n",
      "Epoch 1191/2000\n",
      "453/453 [==============================] - 0s 321us/step - loss: 0.3924 - soft_acc: 0.7263 - val_loss: 0.5369 - val_soft_acc: 0.5439\n",
      "Epoch 1192/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.3930 - soft_acc: 0.7196 - val_loss: 0.5382 - val_soft_acc: 0.5351\n",
      "Epoch 1193/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.3926 - soft_acc: 0.7174 - val_loss: 0.5584 - val_soft_acc: 0.5702\n",
      "Epoch 1194/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3897 - soft_acc: 0.7064 - val_loss: 0.5483 - val_soft_acc: 0.5000\n",
      "Epoch 1195/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.3963 - soft_acc: 0.7152 - val_loss: 0.5406 - val_soft_acc: 0.5351\n",
      "Epoch 1196/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.3926 - soft_acc: 0.7219 - val_loss: 0.5595 - val_soft_acc: 0.5702\n",
      "Epoch 1197/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3922 - soft_acc: 0.7108 - val_loss: 0.5521 - val_soft_acc: 0.5263\n",
      "Epoch 1198/2000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.3923 - soft_acc: 0.7196 - val_loss: 0.5346 - val_soft_acc: 0.5351\n",
      "Epoch 1199/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.3903 - soft_acc: 0.7219 - val_loss: 0.5606 - val_soft_acc: 0.5088\n",
      "Epoch 1200/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.4024 - soft_acc: 0.7241 - val_loss: 0.5461 - val_soft_acc: 0.5263\n",
      "Epoch 1201/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3930 - soft_acc: 0.7241 - val_loss: 0.5578 - val_soft_acc: 0.5614\n",
      "Epoch 1202/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.3906 - soft_acc: 0.7108 - val_loss: 0.5339 - val_soft_acc: 0.5263\n",
      "Epoch 1203/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.3919 - soft_acc: 0.7307 - val_loss: 0.5423 - val_soft_acc: 0.5175\n",
      "Epoch 1204/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.3978 - soft_acc: 0.7174 - val_loss: 0.5368 - val_soft_acc: 0.5263\n",
      "Epoch 1205/2000\n",
      "453/453 [==============================] - 0s 293us/step - loss: 0.3871 - soft_acc: 0.7152 - val_loss: 0.5524 - val_soft_acc: 0.5351\n",
      "Epoch 1206/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.3901 - soft_acc: 0.7219 - val_loss: 0.5352 - val_soft_acc: 0.5351\n",
      "Epoch 1207/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.3926 - soft_acc: 0.7329 - val_loss: 0.5337 - val_soft_acc: 0.5439\n",
      "Epoch 1208/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.3911 - soft_acc: 0.7219 - val_loss: 0.5624 - val_soft_acc: 0.5789\n",
      "Epoch 1209/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3927 - soft_acc: 0.7196 - val_loss: 0.5408 - val_soft_acc: 0.5351\n",
      "Epoch 1210/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.3880 - soft_acc: 0.7241 - val_loss: 0.5322 - val_soft_acc: 0.5439\n",
      "Epoch 1211/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3912 - soft_acc: 0.7241 - val_loss: 0.5326 - val_soft_acc: 0.5439\n",
      "Epoch 1212/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 298us/step - loss: 0.3912 - soft_acc: 0.7196 - val_loss: 0.5408 - val_soft_acc: 0.5263\n",
      "Epoch 1213/2000\n",
      "453/453 [==============================] - 0s 297us/step - loss: 0.3908 - soft_acc: 0.7241 - val_loss: 0.5349 - val_soft_acc: 0.5175\n",
      "Epoch 1214/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.3912 - soft_acc: 0.7219 - val_loss: 0.5559 - val_soft_acc: 0.5439\n",
      "Epoch 1215/2000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.3928 - soft_acc: 0.7329 - val_loss: 0.5549 - val_soft_acc: 0.5526\n",
      "Epoch 1216/2000\n",
      "453/453 [==============================] - 0s 334us/step - loss: 0.3894 - soft_acc: 0.7152 - val_loss: 0.5367 - val_soft_acc: 0.5263\n",
      "Epoch 1217/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.3893 - soft_acc: 0.7108 - val_loss: 0.5339 - val_soft_acc: 0.5263\n",
      "Epoch 1218/2000\n",
      "453/453 [==============================] - 0s 305us/step - loss: 0.3924 - soft_acc: 0.7152 - val_loss: 0.5354 - val_soft_acc: 0.5263\n",
      "Epoch 1219/2000\n",
      "453/453 [==============================] - 0s 298us/step - loss: 0.3905 - soft_acc: 0.7086 - val_loss: 0.5303 - val_soft_acc: 0.5351\n",
      "Epoch 1220/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.3900 - soft_acc: 0.7219 - val_loss: 0.5501 - val_soft_acc: 0.5439\n",
      "Epoch 1221/2000\n",
      "453/453 [==============================] - 0s 285us/step - loss: 0.3867 - soft_acc: 0.7241 - val_loss: 0.5326 - val_soft_acc: 0.5439\n",
      "Epoch 1222/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.3906 - soft_acc: 0.7263 - val_loss: 0.5326 - val_soft_acc: 0.5351\n",
      "Epoch 1223/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.3866 - soft_acc: 0.7219 - val_loss: 0.5525 - val_soft_acc: 0.5263\n",
      "Epoch 1224/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.3915 - soft_acc: 0.7263 - val_loss: 0.5380 - val_soft_acc: 0.5351\n",
      "Epoch 1225/2000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.3912 - soft_acc: 0.7219 - val_loss: 0.5608 - val_soft_acc: 0.5614\n",
      "Epoch 1226/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.3898 - soft_acc: 0.7285 - val_loss: 0.5417 - val_soft_acc: 0.5175\n",
      "Epoch 1227/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.3908 - soft_acc: 0.7152 - val_loss: 0.5446 - val_soft_acc: 0.5351\n",
      "Epoch 1228/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.3892 - soft_acc: 0.7152 - val_loss: 0.5334 - val_soft_acc: 0.5614\n",
      "Epoch 1229/2000\n",
      "453/453 [==============================] - 0s 287us/step - loss: 0.3889 - soft_acc: 0.7152 - val_loss: 0.5263 - val_soft_acc: 0.5526\n",
      "Epoch 1230/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.3915 - soft_acc: 0.7064 - val_loss: 0.5306 - val_soft_acc: 0.5351\n",
      "Epoch 1231/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.3913 - soft_acc: 0.7152 - val_loss: 0.5485 - val_soft_acc: 0.5000\n",
      "Epoch 1232/2000\n",
      "453/453 [==============================] - 0s 285us/step - loss: 0.3947 - soft_acc: 0.7174 - val_loss: 0.5378 - val_soft_acc: 0.5526\n",
      "Epoch 1233/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.3885 - soft_acc: 0.7241 - val_loss: 0.5642 - val_soft_acc: 0.5526\n",
      "Epoch 1234/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3865 - soft_acc: 0.7219 - val_loss: 0.5320 - val_soft_acc: 0.5526\n",
      "Epoch 1235/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.3871 - soft_acc: 0.7130 - val_loss: 0.5669 - val_soft_acc: 0.5702\n",
      "Epoch 1236/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.3932 - soft_acc: 0.7219 - val_loss: 0.5504 - val_soft_acc: 0.5263\n",
      "Epoch 1237/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.3914 - soft_acc: 0.7130 - val_loss: 0.5664 - val_soft_acc: 0.5439\n",
      "Epoch 1238/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.3876 - soft_acc: 0.7196 - val_loss: 0.5408 - val_soft_acc: 0.5263\n",
      "Epoch 1239/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.3881 - soft_acc: 0.7219 - val_loss: 0.5710 - val_soft_acc: 0.5526\n",
      "Epoch 1240/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.3863 - soft_acc: 0.7108 - val_loss: 0.5402 - val_soft_acc: 0.5614\n",
      "Epoch 1241/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.3889 - soft_acc: 0.7086 - val_loss: 0.5552 - val_soft_acc: 0.5526\n",
      "Epoch 1242/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.3915 - soft_acc: 0.6998 - val_loss: 0.5510 - val_soft_acc: 0.5526\n",
      "Epoch 1243/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.3888 - soft_acc: 0.7152 - val_loss: 0.5461 - val_soft_acc: 0.5614\n",
      "Epoch 1244/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.3855 - soft_acc: 0.7196 - val_loss: 0.5402 - val_soft_acc: 0.5526\n",
      "Epoch 1245/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3908 - soft_acc: 0.7108 - val_loss: 0.5492 - val_soft_acc: 0.5702\n",
      "Epoch 1246/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.3896 - soft_acc: 0.7263 - val_loss: 0.5382 - val_soft_acc: 0.5439\n",
      "Epoch 1247/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3864 - soft_acc: 0.7196 - val_loss: 0.5302 - val_soft_acc: 0.5175\n",
      "Epoch 1248/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.3859 - soft_acc: 0.7152 - val_loss: 0.5320 - val_soft_acc: 0.5351\n",
      "Epoch 1249/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.3870 - soft_acc: 0.7351 - val_loss: 0.5306 - val_soft_acc: 0.5263\n",
      "Epoch 1250/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.3922 - soft_acc: 0.7130 - val_loss: 0.5352 - val_soft_acc: 0.5351\n",
      "Epoch 1251/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.3891 - soft_acc: 0.7130 - val_loss: 0.5418 - val_soft_acc: 0.5351\n",
      "Epoch 1252/2000\n",
      "453/453 [==============================] - 0s 290us/step - loss: 0.3844 - soft_acc: 0.7130 - val_loss: 0.5686 - val_soft_acc: 0.5789\n",
      "Epoch 1253/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.3887 - soft_acc: 0.7130 - val_loss: 0.5736 - val_soft_acc: 0.5789\n",
      "Epoch 1254/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3886 - soft_acc: 0.7263 - val_loss: 0.5417 - val_soft_acc: 0.5263\n",
      "Epoch 1255/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.3885 - soft_acc: 0.7241 - val_loss: 0.5505 - val_soft_acc: 0.5614\n",
      "Epoch 1256/2000\n",
      "453/453 [==============================] - 0s 285us/step - loss: 0.3868 - soft_acc: 0.7285 - val_loss: 0.5402 - val_soft_acc: 0.5351\n",
      "Epoch 1257/2000\n",
      "453/453 [==============================] - 0s 294us/step - loss: 0.3879 - soft_acc: 0.7130 - val_loss: 0.5916 - val_soft_acc: 0.5526\n",
      "Epoch 1258/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.3899 - soft_acc: 0.7152 - val_loss: 0.5298 - val_soft_acc: 0.5351\n",
      "Epoch 1259/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.3885 - soft_acc: 0.7152 - val_loss: 0.5349 - val_soft_acc: 0.5439\n",
      "Epoch 1260/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3857 - soft_acc: 0.7307 - val_loss: 0.5455 - val_soft_acc: 0.5351\n",
      "Epoch 1261/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.3862 - soft_acc: 0.7329 - val_loss: 0.5626 - val_soft_acc: 0.4825\n",
      "Epoch 1262/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.3952 - soft_acc: 0.7263 - val_loss: 0.5337 - val_soft_acc: 0.5351\n",
      "Epoch 1263/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.3857 - soft_acc: 0.7130 - val_loss: 0.5377 - val_soft_acc: 0.5439\n",
      "Epoch 1264/2000\n",
      "453/453 [==============================] - 0s 289us/step - loss: 0.3825 - soft_acc: 0.7152 - val_loss: 0.5774 - val_soft_acc: 0.4912\n",
      "Epoch 1265/2000\n",
      "453/453 [==============================] - 0s 287us/step - loss: 0.3956 - soft_acc: 0.7130 - val_loss: 0.5519 - val_soft_acc: 0.5263\n",
      "Epoch 1266/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.3879 - soft_acc: 0.7373 - val_loss: 0.5351 - val_soft_acc: 0.5263\n",
      "Epoch 1267/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 270us/step - loss: 0.3881 - soft_acc: 0.7196 - val_loss: 0.5332 - val_soft_acc: 0.5263\n",
      "Epoch 1268/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.3846 - soft_acc: 0.7241 - val_loss: 0.5521 - val_soft_acc: 0.5088\n",
      "Epoch 1269/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.3900 - soft_acc: 0.7174 - val_loss: 0.5315 - val_soft_acc: 0.5439\n",
      "Epoch 1270/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.3866 - soft_acc: 0.7329 - val_loss: 0.5344 - val_soft_acc: 0.5439\n",
      "Epoch 1271/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.3815 - soft_acc: 0.7219 - val_loss: 0.5553 - val_soft_acc: 0.5088\n",
      "Epoch 1272/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.3974 - soft_acc: 0.7020 - val_loss: 0.5383 - val_soft_acc: 0.5175\n",
      "Epoch 1273/2000\n",
      "453/453 [==============================] - 0s 288us/step - loss: 0.3848 - soft_acc: 0.7130 - val_loss: 0.5502 - val_soft_acc: 0.5702\n",
      "Epoch 1274/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.3849 - soft_acc: 0.7020 - val_loss: 0.5435 - val_soft_acc: 0.5351\n",
      "Epoch 1275/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.3905 - soft_acc: 0.7241 - val_loss: 0.5329 - val_soft_acc: 0.5175\n",
      "Epoch 1276/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.3815 - soft_acc: 0.7219 - val_loss: 0.5330 - val_soft_acc: 0.5175\n",
      "Epoch 1277/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.3831 - soft_acc: 0.7395 - val_loss: 0.5327 - val_soft_acc: 0.5175\n",
      "Epoch 1278/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.3856 - soft_acc: 0.7351 - val_loss: 0.5521 - val_soft_acc: 0.5439\n",
      "Epoch 1279/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.3865 - soft_acc: 0.7196 - val_loss: 0.5377 - val_soft_acc: 0.5614\n",
      "Epoch 1280/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.3836 - soft_acc: 0.7219 - val_loss: 0.5736 - val_soft_acc: 0.5789\n",
      "Epoch 1281/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.3896 - soft_acc: 0.7152 - val_loss: 0.5510 - val_soft_acc: 0.5702\n",
      "Epoch 1282/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.3833 - soft_acc: 0.7307 - val_loss: 0.5494 - val_soft_acc: 0.5526\n",
      "Epoch 1283/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.3845 - soft_acc: 0.7174 - val_loss: 0.5349 - val_soft_acc: 0.5439\n",
      "Epoch 1284/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.3843 - soft_acc: 0.7130 - val_loss: 0.5502 - val_soft_acc: 0.5614\n",
      "Epoch 1285/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3852 - soft_acc: 0.7241 - val_loss: 0.5311 - val_soft_acc: 0.5614\n",
      "Epoch 1286/2000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.3828 - soft_acc: 0.7196 - val_loss: 0.5367 - val_soft_acc: 0.5175\n",
      "Epoch 1287/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.3905 - soft_acc: 0.7020 - val_loss: 0.5415 - val_soft_acc: 0.5702\n",
      "Epoch 1288/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.3829 - soft_acc: 0.7174 - val_loss: 0.5483 - val_soft_acc: 0.5702\n",
      "Epoch 1289/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.3836 - soft_acc: 0.7219 - val_loss: 0.5881 - val_soft_acc: 0.5526\n",
      "Epoch 1290/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.3881 - soft_acc: 0.7174 - val_loss: 0.5421 - val_soft_acc: 0.5614\n",
      "Epoch 1291/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.3815 - soft_acc: 0.7174 - val_loss: 0.5388 - val_soft_acc: 0.5263\n",
      "Epoch 1292/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.3854 - soft_acc: 0.7219 - val_loss: 0.5644 - val_soft_acc: 0.5000\n",
      "Epoch 1293/2000\n",
      "453/453 [==============================] - 0s 264us/step - loss: 0.3899 - soft_acc: 0.7196 - val_loss: 0.5511 - val_soft_acc: 0.5526\n",
      "Epoch 1294/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.3830 - soft_acc: 0.7130 - val_loss: 0.5391 - val_soft_acc: 0.5526\n",
      "Epoch 1295/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.3847 - soft_acc: 0.7241 - val_loss: 0.5854 - val_soft_acc: 0.5789\n",
      "Epoch 1296/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.3889 - soft_acc: 0.7219 - val_loss: 0.5595 - val_soft_acc: 0.4912\n",
      "Epoch 1297/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.3920 - soft_acc: 0.7351 - val_loss: 0.5383 - val_soft_acc: 0.5789\n",
      "Epoch 1298/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.3829 - soft_acc: 0.7196 - val_loss: 0.5479 - val_soft_acc: 0.5439\n",
      "Epoch 1299/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.3835 - soft_acc: 0.7152 - val_loss: 0.5359 - val_soft_acc: 0.5614\n",
      "Epoch 1300/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.3820 - soft_acc: 0.7219 - val_loss: 0.5350 - val_soft_acc: 0.5702\n",
      "Epoch 1301/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.3832 - soft_acc: 0.7307 - val_loss: 0.5291 - val_soft_acc: 0.5263\n",
      "Epoch 1302/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.3906 - soft_acc: 0.7307 - val_loss: 0.5349 - val_soft_acc: 0.5439\n",
      "Epoch 1303/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.3841 - soft_acc: 0.7219 - val_loss: 0.5306 - val_soft_acc: 0.5175\n",
      "Epoch 1304/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.3828 - soft_acc: 0.7219 - val_loss: 0.5456 - val_soft_acc: 0.5614\n",
      "Epoch 1305/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.3796 - soft_acc: 0.7307 - val_loss: 0.5421 - val_soft_acc: 0.5175\n",
      "Epoch 1306/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.3854 - soft_acc: 0.7329 - val_loss: 0.5356 - val_soft_acc: 0.5702\n",
      "Epoch 1307/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.3860 - soft_acc: 0.7108 - val_loss: 0.5698 - val_soft_acc: 0.5526\n",
      "Epoch 1308/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.3841 - soft_acc: 0.7285 - val_loss: 0.5410 - val_soft_acc: 0.5702\n",
      "Epoch 1309/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.3814 - soft_acc: 0.7263 - val_loss: 0.5674 - val_soft_acc: 0.5789\n",
      "Epoch 1310/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3830 - soft_acc: 0.7307 - val_loss: 0.5436 - val_soft_acc: 0.5351\n",
      "Epoch 1311/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.3803 - soft_acc: 0.7263 - val_loss: 0.5697 - val_soft_acc: 0.5614\n",
      "Epoch 1312/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.3806 - soft_acc: 0.7241 - val_loss: 0.5650 - val_soft_acc: 0.4737\n",
      "Epoch 1313/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3901 - soft_acc: 0.7329 - val_loss: 0.5654 - val_soft_acc: 0.5789\n",
      "Epoch 1314/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.3840 - soft_acc: 0.7263 - val_loss: 0.5585 - val_soft_acc: 0.5789\n",
      "Epoch 1315/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.3796 - soft_acc: 0.7174 - val_loss: 0.5545 - val_soft_acc: 0.5439\n",
      "Epoch 1316/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.3820 - soft_acc: 0.7174 - val_loss: 0.5362 - val_soft_acc: 0.5789\n",
      "Epoch 1317/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.3836 - soft_acc: 0.7130 - val_loss: 0.5512 - val_soft_acc: 0.5614\n",
      "Epoch 1318/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.3796 - soft_acc: 0.7219 - val_loss: 0.5409 - val_soft_acc: 0.5614\n",
      "Epoch 1319/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.3862 - soft_acc: 0.7196 - val_loss: 0.5460 - val_soft_acc: 0.5263\n",
      "Epoch 1320/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3841 - soft_acc: 0.7174 - val_loss: 0.6018 - val_soft_acc: 0.5526\n",
      "Epoch 1321/2000\n",
      "453/453 [==============================] - 0s 302us/step - loss: 0.3921 - soft_acc: 0.7064 - val_loss: 0.5856 - val_soft_acc: 0.5877\n",
      "Epoch 1322/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 269us/step - loss: 0.3842 - soft_acc: 0.7285 - val_loss: 0.5377 - val_soft_acc: 0.5614\n",
      "Epoch 1323/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.3795 - soft_acc: 0.7196 - val_loss: 0.5870 - val_soft_acc: 0.5614\n",
      "Epoch 1324/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.3845 - soft_acc: 0.7174 - val_loss: 0.5392 - val_soft_acc: 0.5614\n",
      "Epoch 1325/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.3812 - soft_acc: 0.7020 - val_loss: 0.5419 - val_soft_acc: 0.5263\n",
      "Epoch 1326/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.3830 - soft_acc: 0.7174 - val_loss: 0.5377 - val_soft_acc: 0.5263\n",
      "Epoch 1327/2000\n",
      "453/453 [==============================] - 0s 303us/step - loss: 0.3769 - soft_acc: 0.7285 - val_loss: 0.6347 - val_soft_acc: 0.5614\n",
      "Epoch 1328/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.3936 - soft_acc: 0.7241 - val_loss: 0.5296 - val_soft_acc: 0.5526\n",
      "Epoch 1329/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.3774 - soft_acc: 0.7152 - val_loss: 0.5444 - val_soft_acc: 0.5877\n",
      "Epoch 1330/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.3841 - soft_acc: 0.7174 - val_loss: 0.5295 - val_soft_acc: 0.5351\n",
      "Epoch 1331/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.3887 - soft_acc: 0.7373 - val_loss: 0.5361 - val_soft_acc: 0.5526\n",
      "Epoch 1332/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.3797 - soft_acc: 0.7174 - val_loss: 0.5335 - val_soft_acc: 0.5526\n",
      "Epoch 1333/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.3803 - soft_acc: 0.7263 - val_loss: 0.5353 - val_soft_acc: 0.5702\n",
      "Epoch 1334/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.3802 - soft_acc: 0.7196 - val_loss: 0.5332 - val_soft_acc: 0.5263\n",
      "Epoch 1335/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.3803 - soft_acc: 0.7329 - val_loss: 0.5891 - val_soft_acc: 0.5789\n",
      "Epoch 1336/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.3828 - soft_acc: 0.7241 - val_loss: 0.6602 - val_soft_acc: 0.5614\n",
      "Epoch 1337/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.3919 - soft_acc: 0.7196 - val_loss: 0.5727 - val_soft_acc: 0.5789\n",
      "Epoch 1338/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3883 - soft_acc: 0.7285 - val_loss: 0.5463 - val_soft_acc: 0.4737\n",
      "Epoch 1339/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.3834 - soft_acc: 0.7196 - val_loss: 0.5788 - val_soft_acc: 0.5614\n",
      "Epoch 1340/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.3801 - soft_acc: 0.7395 - val_loss: 0.5580 - val_soft_acc: 0.5526\n",
      "Epoch 1341/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.3828 - soft_acc: 0.7417 - val_loss: 0.5363 - val_soft_acc: 0.5439\n",
      "Epoch 1342/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.3788 - soft_acc: 0.7395 - val_loss: 0.5773 - val_soft_acc: 0.5789\n",
      "Epoch 1343/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.3807 - soft_acc: 0.7285 - val_loss: 0.5294 - val_soft_acc: 0.5088\n",
      "Epoch 1344/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.3798 - soft_acc: 0.7351 - val_loss: 0.5521 - val_soft_acc: 0.5439\n",
      "Epoch 1345/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.3773 - soft_acc: 0.7395 - val_loss: 0.5328 - val_soft_acc: 0.5263\n",
      "Epoch 1346/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.3782 - soft_acc: 0.7263 - val_loss: 0.5257 - val_soft_acc: 0.5175\n",
      "Epoch 1347/2000\n",
      "453/453 [==============================] - 0s 323us/step - loss: 0.3814 - soft_acc: 0.7152 - val_loss: 0.5458 - val_soft_acc: 0.5614\n",
      "Epoch 1348/2000\n",
      "453/453 [==============================] - 0s 321us/step - loss: 0.3808 - soft_acc: 0.7263 - val_loss: 0.5272 - val_soft_acc: 0.5439\n",
      "Epoch 1349/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.3814 - soft_acc: 0.7285 - val_loss: 0.5291 - val_soft_acc: 0.5526\n",
      "Epoch 1350/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.3761 - soft_acc: 0.7329 - val_loss: 0.5339 - val_soft_acc: 0.5351\n",
      "Epoch 1351/2000\n",
      "453/453 [==============================] - 0s 263us/step - loss: 0.3806 - soft_acc: 0.7108 - val_loss: 0.5423 - val_soft_acc: 0.5439\n",
      "Epoch 1352/2000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.3838 - soft_acc: 0.7152 - val_loss: 0.5407 - val_soft_acc: 0.5263\n",
      "Epoch 1353/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.3786 - soft_acc: 0.7219 - val_loss: 0.5321 - val_soft_acc: 0.5351\n",
      "Epoch 1354/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.3755 - soft_acc: 0.7196 - val_loss: 0.6312 - val_soft_acc: 0.5702\n",
      "Epoch 1355/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.3950 - soft_acc: 0.7196 - val_loss: 0.5492 - val_soft_acc: 0.5614\n",
      "Epoch 1356/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.3813 - soft_acc: 0.7285 - val_loss: 0.5275 - val_soft_acc: 0.5000\n",
      "Epoch 1357/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.3779 - soft_acc: 0.7130 - val_loss: 0.5529 - val_soft_acc: 0.5526\n",
      "Epoch 1358/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.3774 - soft_acc: 0.7152 - val_loss: 0.5545 - val_soft_acc: 0.5526\n",
      "Epoch 1359/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.3855 - soft_acc: 0.7174 - val_loss: 0.5488 - val_soft_acc: 0.5614\n",
      "Epoch 1360/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.3791 - soft_acc: 0.7373 - val_loss: 0.5679 - val_soft_acc: 0.5614\n",
      "Epoch 1361/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.3816 - soft_acc: 0.7307 - val_loss: 0.5297 - val_soft_acc: 0.5439\n",
      "Epoch 1362/2000\n",
      "453/453 [==============================] - 0s 264us/step - loss: 0.3790 - soft_acc: 0.7285 - val_loss: 0.5505 - val_soft_acc: 0.5351\n",
      "Epoch 1363/2000\n",
      "453/453 [==============================] - 0s 264us/step - loss: 0.3805 - soft_acc: 0.7395 - val_loss: 0.5272 - val_soft_acc: 0.5439\n",
      "Epoch 1364/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.3821 - soft_acc: 0.7417 - val_loss: 0.5440 - val_soft_acc: 0.5175\n",
      "Epoch 1365/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.3837 - soft_acc: 0.7263 - val_loss: 0.5425 - val_soft_acc: 0.5877\n",
      "Epoch 1366/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.3811 - soft_acc: 0.7351 - val_loss: 0.5335 - val_soft_acc: 0.5702\n",
      "Epoch 1367/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.3811 - soft_acc: 0.7285 - val_loss: 0.5403 - val_soft_acc: 0.5614\n",
      "Epoch 1368/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.3753 - soft_acc: 0.7461 - val_loss: 0.5382 - val_soft_acc: 0.5263\n",
      "Epoch 1369/2000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.3784 - soft_acc: 0.7263 - val_loss: 0.5365 - val_soft_acc: 0.5263\n",
      "Epoch 1370/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.3779 - soft_acc: 0.7307 - val_loss: 0.5628 - val_soft_acc: 0.5702\n",
      "Epoch 1371/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.3801 - soft_acc: 0.7395 - val_loss: 0.5822 - val_soft_acc: 0.5614\n",
      "Epoch 1372/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.3818 - soft_acc: 0.7196 - val_loss: 0.5484 - val_soft_acc: 0.5614\n",
      "Epoch 1373/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.3762 - soft_acc: 0.7417 - val_loss: 0.5765 - val_soft_acc: 0.5789\n",
      "Epoch 1374/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.3819 - soft_acc: 0.7285 - val_loss: 0.5365 - val_soft_acc: 0.5088\n",
      "Epoch 1375/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.3836 - soft_acc: 0.7285 - val_loss: 0.5449 - val_soft_acc: 0.5614\n",
      "Epoch 1376/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.3808 - soft_acc: 0.7483 - val_loss: 0.5263 - val_soft_acc: 0.5439\n",
      "Epoch 1377/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 268us/step - loss: 0.3792 - soft_acc: 0.7285 - val_loss: 0.5381 - val_soft_acc: 0.5000\n",
      "Epoch 1378/2000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.3824 - soft_acc: 0.7285 - val_loss: 0.5460 - val_soft_acc: 0.5526\n",
      "Epoch 1379/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.3802 - soft_acc: 0.7351 - val_loss: 0.5589 - val_soft_acc: 0.5614\n",
      "Epoch 1380/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.3770 - soft_acc: 0.7373 - val_loss: 0.5376 - val_soft_acc: 0.5351\n",
      "Epoch 1381/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3798 - soft_acc: 0.7395 - val_loss: 0.5457 - val_soft_acc: 0.5789\n",
      "Epoch 1382/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.3772 - soft_acc: 0.7351 - val_loss: 0.5334 - val_soft_acc: 0.5351\n",
      "Epoch 1383/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3754 - soft_acc: 0.7395 - val_loss: 0.5286 - val_soft_acc: 0.5351\n",
      "Epoch 1384/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.3768 - soft_acc: 0.7351 - val_loss: 0.5364 - val_soft_acc: 0.5439\n",
      "Epoch 1385/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.3770 - soft_acc: 0.7329 - val_loss: 0.5333 - val_soft_acc: 0.5351\n",
      "Epoch 1386/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.3790 - soft_acc: 0.7219 - val_loss: 0.5911 - val_soft_acc: 0.5789\n",
      "Epoch 1387/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.3843 - soft_acc: 0.7417 - val_loss: 0.5681 - val_soft_acc: 0.5526\n",
      "Epoch 1388/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.3796 - soft_acc: 0.7351 - val_loss: 0.5446 - val_soft_acc: 0.5000\n",
      "Epoch 1389/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.3780 - soft_acc: 0.7483 - val_loss: 0.5926 - val_soft_acc: 0.5877\n",
      "Epoch 1390/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.3817 - soft_acc: 0.7174 - val_loss: 0.5444 - val_soft_acc: 0.5439\n",
      "Epoch 1391/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.3792 - soft_acc: 0.7483 - val_loss: 0.5478 - val_soft_acc: 0.5526\n",
      "Epoch 1392/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.3762 - soft_acc: 0.7152 - val_loss: 0.5392 - val_soft_acc: 0.5351\n",
      "Epoch 1393/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.3764 - soft_acc: 0.7263 - val_loss: 0.6100 - val_soft_acc: 0.5526\n",
      "Epoch 1394/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.3833 - soft_acc: 0.7395 - val_loss: 0.5781 - val_soft_acc: 0.5702\n",
      "Epoch 1395/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3799 - soft_acc: 0.7241 - val_loss: 0.5384 - val_soft_acc: 0.5175\n",
      "Epoch 1396/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.3755 - soft_acc: 0.7241 - val_loss: 0.5435 - val_soft_acc: 0.5175\n",
      "Epoch 1397/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.3842 - soft_acc: 0.7108 - val_loss: 0.5662 - val_soft_acc: 0.5439\n",
      "Epoch 1398/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.3784 - soft_acc: 0.7373 - val_loss: 0.5386 - val_soft_acc: 0.5263\n",
      "Epoch 1399/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.3768 - soft_acc: 0.7307 - val_loss: 0.5387 - val_soft_acc: 0.5526\n",
      "Epoch 1400/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.3753 - soft_acc: 0.7351 - val_loss: 0.5412 - val_soft_acc: 0.5614\n",
      "Epoch 1401/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.3778 - soft_acc: 0.7351 - val_loss: 0.5448 - val_soft_acc: 0.5000\n",
      "Epoch 1402/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.3785 - soft_acc: 0.7373 - val_loss: 0.5494 - val_soft_acc: 0.5439\n",
      "Epoch 1403/2000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.3796 - soft_acc: 0.7285 - val_loss: 0.5459 - val_soft_acc: 0.5351\n",
      "Epoch 1404/2000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.3745 - soft_acc: 0.7329 - val_loss: 0.5729 - val_soft_acc: 0.5614\n",
      "Epoch 1405/2000\n",
      "453/453 [==============================] - 0s 264us/step - loss: 0.3809 - soft_acc: 0.7196 - val_loss: 0.5437 - val_soft_acc: 0.5263\n",
      "Epoch 1406/2000\n",
      "453/453 [==============================] - 0s 262us/step - loss: 0.3769 - soft_acc: 0.7263 - val_loss: 0.6120 - val_soft_acc: 0.5614\n",
      "Epoch 1407/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.3807 - soft_acc: 0.7241 - val_loss: 0.5374 - val_soft_acc: 0.5351\n",
      "Epoch 1408/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.3735 - soft_acc: 0.7241 - val_loss: 0.5410 - val_soft_acc: 0.5439\n",
      "Epoch 1409/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.3752 - soft_acc: 0.7196 - val_loss: 0.5437 - val_soft_acc: 0.5351\n",
      "Epoch 1410/2000\n",
      "453/453 [==============================] - 0s 263us/step - loss: 0.3735 - soft_acc: 0.7417 - val_loss: 0.5362 - val_soft_acc: 0.5175\n",
      "Epoch 1411/2000\n",
      "453/453 [==============================] - 0s 258us/step - loss: 0.3741 - soft_acc: 0.7285 - val_loss: 0.5986 - val_soft_acc: 0.5702\n",
      "Epoch 1412/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.3798 - soft_acc: 0.7219 - val_loss: 0.5346 - val_soft_acc: 0.5175\n",
      "Epoch 1413/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.3758 - soft_acc: 0.7307 - val_loss: 0.5348 - val_soft_acc: 0.5263\n",
      "Epoch 1414/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3793 - soft_acc: 0.7241 - val_loss: 0.5366 - val_soft_acc: 0.5351\n",
      "Epoch 1415/2000\n",
      "453/453 [==============================] - 0s 264us/step - loss: 0.3740 - soft_acc: 0.7351 - val_loss: 0.5438 - val_soft_acc: 0.5263\n",
      "Epoch 1416/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3781 - soft_acc: 0.7373 - val_loss: 0.5296 - val_soft_acc: 0.5439\n",
      "Epoch 1417/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.3804 - soft_acc: 0.7285 - val_loss: 0.5314 - val_soft_acc: 0.5526\n",
      "Epoch 1418/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.3730 - soft_acc: 0.7439 - val_loss: 0.5434 - val_soft_acc: 0.5439\n",
      "Epoch 1419/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.3746 - soft_acc: 0.7329 - val_loss: 0.5512 - val_soft_acc: 0.5439\n",
      "Epoch 1420/2000\n",
      "453/453 [==============================] - 0s 263us/step - loss: 0.3720 - soft_acc: 0.7351 - val_loss: 0.5464 - val_soft_acc: 0.5439\n",
      "Epoch 1421/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.3761 - soft_acc: 0.7439 - val_loss: 0.5438 - val_soft_acc: 0.5175\n",
      "Epoch 1422/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.3817 - soft_acc: 0.7241 - val_loss: 0.5526 - val_soft_acc: 0.5088\n",
      "Epoch 1423/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.3795 - soft_acc: 0.7307 - val_loss: 0.5323 - val_soft_acc: 0.5351\n",
      "Epoch 1424/2000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.3790 - soft_acc: 0.7329 - val_loss: 0.5329 - val_soft_acc: 0.5526\n",
      "Epoch 1425/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.3767 - soft_acc: 0.7285 - val_loss: 0.5377 - val_soft_acc: 0.5351\n",
      "Epoch 1426/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.3832 - soft_acc: 0.7351 - val_loss: 0.5384 - val_soft_acc: 0.5263\n",
      "Epoch 1427/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.3755 - soft_acc: 0.7329 - val_loss: 0.5701 - val_soft_acc: 0.5702\n",
      "Epoch 1428/2000\n",
      "453/453 [==============================] - 0s 263us/step - loss: 0.3749 - soft_acc: 0.7329 - val_loss: 0.5319 - val_soft_acc: 0.5351\n",
      "Epoch 1429/2000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.3796 - soft_acc: 0.7307 - val_loss: 0.5488 - val_soft_acc: 0.5351\n",
      "Epoch 1430/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.3768 - soft_acc: 0.7329 - val_loss: 0.5328 - val_soft_acc: 0.5351\n",
      "Epoch 1431/2000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.3768 - soft_acc: 0.7439 - val_loss: 0.5648 - val_soft_acc: 0.5702\n",
      "Epoch 1432/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 263us/step - loss: 0.3753 - soft_acc: 0.7373 - val_loss: 0.5546 - val_soft_acc: 0.5526\n",
      "Epoch 1433/2000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.3755 - soft_acc: 0.7439 - val_loss: 0.5582 - val_soft_acc: 0.5439\n",
      "Epoch 1434/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.3725 - soft_acc: 0.7528 - val_loss: 0.5458 - val_soft_acc: 0.5175\n",
      "Epoch 1435/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.3745 - soft_acc: 0.7351 - val_loss: 0.5456 - val_soft_acc: 0.5614\n",
      "Epoch 1436/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.3731 - soft_acc: 0.7461 - val_loss: 0.5279 - val_soft_acc: 0.5263\n",
      "Epoch 1437/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.3704 - soft_acc: 0.7263 - val_loss: 0.5547 - val_soft_acc: 0.5263\n",
      "Epoch 1438/2000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.3782 - soft_acc: 0.7307 - val_loss: 0.5302 - val_soft_acc: 0.5439\n",
      "Epoch 1439/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3716 - soft_acc: 0.7395 - val_loss: 0.5598 - val_soft_acc: 0.5614\n",
      "Epoch 1440/2000\n",
      "453/453 [==============================] - 0s 264us/step - loss: 0.3774 - soft_acc: 0.7285 - val_loss: 0.5557 - val_soft_acc: 0.5614\n",
      "Epoch 1441/2000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.3745 - soft_acc: 0.7130 - val_loss: 0.5415 - val_soft_acc: 0.5175\n",
      "Epoch 1442/2000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3717 - soft_acc: 0.7329 - val_loss: 0.5655 - val_soft_acc: 0.5526\n",
      "Epoch 1443/2000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.3726 - soft_acc: 0.7196 - val_loss: 0.5616 - val_soft_acc: 0.5000\n",
      "Epoch 1444/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.3816 - soft_acc: 0.7285 - val_loss: 0.5784 - val_soft_acc: 0.5789\n",
      "Epoch 1445/2000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.3746 - soft_acc: 0.7329 - val_loss: 0.5448 - val_soft_acc: 0.5263\n",
      "Epoch 1446/2000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.3806 - soft_acc: 0.7307 - val_loss: 0.5307 - val_soft_acc: 0.5351\n",
      "Epoch 1447/2000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.3755 - soft_acc: 0.7174 - val_loss: 0.5369 - val_soft_acc: 0.5526\n",
      "Epoch 1448/2000\n",
      "453/453 [==============================] - 0s 259us/step - loss: 0.3782 - soft_acc: 0.7307 - val_loss: 0.5289 - val_soft_acc: 0.5439\n",
      "Epoch 1449/2000\n",
      "453/453 [==============================] - 0s 259us/step - loss: 0.3779 - soft_acc: 0.7130 - val_loss: 0.5531 - val_soft_acc: 0.5702\n",
      "Epoch 1450/2000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.3742 - soft_acc: 0.7307 - val_loss: 0.6189 - val_soft_acc: 0.5789\n",
      "Epoch 1451/2000\n",
      "453/453 [==============================] - 0s 288us/step - loss: 0.3894 - soft_acc: 0.7241 - val_loss: 0.5573 - val_soft_acc: 0.5702\n",
      "Epoch 1452/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.3729 - soft_acc: 0.7196 - val_loss: 0.5299 - val_soft_acc: 0.5614\n",
      "Epoch 1453/2000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.3711 - soft_acc: 0.7307 - val_loss: 0.5540 - val_soft_acc: 0.5526\n",
      "Epoch 1454/2000\n",
      "453/453 [==============================] - 0s 261us/step - loss: 0.3740 - soft_acc: 0.7263 - val_loss: 0.5335 - val_soft_acc: 0.5351\n",
      "Epoch 1455/2000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.3742 - soft_acc: 0.7395 - val_loss: 0.5373 - val_soft_acc: 0.5263\n",
      "Epoch 1456/2000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.3761 - soft_acc: 0.7351 - val_loss: 0.5365 - val_soft_acc: 0.4912\n",
      "Epoch 1457/2000\n",
      "453/453 [==============================] - 0s 252us/step - loss: 0.3732 - soft_acc: 0.7307 - val_loss: 0.5443 - val_soft_acc: 0.5351\n",
      "Epoch 1458/2000\n",
      "453/453 [==============================] - 0s 258us/step - loss: 0.3729 - soft_acc: 0.7351 - val_loss: 0.5413 - val_soft_acc: 0.5175\n",
      "Epoch 1459/2000\n",
      "453/453 [==============================] - 0s 249us/step - loss: 0.3693 - soft_acc: 0.7285 - val_loss: 0.5284 - val_soft_acc: 0.5263\n",
      "Epoch 1460/2000\n",
      "453/453 [==============================] - 0s 245us/step - loss: 0.3758 - soft_acc: 0.7263 - val_loss: 0.5488 - val_soft_acc: 0.5702\n",
      "Epoch 1461/2000\n",
      "453/453 [==============================] - 0s 252us/step - loss: 0.3749 - soft_acc: 0.7174 - val_loss: 0.5330 - val_soft_acc: 0.5263\n",
      "Epoch 1462/2000\n",
      "453/453 [==============================] - 0s 257us/step - loss: 0.3716 - soft_acc: 0.7439 - val_loss: 0.5669 - val_soft_acc: 0.5088\n",
      "Epoch 1463/2000\n",
      "453/453 [==============================] - 0s 254us/step - loss: 0.3764 - soft_acc: 0.7241 - val_loss: 0.5629 - val_soft_acc: 0.5614\n",
      "Epoch 1464/2000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.3737 - soft_acc: 0.7461 - val_loss: 0.5363 - val_soft_acc: 0.5263\n",
      "Epoch 1465/2000\n",
      "453/453 [==============================] - 0s 246us/step - loss: 0.3719 - soft_acc: 0.7417 - val_loss: 0.5319 - val_soft_acc: 0.5351\n",
      "Epoch 1466/2000\n",
      "453/453 [==============================] - 0s 248us/step - loss: 0.3733 - soft_acc: 0.7196 - val_loss: 0.5306 - val_soft_acc: 0.5263\n",
      "Epoch 1467/2000\n",
      "453/453 [==============================] - 0s 256us/step - loss: 0.3730 - soft_acc: 0.7461 - val_loss: 0.5566 - val_soft_acc: 0.5088\n",
      "Epoch 1468/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.3760 - soft_acc: 0.7373 - val_loss: 0.5377 - val_soft_acc: 0.5175\n",
      "Epoch 1469/2000\n",
      "453/453 [==============================] - 0s 304us/step - loss: 0.3726 - soft_acc: 0.7285 - val_loss: 0.5373 - val_soft_acc: 0.5088\n",
      "Epoch 1470/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.3703 - soft_acc: 0.7417 - val_loss: 0.5346 - val_soft_acc: 0.5175\n",
      "Epoch 1471/2000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.3716 - soft_acc: 0.7373 - val_loss: 0.5352 - val_soft_acc: 0.5351\n",
      "Epoch 1472/2000\n",
      "453/453 [==============================] - 0s 297us/step - loss: 0.3745 - soft_acc: 0.7329 - val_loss: 0.5686 - val_soft_acc: 0.5789\n",
      "Epoch 1473/2000\n",
      "453/453 [==============================] - 0s 287us/step - loss: 0.3721 - soft_acc: 0.7351 - val_loss: 0.5422 - val_soft_acc: 0.5000\n",
      "Epoch 1474/2000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.3725 - soft_acc: 0.7395 - val_loss: 0.5411 - val_soft_acc: 0.5175\n",
      "Epoch 1475/2000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.3768 - soft_acc: 0.7461 - val_loss: 0.5347 - val_soft_acc: 0.5526\n",
      "Epoch 1476/2000\n",
      "453/453 [==============================] - 0s 262us/step - loss: 0.3725 - soft_acc: 0.7373 - val_loss: 0.5488 - val_soft_acc: 0.5702\n",
      "Epoch 1477/2000\n",
      "453/453 [==============================] - 0s 248us/step - loss: 0.3769 - soft_acc: 0.7351 - val_loss: 0.5313 - val_soft_acc: 0.5614\n",
      "Epoch 1478/2000\n",
      "453/453 [==============================] - 0s 245us/step - loss: 0.3710 - soft_acc: 0.7373 - val_loss: 0.5215 - val_soft_acc: 0.5439\n",
      "Epoch 1479/2000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.3691 - soft_acc: 0.7373 - val_loss: 0.5864 - val_soft_acc: 0.5965\n",
      "Epoch 1480/2000\n",
      "453/453 [==============================] - 0s 252us/step - loss: 0.3806 - soft_acc: 0.7373 - val_loss: 0.5163 - val_soft_acc: 0.5351\n",
      "Epoch 1481/2000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.3679 - soft_acc: 0.7395 - val_loss: 0.5266 - val_soft_acc: 0.5263\n",
      "Epoch 1482/2000\n",
      " 50/453 [==>...........................] - ETA: 0s - loss: 0.3495 - soft_acc: 0.7800"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_soft_acc',patience=100, mode='max')\n",
    "cp = ModelCheckpoint('model-{epoch:03d}-{soft_acc:03f}-{val_soft_acc:03f}.h5', verbose=0, monitor='val_soft_acc',save_best_only=True, mode='max')  \n",
    "model.compile(optimizer=RMSprop(),loss='mse',metrics=[soft_acc])\n",
    "history = model.fit(data, tags,epochs=2000,  batch_size=50,validation_split=0.2,callbacks=[cp], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "soft_acc = history.history['soft_acc']\n",
    "soft_val_acc = history.history['val_soft_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(soft_acc) + 1)\n",
    "plt.figure(figsize=(30,5))\n",
    "plt.plot(epochs, soft_acc, 'bo', label='Soft Training acc')\n",
    "plt.plot(epochs, soft_val_acc, 'r', label='Soft Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure(figsize=(30,5))\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.578947995838362\n",
      "35.087719062964126\n",
      "36.842105315442666\n",
      "49.12280712211341\n",
      "52.6315792087923\n",
      "54.38596501685026\n",
      "64.91228122460214\n",
      "45.61403498314975\n",
      "49.122806180987446\n",
      "42.59259237183465\n",
      "Accuracy: 46.18908384825751 std: 9.559257271784583\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "cvs_scores = []\n",
    "for train, test in kfold.split(data, tags):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(8, 10, activation='relu',kernel_regularizer=l1(0.038), input_shape=(1000,45)))\n",
    "#     model.add(Conv1D(128, 5, activation='relu',kernel_regularizer=l1_l2(l1=0.01, l2=0.01), input_shape=(1000,45)))\n",
    "#     model.add(MaxPooling1D(5))\n",
    "#     model.add(Conv1D(64, 5, activation='relu',kernel_regularizer=l1_l2(l1=0.001, l2=0.001)))\n",
    "#     model.add(MaxPooling1D(5))\n",
    "#     model.add(Conv1D(32, 5, activation='relu',kernel_regularizer=l1_l2(l1=0.0003, l2=0.0003)))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(1))\n",
    "    def soft_acc(y_true, y_pred):\n",
    "        from tensorflow.python.keras import backend as K\n",
    "        return K.mean(K.equal(K.round(y_true), K.round(y_pred)))\n",
    "    model.compile(optimizer=RMSprop(),loss='mse',metrics=[soft_acc])\n",
    "    model.fit(data[train], tags[train], epochs=1000, verbose=0)\n",
    "    scores = model.evaluate(data[test], tags[test], verbose=0)\n",
    "    print(scores[1]*100)\n",
    "    cvs_scores.append(scores[1]*100)\n",
    "print(\"Accuracy:\", np.mean(cvs_scores),\"std:\", np.std(cvs_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on old dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 0s 159us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7454337044491794, 0.44262295092145604]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(old_data, old_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
